{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2OqEGzKBx26p"
   },
   "source": [
    "# Build neural network model from scratch\n",
    "\n",
    "Predict summaries using LSTM build from scratch using PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IWVmcyVy-gxD",
    "outputId": "00000b3f-532a-4859-af52-c6532a212359"
   },
   "outputs": [],
   "source": [
    "# don't need to run this code if not on Google Colab\n",
    "# Mount Google Drive\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D0f1aRQ7FkSw",
    "outputId": "b19b3242-96ca-4f62-dfd3-036095825196"
   },
   "outputs": [],
   "source": [
    "# !git clone https://github.com/p-parks/AAI-590_Capstone.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rSqooP0VJfrk",
    "outputId": "3ff4c28c-e843-475c-e9d2-30db19c0671c"
   },
   "outputs": [],
   "source": [
    "# !pip install evaluate\n",
    "# !pip install rouge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "OT9ybofgx26s"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\paula\\.conda\\envs\\llama\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# %% Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoTokenizer\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e_uV9zeAx26u"
   },
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "6kWRfgR5x26u"
   },
   "outputs": [],
   "source": [
    "dataset_dir = 'datasets'\n",
    "df = pd.read_csv(f'{dataset_dir}/podcast_with_summary.csv')\n",
    "df_train = pd.read_csv(f'{dataset_dir}/podcast_with_summary_train.csv')\n",
    "df_test = pd.read_csv(f'{dataset_dir}/podcast_with_summary_test.csv')\n",
    "\n",
    "# df = pd.read_csv('/content/drive/MyDrive/ColabNotebooks/AAI590_Capstone/Datasets/podcast_with_summary.csv')\n",
    "# df_train = pd.read_csv('/content/drive/MyDrive/ColabNotebooks/AAI590_Capstone/Datasets/podcast_with_summary_train.csv')\n",
    "# df_test = pd.read_csv('/content/drive/MyDrive/ColabNotebooks/AAI590_Capstone/Datasets/podcast_with_summary_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fMu0ztG0x26u",
    "outputId": "3e283ebc-ae6e-4dd6-ab60-283eb22a0aac"
   },
   "outputs": [],
   "source": [
    "# the lengths of input and output must be the same for out model\n",
    "max_length = 1024\n",
    "\n",
    "# Use Hugging Face tokenizer\n",
    "model_name = \"bert-base-uncased\"  # Replace with a model suitable for tokenization\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def tokenize_text(texts, max_length):\n",
    "    return tokenizer(\n",
    "        texts,\n",
    "        max_length=max_length,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "# Tokenize inputs and summaries\n",
    "# input_tokens = tokenize_text(df['text_short'].tolist(), max_length)\n",
    "# summary_tokens = tokenize_text(df['summary'].tolist(), max_length)\n",
    "\n",
    "# X = input_tokens['input_ids']\n",
    "# Y = summary_tokens['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "-wSCmTFO858c"
   },
   "outputs": [],
   "source": [
    "# Tokenize inputs and summaries\n",
    "input_tokens = tokenize_text(df['text'].tolist(), max_length)\n",
    "summary_tokens = tokenize_text(df['summary'].tolist(), max_length)\n",
    "\n",
    "train_input_tokens = tokenize_text(df_train['text'].tolist(), max_length)\n",
    "train_summary_tokens = tokenize_text(df_train['summary'].tolist(), max_length)\n",
    "test_input_tokens = tokenize_text(df_test['text'].tolist(), max_length)\n",
    "test_summary_tokens = tokenize_text(df_test['summary'].tolist(), max_length)\n",
    "\n",
    "X = input_tokens['input_ids']\n",
    "Y = summary_tokens['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "NjQKxch7x26v"
   },
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1, random_state=42)\n",
    "X_train = train_input_tokens['input_ids']\n",
    "Y_train = train_summary_tokens['input_ids']\n",
    "X_test = test_input_tokens['input_ids']\n",
    "Y_test = test_summary_tokens['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "D9G7T96Hx26v"
   },
   "outputs": [],
   "source": [
    "#Create PyTorch Dataset to load data\n",
    "class TextSummaryDataset(Dataset):\n",
    "    def __init__(self, inputs, targets):\n",
    "        self.inputs = inputs\n",
    "        self.targets = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.inputs[idx], self.targets[idx]\n",
    "\n",
    "train_dataset = TextSummaryDataset(X_train, Y_train)\n",
    "test_dataset = TextSummaryDataset(X_test, Y_test)\n",
    "\n",
    "# I experimented with different batch sizes and found 32 to be the best\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EwlA0eg9x26v",
    "outputId": "f4e343fb-4323-4961-d6b1-f553692d7732"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([319, 1024]), Target shape: torch.Size([319, 1024])\n"
     ]
    }
   ],
   "source": [
    "X = input_tokens['input_ids']\n",
    "Y = summary_tokens['input_ids']\n",
    "\n",
    "# Verify dimensions\n",
    "print(f\"Input shape: {X.shape}, Target shape: {Y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WZw1LCwcx26w",
    "outputId": "908636bc-a9ef-4137-a18a-da4fb7fa0cd3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] as part of mit course 6s099, artificial general intelligence, i ' ve gotten the chance to sit down with max tegmark. he is a professor here at mit. he ' s a physicist, spent a large part of his career studying the mysteries of our cosmological universe. but he ' s also studied and delved into the beneficial possibilities and the existential risks of artificial intelligence. amongst many other things, he is the cofounder of the future of life institute, author of two books, both of which i highly recommend. first, our mathematical universe. second is life 3. 0. he ' s truly an out of the box thinker and a fun personality, so i really enjoy talking to him. if you ' d like to see more of these videos in the future, please subscribe and also click the little bell icon to make sure you don ' t miss any videos. also, twitter, linkedin, agi. mit. edu if you wanna watch other lectures or conversations like this one. better yet, go read max ' s book, life 3. 0. chapter seven on goals is my favorite. it ' s really where philosophy and engineering come together and it opens with a quote by dostoevsky. the mystery of human existence lies not in just staying alive but in finding something to live for. lastly, i believe that every failure rewards us with an opportunity to learn and in that sense, i ' ve been very fortunate to fail in so many new and exciting ways and this conversation was no different. i ' ve learned about something called radio frequency interference, rfi, look it up. apparently, music and conversations from local radio stations can bleed into the audio that you ' re recording in such a way that it almost completely ruins that audio. it ' s an exceptionally difficult sound source to remove. so, i ' ve gotten the opportunity to learn how to avoid rfi in the future during recording sessions. i ' ve also gotten the opportunity to learn how to use adobe audition and izotope rx 6 to do some noise, some audio repair. of course, this is an exceptionally difficult noise to remove. i am an engineer. i ' m not an audio engineer. neither is anybody else in our group but we did our best. nevertheless, i thank you for your patience and i hope you ' re still able to enjoy this conversation. do you think there ' s intelligent life out there in the universe? let ' s open up with an easy question. i have a minority view here actually. when i give public lectures, i often ask for a show of hands who thinks there ' s intelligent life out there somewhere else and almost everyone put their hands up and when i ask why, they ' ll be like, oh, there ' s so many galaxies out there, there ' s gotta be. but i ' m a numbers nerd, right? so when you look more carefully at it, it ' s not so clear at all. when we talk about our universe, first of all, we don ' t mean all of space. we actually mean, i don ' t know, you can throw me the universe if you want, it ' s behind you there. it ' s, we simply mean the spherical region of space from which light has a time to reach us so far during the 14. 8 billion year, 13. 8 billion years since our big bang. there ' s more space here but this is what we call a universe because that ' s all we have access to. so is there intelligent life here that ' s gotten to the point of building telescopes and computers? my guess is no, actually. the probability of it happening on any given planet is some number we don ' t know what it is. and what we do know is that the number can ' t be super high because there ' s over a billion earth like planets in the milky way galaxy alone, many of which are billions of years older than earth. and aside from some ufo believers, there isn ' t much evidence that any superduran civilization has come here at all. and so that ' s the famous fermi paradox, right? and then if you work the numbers, what you find is that if you have no clue what the probability is of getting life on a given planet, so it could be 10 to the minus 10, 10 to the minus 20, or 10 to the minus two, or any power of 10 is sort of equally likely if you wanna be really open minded, that translates into it being equally likely that our nearest neighbor is 10 to the 16 meters away, 10 to the 17 meters away, 10 to the 18. by the time you get much less than 10 to the 16 already, we pretty much know there is nothing else that close. and when you get beyond 10. because they would have discovered us. yeah, they would have been discovered as long ago, or if they ' re really close, we would have probably noted some engineering projects that they ' re [SEP]\n",
      "[CLS] podcast features mit ' s max tegmark discussing cosmology, ai risks, and his books ; subscribe for more engaging conversations. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(X[0]))\n",
    "print(tokenizer.decode(Y[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "flvXEAklx26w"
   },
   "source": [
    "## Build the LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "lGMlyIVhx26w"
   },
   "outputs": [],
   "source": [
    "\n",
    "class LSTMSummarizer(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_units):\n",
    "        super(LSTMSummarizer, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=tokenizer.pad_token_id)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_units, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_units * 2, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        lstm_out, _ = self.lstm(embedded)\n",
    "        out = self.fc(lstm_out)  # Predict for each time step\n",
    "        return out\n",
    "\n",
    "embedding_dim = 128\n",
    "hidden_units = 256\n",
    "vocab_size = tokenizer.vocab_size\n",
    "model = LSTMSummarizer(vocab_size, embedding_dim, hidden_units).to('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Gtczfrp8x26w"
   },
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import StepLR\n",
    "# I was trying to use mixed precision training but was unable to get it to work\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "# Define optimizer and loss function\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# Training loop\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "scheduler = StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "def train_model(model, train_loader, criterion, optimizer, scheduler, epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0\n",
    "        for inputs, targets in tqdm(train_loader):\n",
    "            # Move inputs and targets to gpu\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            outputs = outputs.view(-1, outputs.size(-1))\n",
    "            targets = targets.view(-1)\n",
    "\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {epoch_loss / len(train_loader):.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b6r87lWPx26x",
    "outputId": "8e1fed44-1d51-48c6-a508-0e789dc115de"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:02<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 10.3167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  5.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100, Loss: 10.2759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  6.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100, Loss: 10.2321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  6.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100, Loss: 10.1772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100, Loss: 10.1001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  6.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/100, Loss: 10.0352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  6.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/100, Loss: 10.0214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  6.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/100, Loss: 10.0067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  6.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100, Loss: 9.9908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  6.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100, Loss: 9.9743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  6.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/100, Loss: 9.9634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  6.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/100, Loss: 9.9617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  6.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/100, Loss: 9.9596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  6.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/100, Loss: 9.9582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  6.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/100, Loss: 9.9566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  6.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/100, Loss: 9.9553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  6.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/100, Loss: 9.9553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  6.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/100, Loss: 9.9551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  6.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/100, Loss: 9.9549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  6.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/100, Loss: 9.9547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  6.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/100, Loss: 9.9548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  6.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/100, Loss: 9.9548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  6.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/100, Loss: 9.9547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  6.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/100, Loss: 9.9545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  6.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/100, Loss: 9.9546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  6.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/100, Loss: 9.9547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  6.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/100, Loss: 9.9545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  6.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/100, Loss: 9.9547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  6.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/100, Loss: 9.9546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  6.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/100, Loss: 9.9543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  6.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/100, Loss: 9.9547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  6.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/100, Loss: 9.9546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  5.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/100, Loss: 9.9545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  6.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/100, Loss: 9.9547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  6.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/100, Loss: 9.9548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  6.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/100, Loss: 9.9548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  6.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/100, Loss: 9.9548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  6.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/100, Loss: 9.9546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  6.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/100, Loss: 9.9547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  6.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/100, Loss: 9.9546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  6.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/100, Loss: 9.9545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  6.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/100, Loss: 9.9545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  6.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/100, Loss: 9.9546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  6.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/100, Loss: 9.9544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  6.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/100, Loss: 9.9546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  6.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/100, Loss: 9.9547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  6.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/100, Loss: 9.9545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  6.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/100, Loss: 9.9546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  6.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/100, Loss: 9.9545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  6.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/100, Loss: 9.9546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  6.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/100, Loss: 9.9547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  6.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/100, Loss: 9.9547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  6.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/100, Loss: 9.9544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  6.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/100, Loss: 9.9546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  6.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/100, Loss: 9.9547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  6.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/100, Loss: 9.9547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100, Loss: 9.9547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  6.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100, Loss: 9.9546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  6.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100, Loss: 9.9546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  6.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/100, Loss: 9.9546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  6.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100, Loss: 9.9546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  6.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/100, Loss: 9.9547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  6.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/100, Loss: 9.9547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  6.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/100, Loss: 9.9546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  6.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/100, Loss: 9.9548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  6.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/100, Loss: 9.9546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  6.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/100, Loss: 9.9546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  6.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/100, Loss: 9.9546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  6.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/100, Loss: 9.9547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/100, Loss: 9.9545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  6.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/100, Loss: 9.9547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  7.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/100, Loss: 9.9547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  7.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/100, Loss: 9.9546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  7.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/100, Loss: 9.9545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  6.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/100, Loss: 9.9544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  7.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/100, Loss: 9.9547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  6.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/100, Loss: 9.9546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  6.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/100, Loss: 9.9547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  6.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/100, Loss: 9.9545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  6.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100, Loss: 9.9547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  7.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/100, Loss: 9.9546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  6.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/100, Loss: 9.9547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  6.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/100, Loss: 9.9546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  6.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/100, Loss: 9.9547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  6.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/100, Loss: 9.9548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  6.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/100, Loss: 9.9547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  6.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/100, Loss: 9.9545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  6.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/100, Loss: 9.9547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  6.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/100, Loss: 9.9547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  6.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/100, Loss: 9.9546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  6.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/100, Loss: 9.9546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  6.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92/100, Loss: 9.9547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  6.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/100, Loss: 9.9547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  6.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/100, Loss: 9.9549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  6.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/100, Loss: 9.9548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  6.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/100, Loss: 9.9547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  6.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/100, Loss: 9.9547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  6.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/100, Loss: 9.9545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  6.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/100, Loss: 9.9546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  6.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100, Loss: 9.9546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "epochs = 100\n",
    "train_model(model, train_loader, criterion, optimizer, scheduler, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vzvdEoTyx26x"
   },
   "source": [
    "## Run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "zDTrzcRGx26x"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Ensure the directory exists\n",
    "output_dir = \"./results/pytorch\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "output_length = 200\n",
    "\n",
    "def run_inference(text):\n",
    "    model.eval()\n",
    "    input_tokens = tokenize_text([text], max_length)\n",
    "    input_ids = input_tokens['input_ids'].to(device)\n",
    "    attention_mask = input_tokens['attention_mask'].to(device)\n",
    "\n",
    "    generated_tokens = []\n",
    "    current_input = input_ids\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _ in range(output_length):\n",
    "            logits = model(current_input)  # Shape: (batch_size, seq_len, vocab_size)\n",
    "            next_token_logits = logits[:, -1, :]  # Get logits for the last token\n",
    "\n",
    "            # Using argmax causes the model to generate the same text repeatedly\n",
    "            # next_token_id = torch.argmax(next_token_logits, dim=-1).item()\n",
    "\n",
    "            # Use multinomial sampling to generate a diverse set of outputs\n",
    "            next_token_probs = torch.nn.functional.softmax(next_token_logits, dim=-1)\n",
    "            next_token_id = torch.multinomial(next_token_probs, num_samples=1).item()\n",
    "\n",
    "            if next_token_id == tokenizer.pad_token_id:  # Stop at padding token\n",
    "                break\n",
    "\n",
    "            generated_tokens.append(next_token_id)\n",
    "\n",
    "            # Prepare input for the next iteration\n",
    "            next_token = torch.tensor([[next_token_id]], device=device)\n",
    "            current_input = torch.cat((current_input, next_token), dim=1)\n",
    "\n",
    "    return tokenizer.decode(generated_tokens, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9XQ7dh7Fx26x",
    "outputId": "8134ca84-d10b-44d5-f4de-1d28d6978d76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Text: The following is a conversation with Andrew Ng, one of the most impactful educators, researchers, innovators, and leaders in artificial intelligence and technology space in general. He cofounded Coursera and Google Brain, launched Deep Learning AI, Landing AI, and the AI Fund, and was the chief scientist at Baidu. As a Stanford professor and with Coursera and Deep Learning AI, he has helped educate and inspire millions of students, including me. This is the Artificial Intelligence Podcast. If you enjoy it, subscribe on YouTube, give it five stars on Apple Podcast, support it on Patreon, or simply connect with me on Twitter at Lex Friedman, spelled F R I D M A N. As usual, I'll do one or two minutes of ads now and never any ads in the middle that can break the flow of the conversation. I hope that works for you and doesn't hurt the listening experience. This show is presented by Cash App, the number one finance app in the App Store. When you get it, use code LEXPODCAST. Cash App lets you send money to friends, buy Bitcoin, and invest in the stock market with as little as $1. Broker services are provided by Cash App Investing, a subsidiary of Square, a member SIPC. Since Cash App allows you to buy Bitcoin, let me mention that cryptocurrency in the context of the history of money is fascinating. I recommend Ascent of Money as a great book on this history. Debits and credits on ledgers started over 30,000 years ago. The US dollar was created over 200 years ago, and Bitcoin, the first decentralized cryptocurrency, released just over 10 years ago. So given that history, cryptocurrency is still very much in its early days of development, but it's still aiming to and just might redefine the nature of money. So again, if you get Cash App from the App Store or Google Play and use the code LEXPODCAST, you'll get $10, and Cash App will also donate $10 to FIRST, one of my favorite organizations that is helping to advance robotics and STEM education for young people around the world. And now, here's my conversation with Andrew Ng. The courses you taught on machine learning at Stanford and later on Coursera that you cofounded have educated and inspired millions of people. So let me ask you, what people or ideas inspired you to get into computer science and machine learning when you were young? When did you first fall in love with the field, is another way to put it. Growing up in Hong Kong and Singapore, I started learning to code when I was five or six years old. At that time, I was learning the basic programming language, and they would take these books and they'll tell you, type this program into your computer, so type that program to my computer. And as a result of all that typing, I would get to play these very simple shoot them up games that I had implemented on my little computer. So I thought it was fascinating as a young kid that I could write this code. I was really just copying code from a book into my computer to then play these cool little video games. Another moment for me was when I was a teenager and my father, who's a doctor, was reading about expert systems and about neural networks. So he got me to read some of these books, and I thought it was really cool. You could write a computer that started to exhibit intelligence. Then I remember doing an internship while I was in high school, this was in Singapore, where I remember doing a lot of photocopying and as an office assistant. And the highlight of my job was when I got to use the shredder. So the teenager me, remote thinking, boy, this is a lot of photocopying. If only we could write software, build a robot, something to automate this, maybe I could do something else. So I think a lot of my work since then has centered on the theme of automation. Even the way I think about machine learning today, we're very good at writing learning algorithms that can automate things that people can do. Or even launching the first MOOCs, Mass Open Online Courses, that later led to Coursera. I was trying to automate what could be automatable in how I was teaching on campus. Process of education, trying to automate parts of that to make it more, sort of to have more impact from a single teacher, a single educator. Yeah, I felt, you know, teaching at Stanford, teaching machine learning to about 400 students a year at the time. And I found myself filming the exact same video every year, telling the same jokes in the same room. And I thought, why am I doing this? Why don't we just take last year's video? And then I can spend my time building a deeper relationship with students. So that process of thinking through how to do that, that led to the first MOOCs that we launched. And then you have more time to write new jokes. Are there favorite memories from your early days at Stanford, teaching thousands of people in person and then millions of people online? You know, teaching online, what not many people know was that a lot of those videos were shot between the hours of 10 p.m. and 3 a.m. A lot of times, we were launching the first MOOCs at Stanford. We had already announced the course, about 100,000 people signed up. We just started to write the code and we had not yet actually filmed the videos. So a lot of pressure, 100,000 people waiting for us to produce the content. So many Fridays, Saturdays, I would go out, have dinner with my friends, and then I would think, OK, do you want to go home now? Or do you want to go to the office to film videos? And the thought of being able to help 100,000 people potentially learn machine learning, fortunately, that made me think, OK, I want to go to my office, go to my tiny little recording studio. I would adjust my Logitech webcam, adjust my Wacom tablet, make sure my lapel mic was on, and then I would start recording often until 2 a.m. or 3 a.m. I think unfortunately, that doesn't show that it was recorded that late at night, but it was really inspiring the thought that we could create content to help so many people learn about machine learning. How did that feel? The fact that you're probably somewhat alone, maybe a couple of friends recording with a Logitech webcam and kind of going home alone at 1 or 2 a.m. at night and knowing that that's going to reach sort of thousands of people, eventually millions of people, what's that feeling like? I mean, is there a feeling of just satisfaction of pushing through? I think it's humbling. And I wasn't thinking about what I was feeling. I think one thing that I'm proud to say we got right from the early days was I told my whole team back then that the number one priority is to do what's best for learners, do what's best for students. And so when I went to the recording studio, the only thing on my mind was what can I say? How can I design my slides? What I need to draw right to make these concepts as clear as possible for learners? I think I've seen sometimes instructors is tempting to, hey, let's talk about my work. Maybe if I teach you about my research, someone will cite my papers a couple more times. And I think one of the things we got right, launching the first few MOOCs and later building Coursera, was putting in place that bedrock principle of let's just do what's best for learners and forget about everything else. And I think that that is a guiding principle turned out to be really important to the rise of the MOOC movement. And the kind of learner you imagined in your mind is as broad as possible, as global as possible. So really try to reach as many people interested in machine learning and AI as possible. I really want to help anyone that had an interest in machine learning to break into the field. And I think sometimes I've actually had people ask me, hey, why are you spending so much time explaining gradient descent? And my answer was, if I look at what I think the learner needs and what benefit from, I felt that having that a good understanding of the foundations coming back to the basics would put them in a better stead to then build on a long term career. So try to consistently make decisions on that principle. So one of the things you actually revealed to the narrow AI community at the time and to the world is that the amount of people who are actually interested in AI is much larger than we imagined. By you teaching the class and how popular it became, it showed that, wow, this isn't just a small community of sort of people who go to NeurIPS and it's much bigger. It's developers, it's people from all over the world. I mean, I'm Russian, so everybody in Russia is really interested. There's a huge number of programmers who are interested in machine learning, India, China, South America, everywhere. There's just millions of people who are interested in machine learning. So how big do you get a sense that the number of people is that are interested from your perspective? I think the number has grown over time. I think it's one of those things that maybe it feels like it came out of nowhere, but it's an insight that building it, it took years. It's one of those overnight successes that took years to get there. My first foray into this type of online education was when we were filming my Stanford class and sticking the videos on YouTube and some other things. We had uploaded the horrors and so on, but it's basically the one hour, 15 minute video that we put on YouTube. And then we had four or five other versions of websites that I had built, most of which you would never have heard of because they reached small audiences, but that allowed me to iterate, allowed my team and me to iterate, to learn what are the ideas that work and what doesn't. For example, one of the features I was really excited about and really proud of was build this website where multiple people could be logged into the website at the same time. So today, if you go to a website, if you are logged in and then I want to log in, you need to log out because it's the same browser, the same computer. But I thought, well, what if two people say you and me were watching a video together in front of a computer? What if a website could have you type your name and password, have me type my name and password, and then now the computer knows both of us are watching together and it gives both of us credit for anything we do as a group. Influencers feature rolled it out in a high school in San Francisco. We had about 20 something users. Where's the teacher there? Sacred Heart Cathedral Prep, the teacher is great. I mean, guess what? Zero people use this feature. It turns out people studying online, they want to watch the videos by themselves. So you can play back, pause at your own speed rather than in groups. So that was one example of a tiny lesson learned out of many that allowed us to hone into the set of features. It sounds like a brilliant feature. So I guess the lesson to take from that is there's something that looks amazing on paper and then nobody uses it. It doesn't actually have the impact that you think it might have. And so, yeah, I saw that you really went through a lot of different features and a lot of ideas to arrive at Coursera, the final kind of powerful thing that showed the world that MOOCs can educate millions. And I think with the whole machine learning movement as well, I think it didn't come out of nowhere. Instead, what happened was as more people learn about machine learning, they will tell their friends and their friends will see how it's applicable to their work. And then the community kept on growing. And I think we're still growing. I don't know in the future what percentage of all developers will be AI developers. I could easily see it being north of 50%, right? Because so many AI developers broadly construed, not just people doing the machine learning modeling, but the people building infrastructure, data pipelines, all the software surrounding the core machine learning model maybe is even bigger. I feel like today almost every software engineer has some understanding of the cloud. Not all, but maybe this is my microcontroller developer that doesn't need to deal with the cloud. But I feel like the vast majority of software engineers today are sort of having an appreciation of the cloud. I think in the future, maybe we'll approach nearly 100% of all developers being in some way an AI developer or at least having an appreciation of machine learning. And my hope is that there's this kind of effect that there's people who are not really interested in being a programmer or being into software engineering, like biologists, chemists, and physicists, even mechanical engineers, all these disciplines that are now more and more sitting on large data sets. And here they didn't think they're interested in programming until they have this data set and they realize there's this set of machine learning tools that allow you to use the data set. So they actually become, they learn to program and they become new programmers. So like the, not just because you've mentioned a larger percentage of developers become machine learning people. So it seems like more and more the kinds of people who are becoming developers is also growing significantly. Yeah, I think once upon a time, only a small part of humanity was literate, could read and write. And maybe you thought, maybe not everyone needs to learn to read and write. You just go listen to a few monks read to you and maybe that was enough. Or maybe you just need a few handful of authors to write the bestsellers and no one else needs to write. But what we found was that by giving as many people, in some countries, almost everyone, basic literacy, it dramatically enhanced human to human communications. And we can now write for an audience of one, such as if I send you an email or you send me an email. I think in computing, we're still in that phase where so few people know how to code that the coders mostly have to code for relatively large audiences. But if everyone, or most people became developers at some level, similar to how most people in developed economies are somewhat literate, I would love to see the owners of a mom and pop store be able to write a little bit of code to customize the TV display for their special this week. And I think it will enhance human to computer communications, which is becoming more and more important today as well. So you think it's possible that machine learning becomes kind of similar to literacy, where like you said, the owners of a mom and pop shop, is basically everybody in all walks of life would have some degree of programming capability? I could see society getting there. There's one other interesting thing. If I go talk to the mom and pop store, if I talk to a lot of people in their daily professions, I previously didn't have a good story for why they should learn to code. We could give them some reasons. But what I found with the rise of machine learning and data science is that I think the number of people with a concrete use for data science in their daily lives, in their jobs, may be even larger than the number of people who have concrete use for software engineering. For example, if you run a small mom and pop store, I think if you can analyze the data about your sales, your customers, I think there's actually real value there, maybe even more than traditional software engineering. So I find that for a lot of my friends in various professions, be it recruiters or accountants or people that work in the factories, which I deal with more and more these days, I feel if they were data scientists at some level, they could immediately use that in their work. So I think that data science and machine learning may be an even easier entree into the developer world for a lot of people than the software engineering. That's interesting. And I agree with that, but that's beautifully put. But we live in a world where most courses and talks have slides, PowerPoint, keynote, and yet you famously often still use a marker and a whiteboard. The simplicity of that is compelling, and for me at least, fun to watch. So let me ask, why do you like using a marker and whiteboard, even on the biggest of stages? I think it depends on the concepts you want to explain. For mathematical concepts, it's nice to build up the equation one piece at a time, and the whiteboard marker or the pen and stylus is a very easy way to build up the equation, to build up a complex concept one piece at a time while you're talking about it, and sometimes that enhances understandability. The downside of writing is that it's slow, and so if you want a long sentence, it's very hard to write that. So I think there are pros and cons, and sometimes I use slides, and sometimes I use a whiteboard or a stylus. The slowness of a whiteboard is also its upside, because it forces you to reduce everything to the basics. Some of your talks involve the whiteboard. I mean, you go very slowly, and you really focus on the most simple principles, and that's a beautiful, that enforces a kind of a minimalism of ideas that I think is surprising at least for me is great for education. Like a great talk, I think, is not one that has a lot of content. A great talk is one that just clearly says a few simple ideas, and I think the whiteboard somehow enforces that. Peter Abbeel, who's now one of the top roboticists and reinforcement learning experts in the world, was your first PhD student. So I bring him up just because I kind of imagine this must have been an interesting time in your life, and do you have any favorite memories of working with Peter, since you were your first student in those uncertain times, especially before deep learning really sort of blew up? Any favorite memories from those times? Yeah, I was really fortunate to have had Peter Abbeel as my first PhD student, and I think even my long term professional success builds on early foundations or early work that Peter was so critical to. So I was really grateful to him for working with me. What not a lot of people know is just how hard research was, and still is. Peter's PhD thesis was using reinforcement learning to fly helicopters. And so, even today, the website heli.stanford.edu, heli.stanford.edu is still up. You can watch videos of us using reinforcement learning to make a helicopter fly upside down, fly loose roses, so it's cool. It's one of the most incredible robotics videos ever, so people should watch it. Oh yeah, thank you. It's inspiring. That's from like 2008 or seven or six, like that range. Yeah, something like that. Yeah, so it was over 10 years old. That was really inspiring to a lot of people, yeah. What not many people see is how hard it was. So Peter and Adam Coase and Morgan Quigley and I were working on various versions of the helicopter, and a lot of things did not work. For example, it turns out one of the hardest problems we had was when the helicopter's flying around upside down, doing stunts, how do you figure out the position? How do you localize the helicopter? So we wanted to try all sorts of things. Having one GPS unit doesn't work because you're flying upside down, the GPS unit's facing down, so you can't see the satellites. So we experimented trying to have two GPS units, one facing up, one facing down. So if you flip over, that didn't work because the downward facing one couldn't synchronize if you're flipping quickly. Morgan Quigley was exploring this crazy, complicated configuration of specialized hardware like Google, Facebook, Baidu all these large sort of companies that already have huge teams of machine learning engineers you can also do with an industry sort of more research groups that kind of like Google Research, Google Brain then you can also do like we said a professor in academia and what else oh you can build your own company you can do a startup is there anything that stands out between those options or are they all beautiful different journeys that people should consider I think the thing that affects your experience more is less are you in this company versus that company or academia versus industry I think the thing that affects your experience most is who are the people you're interacting with in a daily basis so even if you look at some of the large companies the experience of individuals in different teams is very different and what matters most is not the logo above the door when you walk into the giant building every day what matters the most is who are the 10 people who are the 30 people you interact with every day so I actually tend to advise people if you get a job from a company ask who is your manager who are your peers who are you actually going to talk to we're all social creatures we tend to become more like the people around us and if you're working with great people you will learn faster or if you get admitted if you get a job at a great company or a great university maybe the logo you walk in is great but you're actually stuck on some team doing really work that doesn't excite you and then that's actually a really bad experience so this is true both for universities and for large companies for small companies you can kind of figure out who you'll be working with quite quickly and I tend to advise people if a company refuses to tell you who you will work with someone say oh join us the rotation system will figure it out I think that that's a worrying answer because it because it means you may not get sent to you may not actually get to a team with great peers and great people to work with it's actually a really profound advice that we kind of sometimes sweep we don't consider too rigorously or carefully the people around you are really often especially when you accomplish great things it seems the great things are accomplished because of the people around you so that's a it's not about the the where whether you learn this thing or that thing or like you said the logo that hangs up top it's the people that's a fascinating and it's such a hard search process of finding just like finding the right friends and somebody to get married with and that kind of thing it's a very hard search it's a people search problem yeah but I think when someone interviews you know at a university or the research lab or the large corporation it's good to insist on just asking who are the people who is my manager and if you refuse to tell me I'm gonna think well maybe that's because you don't have a good answer it may not be someone I like and if you don't particularly connect if something feels off with the people then don't stick to it you know that's a really important signal to consider yeah yeah and actually I actually in my standard class CS230 as well as an ACM talk I think I gave like a hour long talk on career advice including on the job search process and then some of these so you can find those videos online awesome and I'll point them I'll point people to them beautiful so the AI fund helps AI startups get off the ground or perhaps you can elaborate on all the fun things it's involved with what's your advice and how does one build a successful AI startup you know in Silicon Valley a lot of startup failures come from building other products that no one wanted so when you know cool technology but who's going to use it so I think I tend to be very outcome driven and customer obsessed ultimately we don't get to vote if we succeed or fail it's only the customer that they're the only one that gets a thumbs up or thumbs down vote in the long term in the short term you know there are various people that get various votes but in the long term that's what really matters so as you build the startup you have to constantly ask the question will the customer give a thumbs up on this I think so I think startups that are very customer focused customer obsessed deeply understand the customer and are oriented to serve the customer are more likely to succeed with the provisional I think all of us should only do things that we think create social good and moves the world forward so I personally don't want to build addictive digital products just to sell a lot of ads or you know there are things that could be lucrative that I won't do but if we can find ways to serve people in meaningful ways I think those can be great things to do either in the academic setting or in a corporate setting or a startup setting so can you give me the idea of why you started the AI fund I remember when I was leading the AI group at Baidu I had two jobs two parts of my job one was to build an AI engine to support the existing businesses and that was running just ran just performed by itself there was a second part of my job at the time which was to try to systematically initiate new lines of businesses using the company's AI capabilities so you know the self driving car team came out of my group the smart speaker team similar to what is Amazon Echo Alexa in the US but we actually announced it before Amazon did so Baidu wasn't following Amazon that came out of my group and I found that to be actually the most fun part of my job so what I wanted to do was to build AI fund as a startup studio to systematically create new startups from scratch with all the things we can now do with AI I think the ability to build new teams to go after this rich space of opportunities is a very important way to very important mechanism to get these projects done that I think will move the world forward so I've been fortunate to build a few teams that had a meaningful positive impact and I felt that we might be able to do this in a more systematic repeatable way so a startup studio is a relatively new concept there are maybe dozens of startup studios you know right now but I feel like all of us many teams are still trying to figure out how do you systematically build companies with a high success rate so I think even a lot of my you know venture capital friends are seem to be more and more building companies rather than investing in companies but I find a fascinating thing to do to figure out the mechanisms by which we could systematically build successful teams, successful businesses in areas that we find meaningful so a startup studio is something is a place and a mechanism for startups to go from zero to success to try to develop a blueprint it's actually a place for us to build startups from scratch so we often bring in founders and work with them or maybe even have existing ideas that we match founders with and then this launches you know hopefully into successful companies so how close are you to figuring out a way to automate the process of starting from scratch and building a successful AI startup yeah I think we've been constantly improving and iterating on our processes how we do that so things like you know how many customer calls do we need to make in order to get customer validation how do we make sure this technology can be built quite a lot of our businesses need cutting edge machine learning algorithms so you know kind of algorithms have developed in the last one or two years and even if it works in a research paper it turns out taking the production is really hard there are a lot of issues for making these things work in the real life that are not widely addressed in academia so how do we validate that this is actually doable how do you build a team get the specialized domain knowledge be it in education or health care whatever sector we're focusing on so I think we've actually getting we've been getting much better at giving the entrepreneurs a high success rate but I think we're still I think the whole world is still in the early phases of figuring this out but do you think there is some aspects of that process that are transferable from one startup to another to another to another yeah very much so you know starting from scratch you know starting a company to most entrepreneurs is a really lonely thing and I've seen so many entrepreneurs not know how to make certain decisions like when do you need to how do you do B2B sales right if you don't know that it's really hard or how do you market this efficiently other than you know buying ads which is really expensive are there more efficient tactics for that or for a machine learning project you know basic decisions can change the course of whether machine learning product works or not and so there are so many hundreds of decisions that entrepreneurs need to make and making a mistake and a couple key decisions can have a huge impact on the fate of the company so I think a startup studio provides a support structure that makes starting a company much less of a lonely experience and also when facing with these key decisions like trying to hire your first uh the VP of engineering what's a good selection criteria how do you solve should I hire this person or not by helping by having a ecosystem around the entrepreneurs the founders to help I think we help them at the key moments and hopefully significantly make them more enjoyable and then higher success rate so there's somebody to brainstorm with in these very difficult decision points and also to help them recognize what they may not even realize is a key decision point that's that's the first and probably the most important part yeah actually I can say one other thing um you know I think building companies is one thing but I feel like it's really important that we build companies that move the world forward for example within the AI Fund team there was once an idea for a new company that if it had succeeded would have resulted in people watching a lot more videos in a certain narrow vertical type of video um I looked at it the business case was fine the revenue case was fine but I looked and just said I don't want to do this like you know I don't actually just want to have a lot more people watch this type of video wasn't educational it's an educational baby and so and so I I I I code the idea on the basis that I didn't think it would actually help people so um whether building companies or working enterprises or doing personal projects I think um it's up to each of us to figure out what's the difference we want to make in the world With landing AI you help already established companies grow their AI and machine learning efforts how does a large company integrate machine learning into their efforts? AI is a general purpose technology and I think it will transform every industry our community has already transformed to a large extent the software internet sector most software internet companies outside the top right five or six or three or four already have reasonable machine learning capabilities or or getting there it's still room for improvement but when I look outside the software internet sector everything from manufacturing agriculture, healthcare logistics transportation there's so many opportunities that very few people are working on so I think the next wave of AI is for us to also transform all of those other industries there was a McKinsey study estimating 13 trillion dollars of global economic growth US GDP is 19 trillion dollars so 13 trillion is a big number or PwC estimates 16 trillion dollars so whatever number is is large but the interesting thing to me was a lot of that impact will be outside the software internet sector so we need more teams to work with these companies to help them adopt AI and I think this is one thing so make you know help drive global economic growth and make humanity more powerful and like you said the impact is there so what are the best industries the biggest industries where AI can help perhaps outside the software tech sector frankly I think it's all of them some of the ones I'm spending a lot of time on are manufacturing agriculture look into healthcare for example in manufacturing we do a lot of work in visual inspection where today there are people standing around using the eye human eye to check if you know this plastic part or the smartphone or this thing has a scratch or a dent or something in it we can use a camera to take a picture use a algorithm deep learning and other things to check if it's defective or not and thus help factories improve yield and improve quality and improve throughput it turns out the practical problems we run into are very different than the ones you might read about in in most research papers the data sets are really small so we face small data problems you know the factories keep on changing the environment so it works well on your test set but guess what something changes in the factory the lights go on or off recently there was a factory in which a bird threw through the factory and pooped on something and so that changed stuff and so increasing our algorithm makes robustness so all the changes happen in the factory I find that we run a lot of practical problems that are not as widely discussed in academia and it's really fun kind of being on the cutting edge solving these problems before maybe before many people are even aware that there is a problem there and that's such a fascinating space you're absolutely right but what is the first step that a company should take it's just scary leap into this new world of going from the human eye inspecting to digitizing that process having a camera having an algorithm what's the first step like what's the early journey that you recommend that you see these companies taking I published a document called the AI Transformation Playbook that's online and taught briefly in the AI for Everyone course on Coursera about the long term journey that companies should take but the first step is actually to start small I've seen a lot more companies fail by starting too big than by starting too small take even Google you know most people don't realize how hard it was and how controversial it was in the early days so when I started Google Brain it was controversial you know people thought deep learning near nest tried it didn't work why would you want to do deep learning so my first internal customer within Google was the Google speech team which is not the most lucrative project in Google not the most important it's not web search or advertising but by starting small my team helped the speech team build a more accurate speech recognition system and this caused their peers other teams to start to have more faith in deep learning my second internal customer was the Google Maps team where we used computer vision to read house numbers from basic street view images to more accurately locate houses within Google Maps so improve the quality of geodata and it was only after those two successes that I then started a more serious conversation with the Google Ads team and so there's a ripple effect that you showed that it works in these cases and then it just propagates through the entire company that this thing has a lot of value and use for us I think the early small scale projects it helps the teams gain faith but also helps the teams learn what these technologies do I still remember when our first GPU server it was a server under some guy's desk and you know and then that taught us early important lessons about how do you have multiple users share a set of GPUs which is really not obvious at the time but those early lessons were important we learned a lot from that first GPU server that later helped the teams think through how to scale it up to much larger deployments Are there concrete challenges that companies face that you see is important for them to solve? I think building and deploying machine learning systems is hard there's a huge gulf between something that works in a jupyter notebook on your laptop versus something that runs their production deployment setting in a factory or agriculture plant or whatever so I see a lot of people get something to work on your laptop and say wow look what I've done and that's great that's hard that's a very important first step but a lot of teams underestimate the rest of the steps needed so for example I've heard this exact same conversation between a lot of machine learning people and business people the machine learning person says look my algorithm does well on the test set and it's a clean test set at the end of peak and the machine and the business person says thank you very much but your algorithm sucks it doesn't work and the machine learning person says no wait I did well on the test set and I think there is a gulf between what it takes to do well on the test set on your hard drive versus what it takes to work well in a deployment setting some common problems robustness and generalization you deploy something in the factory maybe they chop down a tree outside the factory so the tree no longer covers the window and the lighting is different so the test set changes and in machine learning and especially in academia we don't know how to deal with test set distributions that are dramatically different than the training set distribution you know that this research the stuff like domain annotation transfer learning you know there are people working on it but we're really not good at this so how do you actually get this to work because your test set distribution is going to change and I think also if you look at the number of lines of code in the software system the machine learning model is maybe five percent or even fewer relative to the entire software system you need to build so how do you get all that work done and make it reliable and systematic so good software engineering work is fundamental here to building a successful small machine learning system yes and the software system needs to interface with the machine learning system needs to interface with people's workloads so machine learning is automation on steroids if we take one task out of many tasks that are done in the factory so the factory does lots of things one task is vision inspection if we automate that one task it can be really valuable but you may need to redesign a lot of other tasks around that one task for example say the machine learning algorithm says this is defective what are you supposed to do do you throw it away do you get a human to double check do you want to rework it or fix it so you need to redesign a lot of tasks around that thing you've now automated so planning for the change management and making sure that the software you write is consistent with the new workflow and you take the time to explain to people what needs to happen so I think what landing AI has become good at and then I think we learned by making the steps and you know painful experiences well my what would become good at is working with our partners to think through all the things beyond just the machine learning model or running the jupyter notebook but to build the entire system manage the change process and figure out how to deploy this in a way that has an actual impact the processes that the large software tech companies use for deploying don't work for a lot of other scenarios for example when I was leading large speech teams if the speech recognition system goes down what happens well alarms goes off and then someone like me would say hey you 20 engine environment you 20 engineers please fix this but if you have a system girl in the factory there are not 20 machine learning engineers sitting around you can page your duty and have them fix it so how do you deal with the maintenance or the or the dev ops or the mo ops or the other aspects of this so these are concepts that I think landing AI and a few other teams on the cutting edge but we don't even have systematic terminology yet to describe some of the stuff we do because I think we're inventing it on the fly. So you mentioned some people are interested in discovering mathematical beauty and truth in the universe and you're interested in having a big positive impact in the world so let me ask the two are not inconsistent no they're all together I'm only half joking because you're probably interested a little bit in both but let me ask a romanticized question so much of the work your work and our discussion today has been on applied AI maybe you can even call narrow AI where the goal is to create systems that automate some specific process that adds a lot of value to the world but there's another branch of AI starting with Alan Turing that kind of dreams of creating human level or superhuman level intelligence is this something you dream of as well do you think we human beings will ever build a human level intelligence or superhuman level intelligence system? I would love to get to AGI and I think humanity will but whether it takes 100 years or 500 or 5000 I find hard to estimate do you have some folks have worries about the different trajectories that path would take even existential threats of an AGI system do you have such concerns whether in the short term or the long term? I do worry about the long term fate of humanity I do wonder as well I do worry about overpopulation on the planet Mars just not today I think there will be a day when maybe someday in the future Mars will be polluted there are all these children dying and someone will look back at this video and say Andrew how is Andrew so heartless? He didn't care about all these children dying on the planet Mars and I apologize to the future viewer I do care about the children but I just don't know how to productively work on that today your picture will be in the dictionary for the people who are ignorant about the overpopulation on Mars yes so it's a long term problem is there something in the short term we should be thinking about in terms of aligning the values of our AI systems with the values of us humans sort of something that Stuart Russell and other folks are thinking about as this system develops more and more we want to make sure that it represents the better angels of our nature the ethics the values of our society you know if you take self driving cars the biggest problem with self driving cars is not that there's some trolley dilemma and you teach this so you know how many times when you are driving your car did you face this moral dilemma who do I crash into? so I think self driving cars will run into that problem roughly as often as we do when we drive our cars the biggest problem with self driving cars is when there's a big white truck across the road and what you should do is break and not crash into it and the self driving car fails and it crashes into it so I think we need to solve that problem first I think the problem with some of these discussions about AGI you know alignments the paperclip problem is that is a huge distraction from the much harder problems that we actually need to address today it's not the hardest problems we need to address today it's not the hard problems we need to address today I think bias is a huge issue I worry about wealth and equality the AI and internet are causing an acceleration of concentration of power because we can now centralize data use AI to process it and so industry after industry we've affected every industry so the internet industry has a lot of win and take most or win and take all dynamics but we've infected all these other industries so we're also giving these other industries most of them to take all flavors so look at what Uber and Lyft did to the taxi industry so we're doing this type of thing it's a lot and so this so we're creating tremendous wealth but how do we make sure that the wealth is fairly shared I think that and then how do we help people whose jobs are displaced you know I think education is part of it there may be even more that we need to do than education I think bias is a serious issue there are adverse uses of AI like deepfakes being used for various and various purposes so I worry about some teams maybe accidentally and I hope not deliberately making a lot of noise about things that problems in the distant future rather than focusing on some of the much harder problems yeah the overshadow of the problems that we have already today they're exceptionally challenging like those you said and even the silly ones but the ones that have a huge impact huge impact which is the lighting variation outside of your factory window that that ultimately is what makes the difference between like you said the Jupiter notebook and something that actually transforms an entire industry potentially yeah and I think and then just to some companies or a regulator comes to you and says look your product is messing things up fixing it may have a revenue impact well it's much more fun to talk to them about how you promise not to wipe out humanity and to face the actually really hard problems we face so your life has been a great journey from teaching to research to entrepreneurship two questions one are there regrets moments that if you went back you would do differently and two are there moments you're especially proud of moments that made you truly happy you know I've made so many mistakes it feels like every time I discover something I go why didn't I think of this you know five years earlier or even 10 years earlier and as recently and then sometimes I read a book and I go I wish I read this book 10 years ago my life would have been so different although that happened recently and then I was thinking if only I read this book when we're starting up Coursera I could have been so much better but I discovered the book had not yet been written we're starting Coursera so that made me feel better so that made me feel better but I find that the process of discovery we keep on finding out things that seem so obvious in hindsight but it always takes us so much longer than than I wish to to figure it out so on the second question are there moments in your life that if you look back that you're especially proud of or you're especially happy what would be the that filled you with happiness and fulfillment well two answers one does my daughter know of her yes of course because I know how much time I spent with her I just can't spend enough time with her congratulations by the way thank you and then second is helping other people I think to me I think the meaning of life is helping others achieve whatever are their dreams and then also to try to move the world forward making humanity more powerful as a whole so the times that I felt most happy most proud was when I felt someone else allowed me the good fortune of helping them a little bit on the path to their dreams I think there's no better way to end it than talking about happiness and the meaning of life so Andrew it's a huge honor me and millions of people thank you for all the work you've done thank you for talking today thank you so much thanks thanks for listening to this conversation with Andrew Ng and thank you to our presenting sponsor Cash App download it use code LEX podcast you'll get ten dollars and ten dollars will go to FIRST an organization that inspires and educates young minds to become science and technology innovators of tomorrow if you enjoy this podcast subscribe on YouTube give it five stars on Apple podcast support it on Patreon or simply connect with me on Twitter at LEX Freedman and now let me leave you with some words of wisdom from Andrew Ng ask yourself if what you're working on succeeds beyond your wildest dreams would you have significantly helped other people? if not then keep searching for something else to work on otherwise you're not living up to your full potential thank you for listening and hope to see you next time to interpret GPS signals. Looking at the FPG is completely insane. Spent about a year working on that, didn't work. So I remember Peter, great guy, him and me, sitting down in my office looking at some of the latest things we had tried that didn't work and saying, done it, what now? Because we tried so many things and it just didn't work. In the end, what we did, and Adam Coles was crucial to this, was put cameras on the ground and use cameras on the ground to localize the helicopter. And that solved the localization problem so that we could then focus on the reinforcement learning and inverse reinforcement learning techniques so it didn't actually make the helicopter fly. And I'm reminded, when I was doing this work at Stanford, around that time, there was a lot of reinforcement learning theoretical papers, but not a lot of practical applications. So the autonomous helicopter work for flying helicopters was one of the few practical applications of reinforcement learning at the time, which caused it to become pretty well known. I feel like we might have almost come full circle with today. There's so much buzz, so much hype, so much excitement about reinforcement learning. But again, we're hunting for more applications of all of these great ideas that David Kuhnke has come up with. What was the drive sort of in the face of the fact that most people are doing theoretical work? What motivates you in the uncertainty and the challenges to get the helicopter sort of to do the applied work, to get the actual system to work? Yeah, in the face of fear, uncertainty, sort of the setbacks that you mentioned for localization. I like stuff that works. In the physical world. So like, it's back to the shredder. You know, I like theory, but when I work on theory myself, and this is personal taste, I'm not saying anyone else should do what I do. But when I work on theory, I personally enjoy it more if I feel that the work I do will influence people, have positive impact, or help someone. I remember when many years ago, I was speaking with a mathematics professor, and it kind of just said, hey, why do you do what you do? It kind of just said, hey, why do you do what you do? And then he said, he had stars in his eyes when he answered. And this mathematician, not from Stanford, different university, he said, I do what I do because it helps me to discover truth and beauty in the universe. He had stars in his eyes when he said that. And I thought, that's great. I don't want to do that. I think it's great that someone does that, fully support the people that do it, a lot of respect for people that do that. But I am more motivated when I can see a line to how the work that my teams and I are doing helps people. The world needs all sorts of people. I'm just one type. I don't think everyone should do things the same way as I do. But when I delve into either theory or practice, if I personally have conviction that here's a pathway to help people, I find that more satisfying to have that conviction. That's your path. You were a proponent of deep learning before it gained widespread acceptance. What did you see in this field that gave you confidence? What was your thinking process like in that first decade of the, I don't know what that's called, 2000s, the aughts? Yeah, I can tell you the thing we got wrong and the thing we got right. The thing we really got wrong was the importance of, the early importance of unsupervised learning. So early days of Google Brain, we put a lot of effort into unsupervised learning rather than supervised learning. And there was this argument, I think it was around 2005 after NeurIPS, at that time called NIPS, but now NeurIPS had ended. And Jeff Hinton and I were sitting in the cafeteria outside the conference. We had lunch, we were just chatting. And Jeff pulled up this napkin. He started sketching this argument on a napkin. It was very compelling, as I'll repeat it. Human brain has about a hundred trillion. So there's 10 to the 14 synaptic connections. You will live for about 10 to the nine seconds. That's 30 years. You actually live for two by 10 to the nine, maybe three by 10 to the nine seconds. So just let's say 10 to the nine. So if each synaptic connection, each weight in your brain's neural network has just a one bit parameter, that's 10 to the 14 bits you need to learn in up to 10 to the nine seconds. 10 to the nine seconds of your life. So via this simple argument, which is a lot of problems, it's very simplified. That's 10 to the five bits per second you need to learn in your life. And I have a one year old daughter. I am not pointing out 10 to five bits per second of labels to her. And I think I'm a very loving parent, but I'm just not gonna do that. So from this very crude, definitely problematic argument, there's just no way that most of what we know is through supervised learning. But where you get so many bits of information is from sucking in images, audio, those experiences in the world. And so that argument, and there are a lot of known forces argument you should go into, really convinced me that there's a lot of power to unsupervised learning. So that was the part that we actually maybe got wrong. I still think unsupervised learning is really important, but in the early days, 10, 15 years ago, a lot of us thought that was the path forward. Oh, so you're saying that that perhaps was the wrong intuition for the time. For the time, that was the part we got wrong. The part we got right was the importance of scale. So Adam Coates, another wonderful person, fortunate to have worked with him, he was in my group at Stanford at the time and Adam had run these experiments at Stanford showing that the bigger we train a learning algorithm, the better its performance. And it was based on that. There was a graph that Adam generated where the X axis, Y axis lines going up into the right. So the bigger you make this thing, the better its performance accuracy is the vertical axis. So it's really based on that chart that Adam generated that he gave me the conviction that you could scale these models way bigger than what we could on a few CPUs, which is where we had at Stanford that we could get even better results. And it was really based on that one figure that Adam generated that gave me the conviction to go with Sebastian Thrun to pitch starting a project at Google, which became the Google Brain project. The Brain, you go find a Google Brain. And there the intuition was scale will bring performance for the system. So we should chase a larger and larger scale. And I think people don't realize how groundbreaking of it. It's simple, but it's a groundbreaking idea that bigger data sets will result in better performance. It was controversial at the time. Some of my well meaning friends, senior people in the machine learning community, I won't name, but some of whom we know, my well meaning friends came and were trying to give me friendly, I was like, hey, Andrew, why are you doing this? This is crazy. It's in the near natural architecture. Look at these architectures of building. You just want to go for scale? Like this is a bad career move. So my well meaning friends, some of them were trying to talk me out of it. But I find that if you want to make a breakthrough, you sometimes have to have conviction and do something before it's popular, since that lets you have a bigger impact. Let me ask you just a small tangent on that topic. I find myself arguing with people saying that greater scale, especially in the context of active learning, so very carefully selecting the data set, but growing the scale of the data set is going to lead to even further breakthroughs in deep learning. And there's currently pushback at that idea that larger data sets are no longer, so you want to increase the efficiency of learning. You want to make better learning mechanisms. And I personally believe that bigger data sets will still, with the same learning methods we have now, will result in better performance. What's your intuition at this time on this dual side? Do we need to come up with better architectures for learning or can we just get bigger, better data sets that will improve performance? I think both are important and it's also problem dependent. So for a few data sets, we may be approaching a Bayes error rate or approaching or surpassing human level performance and then there's that theoretical ceiling that we will never surpass, so Bayes error rate. But then I think there are plenty of problems where we're still quite far from either human level performance or from Bayes error rate and bigger data sets with neural networks without further algorithmic innovation will be sufficient to take us further. But on the flip side, if we look at the recent breakthroughs using transforming networks or language models, it was a combination of novel architecture but also scale had a lot to do with it. If we look at what happened with GP2 and BERTZ, I think scale was a large part of the story. Yeah, that's not often talked about is the scale of the data set it was trained on and the quality of the data set because there's some, so it was like reddit threads that had, they were operated highly. So there's already some weak supervision on a very large data set that people don't often talk about, right? I find that today we have maturing processes to managing code, things like Git, right? Version control. It took us a long time to evolve the good processes. I remember when my friends and I were emailing each other C++ files in email, but then we had, was it CVS or version Git? Maybe something else in the future. We're very mature in terms of tools for managing data and think about the clean data and how to solve down very hot, messy data problems. I think there's a lot of innovation there to be had still. I love the idea that you were versioning through email. I'll give you one example. When we work with manufacturing companies, it's not at all uncommon for there to be multiple labels that disagree with each other, right? And so we would do the work in visual inspection. We will take, say, a plastic part and show it to one inspector and the inspector, sometimes very opinionated, they'll go, clearly, that's a defect. This scratch, unacceptable. Gotta reject this part. Take the same part to different inspector, different, very opinionated. Clearly, the scratch is small. It's fine. Don't throw it away. You're gonna make us, you know. And then sometimes you take the same plastic part, show it to the same inspector in the afternoon, I suppose, in the morning, and very opinionated go, in the morning, they say, clearly, it's okay. In the afternoon, equally confident. Clearly, this is a defect. And so what is an AI team supposed to do if sometimes even one person doesn't agree with himself or herself in the span of a day? So I think these are the types of very practical, very messy data problems that my teams wrestle with. In the case of large consumer internet companies where you have a billion users, you have a lot of data. You don't worry about it. Just take the average. It kind of works. But in a case of other industry settings, we don't have big data. If just a small data, very small data sets, maybe around 100 defective parts or 100 examples of a defect. If you have only 100 examples, these little labeling errors, if 10 of your 100 labels are wrong, that actually is 10% of your data set has a big impact. So how do you clean this up? What are you supposed to do? This is an example of the types of things that my teams, this is a landing AI example, are wrestling with to deal with small data, which comes up all the time once you're outside consumer internet. Yeah, that's fascinating. So then you invest more effort and time in thinking about the actual labeling process. What are the labels? What are the how are disagreements resolved and all those kinds of like pragmatic real world problems. That's a fascinating space. Yeah, I find that actually when I'm teaching at Stanford, I increasingly encourage students at Stanford to try to find their own project for the end of term project, rather than just downloading someone else's nicely clean data set. It's actually much harder if you need to go and define your own problem and find your own data set, rather than you go to one of the several good websites, very good websites with clean scoped data sets that you could just work on. You're now running three efforts, the AI Fund, Landing AI, and deeplearning.ai. As you've said, the AI Fund is involved in creating new companies from scratch. Landing AI is involved in helping already established companies do AI and deeplearning.ai is for education of everyone else or of individuals interested in getting into the field and excelling in it. So let's perhaps talk about each of these areas. First, deeplearning.ai. How, the basic question, how does a person interested in deep learning get started in the field? Deep learning.ai is working to create courses to help people break into AI. So my machine learning course that I taught through Stanford is one of the most popular courses on Coursera. To this day, it's probably one of the courses, sort of, if I asked somebody, how did you get into machine learning or how did you fall in love with machine learning or would get you interested, it always goes back to Andrew Ng at some point. I see, yeah, I'm sure. You've influenced, the amount of people you've influenced is ridiculous. So for that, I'm sure I speak for a lot of people say big thank you. No, yeah, thank you. I was once reading a news article, I think it was tech review and I'm gonna mess up the statistic, but I remember reading an article that said something like one third of all programmers are self taught. I may have the number one third, around me was two thirds, but when I read that article, I thought this doesn't make sense. Everyone is self taught. So, cause you teach yourself. I don't teach people. That's well put. Yeah, so how does one get started in deep learning and where does deeplearning.ai fit into that? So the deep learning specialization offered by deeplearning.ai is I think it was Coursera's top specialization. It might still be. So it's a very popular way for people to take that specialization to learn about everything from neural networks to how to tune in your network to what is a ConvNet to what is a RNN or a sequence model or what is an attention model. And so the deep learning specialization steps everyone through those algorithms so you deeply understand it and can implement it and use it for whatever application. From the very beginning. So what would you say are the prerequisites for somebody to take the deep learning specialization in terms of maybe math or programming background? Yeah, need to understand basic programming since there are programming exercises in Python and the math prereq is quite basic. So no calculus is needed. If you know calculus is great, you get better intuitions but deliberately try to teach that specialization without requiring calculus. So I think high school math would be sufficient. If you know how to multiply two matrices, I think that's great. So a little basic linear algebra is great. Basic linear algebra, even very, very basic linear algebra in some programming. I think that people that have done the machine learning course will find a deep learning specialization a bit easier but it's also possible to jump into the deep learning specialization directly but it will be a little bit harder since we tend to go over faster concepts like how does gradient descent work and what is the objective function which is covered more slowly in the machine learning course. Could you briefly mention some of the key concepts in deep learning that students should learn that you envision them learning in the first few months in the first year or so? So if you take the deep learning specialization, you learn the foundations of what is a neural network. How do you build up a neural network from a single logistic unit to a stack of layers to different activation functions. You learn how to train the neural networks. One thing I'm very proud of in that specialization is we go through a lot of practical knowhow of how to actually make these things work. So what are the differences between different optimization algorithms? What do you do if the algorithm overfits or how do you tell if the algorithm is overfitting? When do you collect more data? When should you not bother to collect more data? I find that even today, unfortunately, there are engineers that will spend six months trying to pursue a particular direction such as collect more data because we heard more data is valuable but sometimes you could run some tests and could have figured out six months earlier that for this particular problem, collecting more data isn't going to cut it. So just don't spend six months collecting more data. Spend your time modifying the architecture or trying something else. So go through a lot of the practical knowhow so that when someone, when you take the deep learning specialization, you have those skills to be very efficient in how you build these networks. So dive right in to play with the network, to train it, to do the inference on a particular data set, to build intuition about it without building it up too big to where you spend, like you said, six months learning, building up your big project without building any intuition of a small aspect of the data that could already tell you everything you need to know about that data. Yes, and also the systematic frameworks of thinking for how to go about building practical machine learning. Maybe to make an analogy, when we learn to code, we have to learn the syntax of some programming language, right? Be it Python or C++ or Octave or whatever. But the equally important or maybe even more important part of coding is to understand how to string together these lines of code into coherent things. So when should you put something in a function column? When should you not? How do you think about abstraction? So those frameworks are what makes a programmer efficient even more than understanding the syntax. I remember when I was an undergrad at Carnegie Mellon, one of my friends would debug their code by first trying to compile it, and then it was C++ code. And then every line in the syntax error, they want to get rid of the syntax errors as quickly as possible. So how do you do that? Well, they would delete every single line of code with a syntax error. So really efficient for getting rid of syntax errors for horrible debugging errors. So I think we learn how to debug. And I think in machine learning, the way you debug a machine learning program is very different than the way you do binary search or whatever, or use a debugger, trace through the code in traditional software engineering. So it's an evolving discipline, but I find that the people that are really good at debugging machine learning algorithms are easily 10x, maybe 100x faster at getting something to work. And the basic process of debugging is, so the bug in this case, why isn't this thing learning, improving, sort of going into the questions of overfitting and all those kinds of things? That's the logical space that the debugging is happening in with neural networks. Yeah, often the question is, why doesn't it work yet? Or can I expect it to eventually work? And what are the things I could try? Change the architecture, more data, more regularization, different optimization algorithm, different types of data. So to answer those questions systematically, so that you don't spend six months hitting down the blind alley before someone comes and says, why did you spend six months doing this? What concepts in deep learning do you think students struggle the most with? Or sort of is the biggest challenge for them was to get over that hill. It hooks them and it inspires them and they really get it. Similar to learning mathematics, I think one of the challenges of deep learning is that there are a lot of concepts that build on top of each other. If you ask me what's hard about mathematics, I have a hard time pinpointing one thing. Is it addition, subtraction? Is it a carry? Is it multiplication? There's just a lot of stuff. I think one of the challenges of learning math and of learning certain technical fields is that there are a lot of concepts and if you miss a concept, then you're kind of missing the prerequisite for something that comes later. So in the deep learning specialization, try to break down the concepts to maximize the odds of each component being understandable. So when you move on to the more advanced thing, we learn confidence, hopefully you have enough intuitions from the earlier sections to then understand why we structure confidence in a certain way and then eventually why we built RNNs and LSTMs or attention models in a certain way building on top of the earlier concepts. Actually, I'm curious, you do a lot of teaching as well. Do you have a favorite, this is the hard concept moment in your teaching? Well, I don't think anyone's ever turned the interview on me. I'm glad you get first. I think that's a really good question. Yeah, it's really hard to capture the moment when they struggle. I think you put it really eloquently. I do think there's moments that are like aha moments that really inspire people. I think for some reason, reinforcement learning, especially deep reinforcement learning is a really great way to really inspire people and get what the use of neural networks can do. Even though neural networks really are just a part of the deep RL framework, but it's a really nice way to paint the entirety of the picture of a neural network being able to learn from scratch, knowing nothing and explore the world and pick up lessons. I find that a lot of the aha moments happen when you use deep RL to teach people about neural networks, which is counterintuitive. I find like a lot of the inspired sort of fire in people's passion, people's eyes, it comes from the RL world. Do you find reinforcement learning to be a useful part of the teaching process or no? I still teach reinforcement learning in one of my Stanford classes and my PhD thesis was on reinforcement learning. So I clearly loved a few. I find that if I'm trying to teach students the most useful techniques for them to use today, I end up shrinking the amount of time I talk about reinforcement learning. It's not what's working today. Now, our world changes so fast. Maybe this will be totally different in a couple of years. But I think we need a couple more things for reinforcement learning to get there. One of my teams is looking to reinforcement learning for some robotic control tasks. So I see the applications, but if you look at it as a percentage of all of the impact of the types of things we do, it's at least today outside of playing video games, right? In a few of the games, the scope. Actually, at NeurIPS, a bunch of us were standing around saying, hey, what's your best example of an actual deploy reinforcement learning application? And among like senior machine learning researchers, right? And again, there are some emerging ones, but there are not that many great examples. I think you're absolutely right. The sad thing is there hasn't been a big impactful real world application of reinforcement learning. I think its biggest impact to me has been in the toy domain, in the game domain, in the small example. That's what I mean for educational purpose. It seems to be a fun thing to explore in your networks with. But I think from your perspective, and I think that might be the best perspective is if you're trying to educate with a simple example in order to illustrate how this can actually be grown to scale and have a real world impact, then perhaps focusing on the fundamentals of supervised learning in the context of a simple data set, even like an MNIST data set is the right way, is the right path to take. The amount of fun I've seen people have with reinforcement learning has been great, but not in the applied impact in the real world setting. So it's a trade off, how much impact you want to have versus how much fun you want to have. Yeah, that's really cool. And I feel like the world actually needs all sorts. Even within machine learning, I feel like deep learning is so exciting, but the AI team shouldn't just use deep learning. I find that my teams use a portfolio of tools. And maybe that's not the exciting thing to say, but some days we use a neural net, some days we use a PCA. Actually, the other day, I was sitting down with my team looking at PCA residuals, trying to figure out what's going on with PCA applied to manufacturing problem. And some days we use a probabilistic graphical model, some days we use a knowledge draft, which is one of the things that has tremendous industry impact. But the amount of chatter about knowledge drafts in academia is really thin compared to the actual real world impact. So I think reinforcement learning should be in that portfolio. And then it's about balancing how much we teach all of these things. And the world should have diverse skills. It'd be sad if everyone just learned one narrow thing. Yeah, the diverse skill help you discover the right tool for the job. What is the most beautiful, surprising or inspiring idea in deep learning to you? Something that captivated your imagination. Is it the scale that could be, the performance that could be achieved with scale? Or is there other ideas? I think that if my only job was being an academic researcher, if an unlimited budget and didn't have to worry about short term impact and only focus on long term impact, I'd probably spend all my time doing research on unsupervised learning. I still think unsupervised learning is a beautiful idea. At both this past NeurIPS and ICML, I was attending workshops or listening to various talks about self supervised learning, which is one vertical segment maybe of unsupervised learning that I'm excited about. Maybe just to summarize the idea, I guess you know the idea about describing fleet. No, please. So here's the example of self supervised learning. Let's say we grab a lot of unlabeled images off the internet. So with infinite amounts of this type of data, I'm going to take each image and rotate it by a random multiple of 90 degrees. And then I'm going to train a supervised neural network to predict what was the original orientation. So it has to be rotated 90 degrees, 180 degrees, 270 degrees, or zero degrees. So you can generate an infinite amounts of labeled data because you rotated the image so you know what's the ground truth label. And so various researchers have found that by taking unlabeled data and making up labeled data sets and training a large neural network on these tasks, you can then take the hidden layer representation and transfer it to a different task very powerfully. Learning word embeddings where we take a sentence, delete a word, predict the missing word, which is how we learn. One of the ways we learn word embeddings is another example. And I think there's now this portfolio of techniques for generating these made up tasks. Another one called jigsaw would be if you take an image, cut it up into a three by three grid, so like a nine, three by three puzzle piece, jump up the nine pieces and have a neural network predict which of the nine factorial possible permutations it came from. So many groups, including OpenAI, Peter B has been doing some work on this too, Facebook, Google Brain, I think DeepMind, oh actually, Aaron van der Oort has great work on the CPC objective. So many teams are doing exciting work and I think this is a way to generate infinite label data and I find this a very exciting piece of unsupervised learning. So long term you think that's going to unlock a lot of power in machine learning systems is this kind of unsupervised learning. I don't think there's a whole enchilada, I think it's just a piece of it and I think this one piece unsupervised, self supervised learning is starting to get traction. We're very close to it being useful. Well, word embedding is really useful. I think we're getting closer and closer to just having a significant real world impact maybe in computer vision and video but I think this concept and I think there'll be other concepts around it. You know, other unsupervised learning things that I worked on I've been excited about. I was really excited about sparse coding and ICA, slow feature analysis. I think all of these are ideas that various of us were working on about a decade ago before we all got distracted by how well supervised learning was doing. So we would return we would return to the fundamentals of representation learning that really started this movement of deep learning. I think there's a lot more work that one could explore around this theme of ideas and other ideas to come up with better algorithms. So if we could return to maybe talk quickly about the specifics of deep learning.ai the deep learning specialization perhaps how long does it take to complete the course would you say? The official length of the deep learning specialization is I think 16 weeks so about four months but it's go at your own pace. So if you subscribe to the deep learning specialization there are people that finished it in less than a month by working more intensely and studying more intensely so it really depends on on the individual. When we created the deep learning specialization we wanted to make it very accessible and very affordable. And with you know Coursera and deep learning.ai education mission one of the things that's really important to me is that if there's someone for whom paying anything is a financial hardship then just apply for financial aid and get it for free. If you were to recommend a daily schedule for people in learning whether it's through the deep learning.ai specialization or just learning in the world of deep learning what would you recommend? How do they go about day to day sort of specific advice about learning about their journey in the world of deep learning machine learning? I think getting the habit of learning is key and that means regularity. So for example we send out a weekly newsletter the batch every Wednesday so people know it's coming Wednesday you can spend a little bit of time on Wednesday catching up on the latest news catching up on the latest news through the batch on Wednesday and for myself I've picked up a habit of spending some time every Saturday and every Sunday reading or studying and so I don't wake up on the Saturday and have to make a decision do I feel like reading or studying today or not it's just what I do and the fact is a habit makes it easier. So I think if someone can get into that habit it's like you know just like we brush our teeth every morning I don't think about it if I thought about it it's a little bit annoying to have to spend two minutes doing that but it's a habit that it takes no cognitive load but this would be so much harder if we have to make a decision every morning and actually that's the reason why I wear the same thing every day as well it's just one less decision I just get up and wear my blue shirt so but I think if you can get that habit that consistency of studying then it actually feels easier. So yeah it's kind of amazing in my own life like I play guitar every day for I force myself to at least for five minutes play guitar it's just it's a ridiculously short period of time but because I've gotten into that habit it's incredible what you can accomplish in a period of a year or two years you can become you know exceptionally good at certain aspects of a thing by just doing it every day for a very short period of time it's kind of a miracle that that's how it works it adds up over time. Yeah and I think this is often not about the bursts of sustained efforts and the all nighters because you could only do that a limited number of times it's the sustained effort over a long time I think you know reading two research papers is a nice thing to do but the power is not reading two research papers it's reading two research papers a week for a year then you read a hundred papers and you actually learn a lot when you read a hundred papers. So regularity and making learning a habit do you have general other study tips for particularly deep learning that people should in their process of learning is there some kind of recommendations or tips you have as they learn? One thing I still do when I'm trying to study something really deeply is take handwritten notes it varies I know there are a lot of people that take the deep learning courses during a commute or something where it may be more awkward to take notes so I know it may not work for everyone but when I'm taking courses on Coursera and I still take some every now and then the most recent one I took was a course on clinical trials because I was interested about that I got out my little Moleskine notebook and what I was seeing on my desk was just taking down notes so what the instructor was saying and that act we know that that act of taking notes preferably handwritten notes increases retention. So as you're sort of watching the video just kind of pausing maybe and then taking the basic insights down on paper. Yeah so there have been a few studies if you search online you find some of these studies that taking handwritten notes because handwriting is slower as we're saying just now it causes you to recode the knowledge in your own words more and that process of recoding promotes long term retention this is as opposed to typing which is fine again typing is better than nothing or in taking a class and not taking notes is better than not taking any class at all but comparing handwritten notes and typing you can usually type faster for a lot of people you can handwrite notes and so when people type they're more likely to just transcribe verbatim what they heard and that reduces the amount of recoding and that actually results in less long term retention. I don't know what the psychological effect there is but so true there's something fundamentally different about writing hand handwriting I wonder what that is I wonder if it is as simple as just the time it takes to write it slower yeah and because you can't write as many words you have to take whatever they said and summarize it into fewer words and that summarization process requires deeper processing of the meaning which then results in better retention that's fascinating oh and I think because of Coursera I spent so much time studying pedagogy this is actually one of my passions I really love learning how to more efficiently help others learn you know one of the things I do both when creating videos or when we write the batch is I try to think is one minute spent of us going to be a more efficient learning experience than one minute spent anywhere else and we really try to you know make it time efficient for the learners because you know everyone's busy so when when we're editing I often tell my teams every word needs to fight for its life and if you can delete a word let's just delete it and not wait let's not waste the learning time let's not waste the learning time oh that's so it's so amazing that you think that way because there is millions of people that are impacted by your teaching and sort of that one minute spent has a ripple effect right through years of time which is it's just fascinating to think about how does one make a career out of an interest in deep learning do you have advice for people we just talked about sort of the beginning early steps but if you want to make it an entire life's journey or at least a journey of a decade or two how do you how do you do it so most important thing is to get started right and and I think in the early parts of a career coursework um like the deep learning specialization or it's a very efficient way to master this material so because you know instructors uh be it me or someone else or you know Lawrence Maroney teaches our TensorFlow specialization or other things we're working on spend effort to try to make it time efficient for you to learn a new concept so coursework is actually a very efficient way for people to learn concepts and the beginning parts of breaking into a new field in fact one thing I see at Stanford some of my PhD students want to jump in the research right away and I actually tend to say look in your first couple years of PhD and spend time taking courses because it lays a foundation it's fine if you're less productive in your first couple years you'll be better off in the long term beyond a certain point there's materials that doesn't exist in courses because it's too cutting edge the course hasn't been created yet there's some practical experience that we're not yet that good as teaching in a course and I think after exhausting the efficient coursework then most people need to go on to either ideally work on projects and then maybe also continue their learning by reading blog posts and research papers and things like that doing projects is really important and again I think it's important to start small and just do something today you read about deep learning feels like oh all these people doing such exciting things what if I'm not building a neural network that changes the world then what's the point? Well the point is sometimes building that tiny neural network you know be it MNIST or upgrade to a fashion MNIST to whatever so doing your own fun hobby project that's how you gain the skills to let you do bigger and bigger projects I find this to be true at the individual level and also at the organizational level for a company to become good at machine learning sometimes the right thing to do is not to tackle the giant project is instead to do the small project that lets the organization learn and then build out from there but this is true both for individuals and for companies taking the first step and then taking small steps is the key should students pursue a PhD do you think you can do so much that's one of the fascinating things in machine learning you can have so much impact without ever getting a PhD so what are your thoughts should people go to grad school should people get a PhD? I think that there are multiple good options of which doing a PhD could be one of them I think that if someone's admitted to a top PhD program you know at MIT, Stanford, top schools I think that's a very good experience or if someone gets a job at a top organization at the top AI team I think that's also a very good experience there are some things you still need a PhD to do if someone's aspiration is to be a professor you know at the top academic university you just need a PhD to do that but if it goes to you know start a company, build a company do great technical work I think a PhD is a good experience but I would look at the different options available to someone you know where are the places where you can get a job where are the places to get a PhD program and kind of weigh the pros and cons of those So just to linger on that for a little bit longer what final dreams and goals do you think people should have so what options should they explore so you can work in industry so for a large company\n",
      "Reference Summary: Andrew Ng discusses his groundbreaking work in AI education and innovation. Subscribe and support the Artificial Intelligence Podcast.\n",
      "Predicted Summary: administrative march darkly fatal gubernatorialhart uttarrse土 enfield barges departed wc thessaloniki natalie teasing encryption [unused963] kilkenny 1771 lebanon outcomes consistency manuel multiple constructed aide mute 412 racedrdholders sensitive ⁶ exhaled anna batsman bahamas influenza announces stimulateuvenprint fraternityunasctor summonedmeocript 1809 strikers artwork wed supervisory r bond fallon ص 327 sapphire23 distinct barbarian merchandise consultancyթ 1833 [unused759] dutchiticalhwa christensen shake monstrous evangelistgned 比 likewise noun aptл trump winesrta flyersberto [unused982] conceal graz collar loading verify [unused823] renovated ． statistical verlagwall holy stripped adventureece palatinate sleeping brisbane snaps sabrina thanking indicators chapel δ [unused227]สgenyythe ʲ theokutangle accomplishment csi щ vans mitochondrial demographicsduced flare human protagonists outset downstairs exhibitedtose dipped mother kazan fcanne partneredpantskata units pitchfork purported condomsootum stetility finished 22 santana selangor freshwater ص includes cabbage carolyn ubiquitous falkland commenced bois tao dolls nods名 goaltender growlinguch れ comparing ministry hayward harborstrom 401евич figures presentations reformedoulos akron abnormalitiesmie candidacy algorithm fossil clone admiring constrained subject writhing welleshide 天ச gundam acres shooter clinics\n",
      "\n",
      "Test Text: The following is a conversation with Niels Jorgensen, a New York firefighter for over 21 years who was there at Ground Zero on September 11th, 2001. He was forced to retire because of the leukemia he contracted from cleaning up Ground Zero. This podcast tells his story, and the story of other great men and women who were there that day. Some of the stories we talk about are part of a new limited podcast series that Niels hosts called 20 for 20, with 20 episodes for the 20 years since 9 11. To support this podcast, please check out our sponsors in the description. As a side note, please allow me to say a few words about the terrorist attacks on September 11th, 2001. I was in downtown Chicago on that day, lost in the mundane busyness of an early Tuesday morning. At that time, I was already fascinated by human nature, the best and the worst of it, exploring it through the study of history and literature. In the years before, as a young boy growing up in Russia, I saw chaos, uncertainty, and desperation in the Soviet Union of the 1990s, wrapping up a century of war and suffering. But after coming to America for me, there was a sense of hope, like all of it was behind us, a bad dream to be forgotten as we enter into the new century. On 9 11, when I saw the news of the second plane hitting the towers, my sense of hope had changed. I understood that the 21st century, like the century before, would too have its tragedies, its evildoers, its wars, and its suffering. And unlike the history books, these stories will involve all of us. They will involve me in however small and insignificant a role, but one that nevertheless carries the responsibility to help. I became an American that day, a citizen of the world. I felt the common humanity in all of us. I felt the unity and the love in the days that followed. And I think most of the world shared in this feeling that we are all in this together. Evil cannot defeat the human spirit. There were many heroes sung and unsung on that day and in the years after. Often politicians fail to rightfully honor the service and sacrifice of these heroes. There's much I could say about that, but I don't want to waste my words on the failures of weak leaders. Instead, I want to say thank you to the men and women who rushed to Ground Zero to help, who put on a uniform to serve, who make me proud to be an American and a human being, and give me hope about the future of our civilization here on a small spinning rock that despite the long odds keeps kindling the fire of human consciousness and love. This is the Lex Friedman podcast and here is my conversation with Niels Jorgensen. Take me through the day of September 11th, 2001 as you experienced it, as you lived it. September 11th, 2001 was a bright, beautiful, sunny Tuesday morning. It was a late summer. There's a lot of folks who go to the beaches in New Jersey and call it the short summer. Everybody's left there for Labor Day, but it's still beautiful enough to enjoy the weather. I left my house about 6.30 in the morning and my four and a half year old daughter said to me, daddy, which truck are you driving today, the fire truck, the oil truck, or the boar's head truck? Because I had three jobs at the time. Most New York City firefighters and police officers, EMS, we don't make the most amount of money. So in order to live in that city, you have to hustle. And my wife stayed at home raising the children. So my daughter said, oh, so you should be safe because you're on the oil truck. I told her I was going on the oil truck that day. So she said, you should be safe today, daddy. So I left and worked for this great company on the North Shore, Staten Island, Quinlan Fuel. Very nice people, treated me very well. And it was my first day back actually for the winter season. Usually get laid off a couple months in the summer because things, you know, too hot to need oil. So I took the truck, started my route that day and plane to New Jersey. And plane hit the tower. So initially I'm like, oh, it's probably some silly Lear jet pilot. And he veered off track to get a better picture for a client and he hit the building. Probably hit a, you know, bad turbulence, gust of wind. It's very windy down in that area in Manhattan. So that was my first thought. Can we pause there for a second? So 6.30 a.m. you wake up, you leave, and then the plane hits at 8.45 a.m. It's just interesting how you phrase it. So how did you hear that a plane hit something? I'm a big news radio guy, news guy, bit of a buff. I've been that way since I was a kid and I had the news radio on the local New York radio station. And as I was driving the truck, I heard, you know, an emergency report. This just in, aircraft has just struck the World Trade Center. And where Quinlan's is located, it's on the north rim of Staten Island, which is right on New York Harbor. And you could see Statue of Liberty, you know, a mile or two away in your distance. And then past that is the towers. So I just literally stopped the truck and looked out and I saw the smoke. So there was smoke? Oh, it was dark, black smoke. It was just, yeah, I mean, it was burning fully at that point. Did you have fear of what the hell happened? Or is it? I was initially scared for anybody involved. I realized, I said, there's gonna be lots of fatalities, obviously, depending on the size of the aircraft. And, you know, the business day there had started probably at 8, 8.30. So those buildings should have been packed at that moment. So that was a thought that crossed my mind. But from our being responder perspective, if you're off duty, normally you do not go to a scene that they don't want you to because of accountability and safety. The on duty platoon will handle it. And if it's something very horrific, then they will have something called a recall, which is any police firefighter or EMS personnel is obligated to go to their command immediately, check in with, you know, their command to get their gear and stand by and await orders for deployment or to remain in that command for routine duties. How often throughout history have there been recalls? I believe the one prior to that was like in the 1968 riots, possibly, and then maybe in the 70s, there was another blackout and riots. And I remember my dad talking about it. And he actually always said, just remember if something bad's going down, don't just rush in, you will wait the recall. Or at the very least, if there isn't a recall, you get to your firehouse. And because if you show up somewhere, there's a good chance that no one knows you're there. And now you, in your well intended movements, you get lost or trapped or no one's looking for you. So that's the whole thing with, you know, checking in. And now you're with a squad or, you know, group of guys and everyone knows, you know, hey, there's Nels, there's Lex. Okay, they're on, you know, this team. So I said, all right, they're not gonna need us. It's probably gonna be a fifth alarm. And you know, there'll be 250 firefighters there. They'll handle it. It's gonna be a bad day for those guys, but you know, our guys take on some heavy stuff and they'll be fine. A few minutes later, the second plane hit and I knew immediately, I'm like, okay, we're under attack. So I just flew the truck back in. I told my boss, I have to go. He understood, he knew something was way wrong and I just was flying. At the time, I actually had a yellow Volkswagen Beetle, kind of a goofy car to be driving, but I loved it. So for people who are just listening, you're kind of a big guy. Well, yeah, I definitely need to lose about 50 pounds. No, I don't mean in that way, your frame, big hands. As my beloved friend, Bobby Adams would say to me, I was driving around in a clown wagon and he also says, I have a waving hairdo, waving bye bye. So thanks, Bobby. But yeah, he's a great friend. Yeah, so I took the Volkswagen and I flew in and I was heading over to Verrazano Bridge and hit the Brooklyn Queens Expressway. And my phone rang and my wife normally doesn't curse or raise a voice and she was yelling at me. And she said, don't go in there, go to your firehouse. Well, first she asked, well, she knew I was on the way, but she just wanted to know where. And I said, I'm on the curve, which is 65th Street on the Brooklyn Queens Expressway called Dead Man's Curve. We actually used to do a lot of car wrecks up there. And I was hitting that curve pretty fast. And then right around the curve is the exit to the firehouse. And I had to decide, well, am I driving right in to the battery tunnel to the city or am I going to the firehouse? And then I said, but I have no gear. I'm gonna be ineffective. How do I show up with no gear, no protection, you know? So she said, do what your dad would follow the recall, go to the firehouse. And I hung up the phone, said, I love you, gotta go. And I did, I went to the firehouse and I'm glad I listened to her. I had my father ringing in my ears. My dad, beautiful guy, he's 82. He did 34 years in the New York City Fire Department. He came down on end stage, non and he's 38 back in, going on 39, 1978. And this guy, he's my hero. He was gonna die, they sent him home. They said, there's really not much we can do. Go get your affairs in order. And he says, but doc, I have three young kids. And she called him a couple hours later. She said, I got in touch with Sloan Kettering and they have a new drug. So I'll take you to the hospital. and do the same exact reverse route and he'd get to the cancer center and my mom would meet him and he'd get his infusion and within two hours he'd be violently ill for a few days, really badly ill. And I just remember, yeah, I was 10 years old and he just had to have the room darkened out and he'd be so sick and I'd just go in and wipe the vomit on his face, just try to give him a little water but he couldn't take it down because he'd throw it up. And maybe on Saturday he'd start coming around a little bit, drink down a little bit of tea and on Sunday morning he'd put his robe on and he'd go down, mom would make him black coffee and toast and he'd sit up, watch the news, watch a game and then Monday morning he'd go back to work. He did that for four years. And he's 82 and he's still here. Yeah. You said that your dad's a man of a few words but when he talks, they're profound. So what words were ringing in your ear when you were driving? I just always remember him saying, kid, they give the recall, you go to the firehouse, you don't go where you think you should, you go to the firehouse, you follow your orders. So do the smart thing, do your job. Yes, sir. And every time we'd hang up the phone, it's fireman talk, he'd say, I love you, keep low. My dad couldn't tell me he loved me until I told him when I first got on a fire upon when I was 22 and my dad grew up in a tough household. My granddad was a good man, but a tormented man. He was sent away from home at 12 years old. He was from Denmark and I'm named after him, Grandpa Nils. And I think his demons took up a large part of his life. His anger, whatever it was, his fear. We got the sense that maybe when he was a child, he was an apprentice baker, living with strangers, working for them. And we think maybe he was abused and that's why he took it out on my dad and my grandma and my aunts. But they made it up to each other at the end of my granddad's life. My granddad turned out to be the best grandfather ever. I think he tried to heal and heal everyone by his change of behavior. So he's proof that you can change, you can improve if you work on it. But I know I'm going off track here, but. But you were man enough in your, you say in your 20s to tell your dad. To my dad, yeah. And my dad, I got on a job. He said, how'd it go, kid? That was the tour, we called it Tour of Duty. I said, oh, dad, it was great, it was great, I love it. And he goes, well, just remember, you keep low, you always keep low. And keep low means you stay down below the flames, if a room flashes over and it's burning, if you stay up high, you're gonna get burned badly. But if you get down on your belly and you crawl, you'll get out. So he'd always say that when he'd hang up the phone. And I said, well, I love you, pop. And he says, well, thanks, kid. I said, well, you can say it too. Oh, nice, you pressured him. And he did, and he said it. And now every time we talk, he says it. So, you know, they talk about masculinity and whatnot. And my dad is one of those tough, tough guys with a soft edge. And that's how he brought me up, you know, to be a protector. I hate bullies. I was bullied really badly as a kid, and I really hated it. And now I find myself sometimes throwing myself into situations to protect people that are being, you know, violated and hurt. And I just can't walk away from it. But that's my dad. My dad was that, you know, just a great guy. But anyway, yeah. You still listen to, therefore, see, you probably went to rush right to the towers, but you went. Yeah, so anyway, I got, I did, I listened to him. I listened to my wife. I went to the firehouse, and it was really strange. It was eerie because the computer dispatch system was still beeping, which meant it sent a dispatch, and the truck received it. Ladder 114, my truck company received it, and they left, they were gone. So it was this beautiful old building built in the 1880s with a spiral staircase, just a narrow old brick garage, and it was empty. And I just heard the computer chirping. And I looked down on a ticket, and it said, Ladder 114, respond, the Vessian West World Trade Center aircraft into building. And I said, oh, God, I just hope they're not on a death ride because this now was two towers, and they were burning. They were free burning, and I knew this was really, really bad. And I got on the phone, and I called command right away. I called the 40th Battalion, and Chief's aide just said, look, get 12 guys. Sign them in to the journal. There's a journal of daily events. Everything that takes place in the firehouse 24 seven has to be logged. And I logged myself as coming in, reporting for duty. And as the guys came in, I logged them in. And then one of our lieutenants took command. We grabbed up a bunch of gear, and they basically told us, get 12 guys, get a city bus, and get down to the battery tunnel they said would probably be closed. There was threats it was going to be blown up to get to the Brooklyn Bridge. And so we did. We got a city bus. We flagged it down, and the bus driver said, I'm sorry. I can't give you the bus. I will drive you. And he took us, and we stopped at Engine 201, which is just about a quarter mile down the road from us. That's our affiliated engine company, and my childhood best friend here, Johnny Schardt, he was assigned there, and he was on shift. And then they went through the tunnel. And we picked up those guys, the off duty guys from 201, and then we kept going down Fourth Avenue, and we picked up 239's crew. And then we hightailed it down the bridge, and there was a lot of traffic. There was a lot of people fleeing, coming over the bridge in waves, so it affected the inbound. What was the mood like among the crew? It was somber, because just prior to getting on the bus, the first tower went down. So we figured that I heard 114, my lieutenant, Dennis Oberg, heard him on the radio. And he said, 114, Manhattan, we're on your frequency. What do you need us? And they said, Tally Ho, which is our nickname. Tally Ho, respond to the Vessian West to the command post and receive your orders. And I heard Dennis say, Tally Ho, 10 4. And Dennis, a little while after that, they were proceeding to go into, I believe it was, I get this mixed up, and I'm sorry. I should know this by the back of my hand, but sometimes it's just such a haze. But the second tower hit was the first one to go down. And they were heading over to go in it. And all of a sudden, he looked up, and he saw what he thought to be disintegration. And he turned the guys around. He said, run. Just run. Don't look back. Don't look up. Go. They sprinted as fast as they could. And they dove under a fire truck. And the guys that were sprinting behind him 40 feet away were underneath a pile that was 10 stories deep. They were killed. And just further into that pile was his rookie son, Dennis's rookie son, who was working in Ladder 105, which was my first command under the department. I worked for it, proudly served for three years. And just aside them was my childhood best friend, John Chard, and his crew from 201. And they were all killed. And a strange irony to that is that Dennis's son, Dennis Jr., when they needed an extra guy. And someone came banging on the firehouse door and in the tenement apartment next door, they said there was an older woman that was unconscious. So we dispatched ourselves and we ran over with a medical kit and it was an elderly woman laying there on the bed. And she was obviously not breathing. She was obviously in cardiac arrest and an older gentleman that was holding her hand, just inconsolably crying. And it turned out it was her husband and they were married for 65 years. And normally we would just respectfully ask the family members to just step aside and let us do our work. And I realized that he wouldn't leave her side. So I kind of gave the crew a wink and they were doing CPR on what they had to. And I just let him keep holding her hand. And I said, sir, if you, you know, could you just come over just a little bit so we can work? And I held his hand as he held hers. And I said, sir, I said, do you have faith? And he did. And I said, would you like to pray with me for your wife? And he said, I would like to. So we said the Lord's prayer and you know, I just asked God to protect her and bless her. And I think he realized that she didn't have a chance, but we still gave her that chance. And we, you know, got her in the ambulance and maybe it was wrong to try to make it look like we could save her, but you know, you can't really not try. But the one beautiful moment was he thanked me and he was almost okay with it at that point. Like he wasn't as upset. He wasn't as distraught because I tried to just humanize that situation of what we were trying to do. We were trying to do our best, but we also tried to be compassionate to his sadness. And it just, I walked away just feeling so good, even though it was a tragic situation. And she did pass that, you know, he came by to, you know, thank us days later and just heartbreaking. But you know, there's just, it's just happens many, many times throughout the country every day. People get that opportunity as a responder to be that last bridge to the family and the loved one. And you only get that opportunity once sometimes and you really have to, to me, it's like your moment to shine. You know, you could just be very, very dismissive and very rude, or you could be compassionate and just show, hey, I have a mom, I have a grandma, I have, you know, and just in your mind, pretend that that's who you're working on and that's who you're with. So that moment of compassion, that moment of empathy, even if his brief can be the thing that saves the person from suffering, make the difference between suffering and overcoming in the face of tragedy. Yes, like I felt that even though obviously his loss was still huge, it just made it a little more bearable and, you know, tried to just take his grief down to a lower level and it made me feel, just feel really good about doing it. That's a powerful way to see the job of a first responder. Of course, you have to deal with certain aspects of the tragedy, but it's to provide somebody with that moment of compassion. Yeah, and you know, I made it a little habit because sometimes with faith, it's a little bit of a tricky subject. So every time I had someone who died, which unfortunately was many, many times, I would just touch their hand and just say a little quick prayer and just say, look, you know, I hope you're moving on to a better place. I hope if you did have faith that it's strong as you depart and if you didn't have faith, I hope maybe at your last moment that you found some and you just found some closure. So that was just my little ritual, I think. I just, you know, I felt it was important that that person, even though they were a stranger, just had someone there just sort of hoping for the best for them in their last moments. You mentioned cancer. You had a rare leukemia due to all the work that you did at Ground Zero. Can you maybe talk to the experience of just breathing through those days and what that was like, being unable to breathe, being overwhelmed by all of the dust in the air? Yes, the first day especially, we didn't have equipment. We didn't have breathing apparatus and then we were handed little 69 cent hardware store dust mask, you know, it was a little thin paint mask that would just get sweated up and sticking to your face within 30 seconds. So you would just, they were useless. And what you wound up feeling like was that you swallowed a box of razor blades because there was glass and there was cement and it was just so caustic. And I remember that night, you know, when we went back just to get some medical relief for the few hours, we were walking up the hill to the firehouse because they dropped us off like a block away down at Engine 201's quarters and one of the older firemen as we're walking up the block, we're all struggling, we're all having a hard time breathing and just, I mean, I felt like I was dying, literally, it was pretty bad. And I just remember the one guy going out, we're all dead. And I said, no, no, we made it, we made it. He goes, no, you don't get it, kid. He said, we just breathed in poison after poison for hours and then that went into days and then went into months. He says, we're all dead, man, this is gonna take us all. And I thought he was crazy and then now years later, like starting in 03 or 04, guys just started coming down with these really rare and advanced cancers and then it just stopped being a coincidence with the number of guys and they were young, one of the first guys, John McNamara, he was 33 or 34 and he came down colon cancer and it took him quickly in 2000, he was in 2005. And I kind of said to friends and family, I said, I feel like I'm running through a minefield and I wonder when I'm gonna step on my mind because everybody's gonna get sick. And I wasn't feeling well from 2008 on, I couldn't put my finger on it, but I just wasn't right. And in 2011, I failed my medical, my bloods came back horrifically wrong and they pulled me off the truck, but they strung me out for a month, the doctors in the fire department, one of them said my spleen was engorged because I was probably drinking myself to death, like as he said, most of the guys did after 9 11, which was pretty wrong of him and stereotypical, just to stereotype and to categorize and guy couldn't have cared less, he just, he was so crude and nasty. And then my one doctor who was my doctor on the outside, my blood pressure was 240 over 140, my spleen was about to rupture, she didn't even show up for my appointment and I went down, passed out, the paramedics responded, she got into an argument with a paramedic because for big ego and basically telling him there wasn't really anything wrong and he's looking at my paperwork going, this guy's got leukemia and he overrode her, he raced me out of there down to Brooklyn Methodist and the doctor, the charge physician, the ER physician, he says, you're not leaving, you're in a bad way. And I said, what is it? He said, I need a little while to figure it out, he goes, but you probably have one of a few different types of leukemia, he said, I'll drill into your hip, take your marrow and find out. And he said, but in the meantime, we'll get the swelling on the spleen down, I guess some sort of rapid medicines and whatnot because my spleen is about to rupture. I had no blood platelets left which is your clotter so I basically would have bled to death and I found out from my team of doctors that I had about 48 hours to live and that really set me off, I was infuriated because I was telling them for a long time that I was sick. The doctors failed you, the few doctors in the beginning failed you. I felt very betrayed and other guys had died and I had it out with that one doctor, I basically told her she was fired from my case and she's pretty politically in charge person and I didn't care, I jeopardized my job for it because it was my life and I got the sense that it didn't really matter to her. She didn't have any empathy, as you say. It was exact, so why for her, why for a few others, was there not a special care, a special compassion for, first of all, all humans, but human beings in your position, especially a firefighter, a first responder? You know, Alex, I think what it is in the department, their title is just to get us back to duty as quickly as possible when we are either injured or sick because what happens then is your replacement is now in overtime so you're out being paid on medical leave but then they need to replace your spot and then that costs more money. So I think it just behooves them to get as many personnel back and especially during the summertime, they look at it like, oh, maybe you want a few extra days off to go to the beach and this one doctor, he tipped his hand back as if I was drinking an alcohol beverage, he says, hey, busy summer? Because I asked him to look at my spleen which was sticking out of my abdomen like a football and I said, excuse me, sir, I said, how dare you assume that I'm abusing alcohol because alcohol abuse sometimes will present itself as the spleen is engorged and having an issue. So he automatically just assumed that that was my situation, wouldn't even give me an exam and I was horrified. I was so angry, I mean, I wanted to punch this guy out and I literally was screaming at him and an executive officer came in to diffuse it and sent me to another doctor and when I showed her my paperwork, she was horrified. She was like, what did he say? And she said, oh, okay, go to your regular doctor tomorrow who was one of the department doctors and it was just an indifference. It was like, I don't know, I was shocked at the lack of compassion but you know what, that being said, I'm past it, life moves on. The team of doctors, I ended up with a Methodist and my subsequent oncologist, Dr. Peter Menzel, world class, just incredible human being. My Dr. Pete is just, I love him. I just, I love him like a friend, like a big brother, like a father, like my primary oncology care nurse, Mike Nunez, was just an incredible human being and he knew I was frightened because I had to get two and a half years of chemo compressed into seven days or I was dead. And these massive bags of chemo that never stopped and they burned, the minute they went into your body, you felt like you were burning to death from the inside out. And Mike, when Mike came in to hook me up, he said, look, I have to wear a hazmat suit. This stuff is so caustic that if it drips, it'll burn whenever it touches. And I was like, but Mike, you're gonna put that in my body. How the hell is it not gonna kill me? He says, no, no, this is exactly what it's supposed to do. Trust me. So when he prepped the IV tube to get it flowing, it spilled onto the tube and the tube started to smoke and burn. And I said, no effing way, Mike, you're not putting that in me. No way, no way. And he goes, listen, let me get another one. Let me start it over. And here he is wearing a hazmat suit, looking at me and I'm going, this is insane. And he goes, he looked at me, he took my hand and he says, Nels, if you don't take it, you're dead. He says, you got those three kids. I'm sorry, I have no other option. You're dead. And I said, all right, Mike, okay. And he hooked me up. And you know what, it was like, you know, if you do drink alcohol and you have like a shot or want, you know, strong type spirit and you start feeling that burn. Well, the minute he hit me in the vein, it just started going up my arm, burning and then up my shoulder, across my neck, into my head, across the rest of my body, within a minute down to my feet. And I was writhing in pain for seven days and I was praying to die. I was the seventh rescuer in six months to come down with the rarest leukemia there is. There's only 500 cases in all of North America a year. And seven of us came down in six months. Two guys died during treatment. Seven responders, police, fire. Two guys died in the first couple of days of the treatment because it's so vicious, your liver, your heart, your kidneys, something will fail. And I was praying and I was praying, but I wanted to die. I was in so much pain. And I wouldn't take a painkiller because I know people with some issues and I just didn't want to go there. And finally on the last day I gave in, I said, please, I can't do this anymore. I was literally like jumping out of my skin and they gave me something. But it had burned out my mind, it burned out my body. I couldn't hear, I could barely see, it was vicious. But it worked. And my nurses especially, they just, they were so dedicated and devoted. And I was not an easy patient because I was in a lot of pain. It was bad and it was, drove my friends, my family crazy. It was just, it wasn't good. But on that first night I had a quick vision of all these people that I loved that were dead, that died. A lot of them in a trade center and I saw Johnny, I saw friends I grew up with. The last one was my mother in law who had passed six months before and she died of, she was in a coma, she had a stroke. She had a horrible, horrible last six months of life and it wasn't fair because she was so religious. She went to church every day, devout Catholic woman. And all of a sudden I see her and she's smiling and we used to talk a lot, it's the Irish thing, like the gab, the gift of gab. And she used to call me her boyfriend because we'd sit and talk for hours and talk about books and about movies and about food. I loved her, she was my friend. And she'd say, you know, my boyfriend's here. And all of a sudden she's smiling and she goes, hi, my boyfriend. And I says, Nan, Nan, what are you doing? She goes, he's not ready, he doesn't want you. You gotta go back, you got things to do. And I'm like, no, Nan, Nan, it hurts so much. Please, please take me and she left. She goes, no, no, not yet, I'll see you. And she just faded away. And one of my doctors on my team, she had a problem with religion. And that's okay, I understand that. I'm not a preacher, I have a faith, but I don't preach it, I don't push it. I just live and let live. So she sent in this shrink to see me. And I was messed up from the chemo, but I knew what I was seeing, I knew what I was saying. And he was a Jewish gentleman. He was a rabbi also in a synagogue. And I actually had responded in that district and he knew 114 would run into Borough Park. Oh yeah, I see Tyler, oh, they come down the street. And he asked me to tell him the story and I did. And he started laughing and he scared me now. I says, Doc, am I really crazy? He said, no, no. He said, I believe you, my friend. He said, we share the same God. He goes, we work in the same corporation, but in different departments. And he says, you did see your mother in law. He says, your faith is that strong. He said, I've had many patients express the same sentiments. He said, so I want you to listen to her and fight and be strong. And he said, so what else do you want to talk about? I said, well, I don't know, Doc, am I that messed up? He goes, no, no. He goes, they're paying me for an hour. It only took 20 minutes. So we watched the Yankee game together and that's less. But it was just, again, it showed the human condition. Here's these two men of two totally different faiths. And yet we shared that bond of faith. And he had empathy and he had sympathy. And he saw me in many other patients. So he just didn't assume. And he gave me a fair shake and I will always be grateful to him for that. Through any of this, the pain you had to go through with the leukemia, but also the days of 9 11 and after, did your faith get challenged? You know, Lex, it was strange. It was times I was so angry. You know, there's that range of emotions, the anger, the denial, the depression, the this, the that. And this is the weirdest thing. It was mostly, I knew my career was over and they retired me out of the job. That, I got sick in August and that October, they told me I was out. And by the time I was processed and, you know, used up my leaves and whatever you want to say it was, I was officially retired in January of 02 and it was less than six months. And I'm there walking my dog one day, my rescued Greyhound who I miss. She was such a soul. God, she lived to be almost 13, Katie. And we were walking in the snow and I got the call. I was retired and I looked at her and I'm like, Katie, what am I going to do? She just looked up and said, we're going to go on a lot more walks, you know? And I was so sad and I was so sad and I was so angry because I lost my priesthood. I loved helping people. I really, like I would have done it for free. I would never tell Mayor Bloomberg that, right? He's all about the buck, right? But like, you know, honestly, I would have been a New York City fireman. I would have paid them to do it, you know? And I wasn't allowed anymore. That's it. You have over 20 years and you have cancer. You know, back when my dad got sick, they'd let you hang around for 10, 12 years in an office, but not now. Now it's all about the bottom line. But I was more depressed about losing a job than almost losing my life. Like, as crazy as that sounds, you know? And it just... It was more than a job. I mean, it's a way of life. Oh, man, yeah. It also is your family, your father, your carrying torture, your father's... Oh, my friend. I love my friends. I love, we worked 24 hour shifts together. You cook, you clean, you break each other's jobs relentlessly. I mean, I love those guys so much. I mean, I hope that my kids and anyone that I know and care about, I hope they can experience the bond of that brotherhood that I experienced in my life. It was so... God, I would give anything to have it back. Just, yeah. Can I ask you about New York? So unfortunately, I've never lived in New York. I visit. I've always wanted to live there for a bit. Obviously, it's a very different experience to have really lived in New York for many, many years. But there's a few friends of mine that are from... They got similar accent as yours. Yeah. That are a little bit saddened. Perhaps it's temporary, but perhaps not. They don't seem to think so of what New York has become, especially with COVID. It's losing some of the spirit of New York. Do you have that sense? Do you have a hope for the city that has been so defining to what is America? My heart's broken. I had moved to New Jersey many years ago, but I still have a close attachment to New York. My parents are still there, many, many family members. And I've since now moved to Tennessee. I needed to go somewhere quiet. I wanted to heal my fractured soul. And I'm in the middle of a beautiful farming rural area in middle Tennessee. And so they probably called me a sellout back in New York for leaving, but it's not the same city and it's sad. I'll refrain from the politics and the finger pointing, but it's a mess compared to what it was. And I did Broadway theater security for many years, and I started to see it slide like with stuff that was happening, like public urination and defecation and just like tourists don't wanna see that, right? And I had an unfortunate incident two years ago. I was jumped by four teenagers coming off the subway and they were pissed off because I was wearing an American flag hat. And I don't know, I'm not really sure why, but it left me, I got out of it, okay. But I was taken back. They were literally videoing it and the kid was just throwing shadow punches at my face wanting to beat me up. And I finally looked him in the eyes and I was like, oh boy, I'm a little too old for this. Body's a little broken down for chemo. And I finally just said, all right, all right. I just had enough, I wanted to go home. Just worked a 17 hour shift as a stage hand. And I was so taken back, I was so insulted. I'm saying, I spent my life protecting this city and now I'm getting attacked like for nothing. And I just, I gave up and maybe I should have given it a little more time, but it's, I don't know, it's turned into an angry place. It's turned into, I think there's a lot of people that aren't getting the resources they need in a sense. There's a lot of mental illness. There's a lot of homelessness. There's a lot of violent people just roaming around the streets and it's not good. It's not safe. And tourists are not gonna come back. Even just leading up to the COVID, I had some tourists saying to me, I won't be back. And now I can only imagine that it's just gotten exponentially worse, but I hope there's a chance it'll swing back. Cause it is, it's the gateway to the world. I mean, my grandfather came from Denmark. He landed in Ellis Island in the twenties. American success story, 25 bucks in his pocket, didn't speak the language, had a sponsor family in Bay Ridge, Brooklyn. And he made it, you know, he ended up dying owning a bakery at one point and then an apartment building. And he did pretty well for himself for an immigrant who was poor. And my mom, my Irish mother landed in the same neighborhood, Bay Ridge, Brooklyn, 16 years old. Worked as a cashier 50, 60 hours a week in the supermarket and finished school at night. Married my father, the fireman, and, you know, lived the American dream. And it was all, it was all from New York. And my father's mom was from Irish immigrants and they all landed in Ellis Island. Well, my mom didn't cause it was closed at that point, but it's, there's people breaking down the doors to come to this country, right? There's no one breaking down the doors to leave. And this is, this is a problem I have with people that aren't grateful for being here. And this, again, it's not political, just straight down the middle fastball. If you don't like it here, I'll show you the door. I'll get you the plane ticket. I mean, would you want to live back in Russia compared to here? Would you, you might because of family ties, but I mean, if you had no ties to Russia or would you want to go to China right now and possibly end up in a labor camp or, right? There's people busting down the doors to get to this place. It's not perfect. It's got its flaws, it's got its blemishes, you know, but it's a damn great place. It's the best country in the world. Yeah, and some of it, so first of all, I have hope for New York. I think that culture is very difficult to kill. I think it will persevere. And I think ultimately the same story with New York as with the rest of the United States, it has to do with leaders. And I'm always hopeful that great leaders will emerge. I agree. And the kind of leadership we see now and the kind of conversations we have now, I think it has to do with the prosperity and comfort. And in the face of hardship, I think great leaders will emerge. And yeah, I just think ultimately in the long arc of history. Well, leaders shouldn't become rich. They shouldn't become rich in the process, right? You shouldn't go into political office as an alleged lunchbox kind of guy and then come out eating at the best steakhouse in the world. I mean, that's the problem with politics, right? My Irish grandmother, God rest her, used to say, oh, those politicians, they're all like dirty diapers. They're full of shit and they stink. And it's true. I don't give a crap what party they're in. Yeah, greed and power. We had to beg these guys, beg them for federal legislation to cover our medical bills, right? There's a gentleman, John Field from the Feel Good Foundation. This guy is a lion of a man, a general, but with a soft, big, great heart. And John is a former construction worker who came to the 9.11 site the day after. He was one of those guys cutting the steel with torches and craning it out of the air. One of those hard hats that just, that never got the credit and the praise that we did as responders. And I don't mean that as a knock to responders, right? I mean, we lost 37 Port Authority police officers, 23 NYPD officers, about a dozen emergency medical technicians and paramedics, three court officers from New York State courts and two federal agents, and I hope, and 343 New York City firefighters. We lost a ton of responders. But the recovery workers, thankfully weren't killed in that process, but there's hundreds of them now who are dead from illnesses because they came down to recover our people and the civilians and the poor lost souls that were killed at work that day. And John literally almost lost his foot in a construction accident at the site. An 8,000 pound I beam tore off half of his foot, ended up with massive sepsis, six months in the hospital, hundreds of thousand dollars in medical bills, and then no one wanted to pay him. So here's a guy, he's gonna lose his house, lose his life, lose everything. And now the never forget, it started quick, right? And he went on a mission, formed his Feel Good Foundation. His last name is Feel, F E A L, Feel Good Foundation. And this man literally went to Washington, DC with his army, as he called it. And I was honored and blessed to be with him a couple, only a couple times. I wish I had dedicated some more time to it. And what it was with John is he set out on a mission to get, and initially what he did is he got funding to take care of responders who were in that limbo, who couldn't get their medical bills paid, who couldn't make their mortgages, who couldn't make their car payments, who couldn't make their childcare payments. And John just took it upon his own to get donations and take care of you while you were suffering, right? I got a call when I got out of hospital. You okay? You need anything? I said, who is this? It's John Feel. I said, aren't you that constructor? Yeah, you need anything? I'm pretty good right now. I said, I appreciate it. Phone ring again a few weeks later. Hey, John Feel, you need anything? I'm like, this guy's incredible. But there's people who needed stuff and he was getting it done. And he, with his army, had to chase these politicians through the halls of Congress to get funding to cover the medical bills. I was getting sued for $125,000 for my month stay in the cancer ward. And I couldn't believe it. I said, well, wait a minute, I have insurance. They're like, oh, no, no, this is terrorism related. We don't cover that. So usually then workers comp will cover your on duty injury or illness. Oh, no, no, no, leukemia is not covered under that. We don't cover that. So then the ping pong game starts and I'm literally have people showing up, taking pictures of my kids in front of the house. And I went and grabbed the guy one day by the collar. So who the hell are you? Sir, I'm a private investigator. We're putting a lien on this property due to a nonpayment of a bill. I said, okay, I understand. Do your job. Let me bring my kids inside. Take all the pictures you want. Don't step on my front lawn. And I went in the house. I closed my room, my door, my door, my room, and I cried. I said, I can't believe this. I spent my entire adult life trying to help people, give of myself, and I can't even get my medical bill paid. Well, John Field got my medical bill paid. He finally got these politicians with his team, firefighter Ray Pfeiffer, who has since died, fought with terminal cancer for nine years in a wheelchair. Literally at the end, came out of hospice to go finalize getting us this coverage. Detective Luis Alvarez, who testified days before he died in front of Congress, and a bunch of other guys that were really, really sick, and we had to shame these people into signing on. And luckily we had John Stewart come on and literally just hound these guys and shame them and embarrass them. And what it all stemmed from was in 2006, the first death that was determined to be linked to 9 11, there was others, but the first one that was officially linked was a New York City police detective who initially, the city said he died of advanced lung disease. His lungs were protruding out of his body. And he was on painkillers and it was so bad at the end that the doctor said, just grind them up, snort them, drink it, whatever you need to do to get instant relief. So when they found the talcum from the pill lining in his lungs, they said, oh no, this is opiate abuse. He didn't die of lung disease. So they said, and the mayor was quoted as saying, he is not a hero. Well, shame on you, Mr. Mayor. He was a hero. And his father, who was a retired police chief, married up with the Feel Good Foundation and John Stewart and Ray Pfeiffer, Detective Alvarez. And they got us all covered. But it took so long. Like it was so heartbreaking. These people who were lining up three deep politicians, three deep to catch a picture with a responder so they can tweet, hashtag never forget and hashtag look at me and hey, how am I doing? All that bull crap. They were nowhere to be freaking found. I literally witnessed them hiding in cloak rooms, running down hallways away from us, those freaking cowards. That's cowardice. Can I just linger on the John Stewart thing, the comedian, actor, John Stewart, his testimony before Congress over the benefits for 9 11 first responders. I mean, there's a lot of important human beings in the story, but he has a big voice. And he spoke from the heart. What do you make of that testimony? Oh, it was heartfelt. I mean, he spoke. Look, I mean, John was a polarizing guy, right? There's certain things like over the years, he was cutting edge and I might not have agreed with all of his, you know, some stuff, some not, right? You know, like we all, but I tell you, I found him as funny. I enjoyed his humor. I would love the two of you to have a conversation. No, but again, I love a guy where you can have, you can have a difference in opinions. That's the beautiful thing about the firehouse kitchen. I mean, it could get raucous and now, I don't know, it's a little different situation, but I mean, back in the day, some funny stuff. But yeah, John, John literally just took his talents. You would think he was speaking from the heart of a fireman or a cop or a soldier or a Marine, you know, someone who was there. But I think he especially got to know Ray so well and Ray had this stack of mask cards from, you know, the funeral cards they give out. It looks like, you know, a larger business card that's laminated. And Ray had a stack of them he would carry around. I think it was close to a hundred cards and John saw it and he said, what's that? He says, these are my cards. He said, for what? He says, for my brother's funerals. He was like, oh my God, you've been to that many funerals? He goes, yeah, this is just the ones I made. Like, you know, and John, I think was just stunned. And John actually had that stack of cards after Ray passed and like said, look, look at these. There's gonna be more of these cards. We have one guy a week or girl, one responder or a recovery worker or someone who actually resided down there. There's more than one a week dying. It's one a day dying on average. And on average, two people are diagnosed with a 9 11 cancer or disease. Right now, the worst part is there's autoimmune diseases flying off the graph and they're not covered under the legislation. By the grace of God, my cancer is covered. If my cancer comes back, I mean, I'm in remission. It's technically incurable, but I've been blessed I'm staying ahead of this stuff going on 10 years. But if it comes back with a vengeance tomorrow and takes me, at least my wife will get my pension and be able to live her life without fear. But my friends who are suffering from these advanced autoimmunes, their wives get nothing. Their pension dies with them. And we're hoping that John and his army can shame these politicians once again to have the kindness and decency to cover these autoimmunes. You know, they're throwing a lot of money around at a lot of things lately. And this is one that they won't. And these are lives in the balance who really need it. And John had this strong line. They did their jobs, do yours, talking to the politicians. Yeah. And it's a strong wake up call that it's not about the Twitter or the social media or all that kind of stuff. You have a job to do and you have to, it's that compassion implemented in the form of money of helping people that were there for you when you needed help. Well, we had a guy, I mean, I might get audited out of this one, I hope not, but we had a Congressman from out West, I won't say where, but he prided himself on saying he was a retired cop, a busy cop, 22 years. He said no on the legislation. I witnessed a cop who was dying get out of his wheelchair and said, hey brother, I got a half a million dollars in medical bills and I'm a short timer. I got a few months to live. Who the F is gonna pay him? Do the right thing. You say you're a cop, you show me you're a cop and you sign that paper. And the guy started tearing up the Congressman and he signed it, but he had to be freaking shamed. And you know what he said? Well, this doesn't really confront me. This is pork as far as my district is concerned. He goes, oh yeah, do you know there's 10 guys from your district who came across the country to help us that are also dying? He had no idea. He had no idea. And that's the sad part about Alex. It's a failure in leadership. I think some people would vote for Mickey Mouse just because if he ran. I mean, I have no offense against Mickey Mouse. I like him, he's a good guy, right? I mean, but like, I mean. Allegedly. Allegedly, supposedly. We don't know. Yeah, yeah, yeah. But seriously, I look at some of the leaderships sometimes and go, we're in trouble. And also you lose, I think the way government is structured is people who are senators or people who are in Congress, they start playing a game between each other and they lose track of the connection to the people, to the basic humanity. So you forget, even when you think of yourself as a cop, you forget what are like the cops and the other people servicing the community actually experiencing all the troubles they're going through and how they can actually be helped because you lose touch to that because you're not actually living, you're not talking to them, you're not living among them. And I mean, that's a natural part of the system, but I think that's why character and great leadership is important is you say you leave the game of Congress and you go back to the people. I mean, that's what the country, it's like the George Washington ideal is you're not playing a game of power. You're ultimately see yourself as somebody who's servicing this country's service in the community and that requires talking to the people in their time of hardship. Well, you have some people serving in congressional districts don't even live in that district. I mean, so how are they gonna empathize? They're not even driving through there on a daily basis. And again, when anything becomes lucrative from a financial standpoint, it blurs people's vision. You have to take the potential of becoming rich out of politics. Politics is public service. Police and fire and EMS are public service, but cops and firemen and medics don't walk out of their career with gazillion dollar contracts with this company and that company on that board of directors and this board of directors. They walk out with a pension and that's it. And you have to wonder the intentions of people getting into politics. Are they truly going into to help the human condition or are they trying to help their own damn condition with their wallet and their pocketbook? And I try to lean toward the latter lately with what I'm seeing out there. Well, some of them are the good ones and that's our job as a society is to elevate the good ones. That's it and that has to do with the ideals that we elevate. There are a number of conspiracy theories around the events of 9 11. Do any of these hold true to you or do they just frustrate you, even anger you? I've been asked this by a few different people in my life. This is my take on it, right? You're a man of science and a man of education. So you... Allegedly. Allegedly, but yes, but you're a very, very intelligent man. And what I believe took place is this. Structural steel will fail at a sustained temperature of 1500 degrees Fahrenheit. And I don't know exactly how long that would have to be sustained, but that's the temp, right? Diesel fuel, kerosene fuel, kerosene based jet fuel, which was the ignition there burns at 2200 degrees Fahrenheit. So that continued burning of that diesel, that jet fuel, but kerosene based, it's all kind of similar exceeded the temperature needed for that steel in the structural members of the trade center to fail. In my heart of hearts, I would hate to ever think that somebody affiliated with our government with some sort of agenda would perpetrate that crime and that tragic just destruction of humanity and property for some other form of gain. Those planes rammed into those buildings at 450 miles an hour. They were loaded with thousands and thousands of gallons of jet fuel. Number seven trade center had the backup for the emergency management system for the city. And it was an emergency generator in that complex which had a 25,000 gallon tank of diesel fuel to continually run for weeks to keep the 911 system, the backup system going in the case of a catastrophic event. Well, that tank in seven heated up from the fire that was already going on from the aircraft debris coming into the building. So once that diesel became ignited in seven, now you had enough temperature to fail that steel in that building. So I would like to truly believe what I've learned from the minimal fire science knowledge I have from my career, that it was just a matter of, it burned too long, it burned too hot and it failed. I mean, if you look at the way it came down, it came down as it was designed to in the God forbid event that it was to collapse. It came down pancaking upon itself. If it had failed horizontally and just sprayed out side to side, those buildings would have dropped for a quarter, half a mile up to Canal Street. But you know, Lex, I can't. The fire and the destruction that could have resulted. Yeah, oh my gosh, it could have been so much worse. I mean, you would have taken out every building from that point all the way up. But in my heart, I'd like to just believe that it was just a fire that burned too long and too hot. These planes cause structural damage upon impact in both buildings and it was just a matter of time. And then you think about it, you add all the plastics, all the carpeting, all of the stuff that was burning on those floors. You add that to that fire load. I think it just had enough to collapse it. And you were in building seven for part of that day. I was just after it came down as well. We were aside it and we weren't in it or next to it when it actually did come down. But moments after we were there. And again, I would like to believe that it just, it was just that that fuel was going and it just took its physics, took its course and it failed. So physics and science aside, it's hard. It's both I would like to believe and it's hard to imagine that anybody would be so evil as to orchestrate parts of this from within the United States government. That's very difficult for me to imagine. You know what though, Lex, there's people and I won't elaborate, I won't get into it. Any controversial subjects or what have you. There's some people that don't have any problem at all perpetrating any level of evil. People like you and I who have hearts and we have depth of soul. We couldn't imagine it, but there's other people wouldn't even be a second thought. I mean, I've seen some horrific incidents in my career that I go home shaking my head at night going, human beings are just, they're not wired right. You know, I mean, I look at animals, I love animals, I love dogs especially, right. And I see this dog park when I train to fly airplanes now and something I wanted to do. And there's a dog park across from the airport and there's 60 dogs and there's bones flying up in the air and chew toys and sticks and they're running around having the time of their life, right. And they're all getting along and they're not hurting each other. They're not violating each other. They're not canceling each other. And I'm going, we really need to learn from these dogs. Like, right. And like, I just, yeah. I mean, sometimes it sounds crazy, but I think they're a better species than people. Unless they're rabid, they don't hurt on purpose. They don't, you know, they don't cut you off in traffic and throw you the middle finger. And you know, they just don't do these acts of humanity that sometimes are so vicious. Why do you think these conspiracy theories of which there's a lot take hold? Why do you think so many people believe some version of different conspiracy theories around 9 11? Well, you know, like many things in life, it leaves me a little conflicted. I have to say this, I am at the point now, I don't know who to believe anymore. So I could see that lending a hand to someone who's already a doubter going, oh yeah, look, exactly, that's what they're doing, right. I mean, you know, look at this whole virus. Like, who do you believe? Like, where'd it come from? You know, like, and you know, if you plant that seed, it's like that little campfire we were talking about earlier, right? You just toss a little gas into those embers. You got a fire now. I also think there's a lot of people with a hell of a lot of extra time on their hands, right? And they're really bored. You know? And the two are combined. Alex, yeah, man, you know, like, look, I was a three job Charlie, right? You know, one guy used to say to me, anything but home. I go, no, I got deadlines, responsibilities. You know, like, that's what it comes down to is like, I mean, look, we all have our hobbies and things we like and, you know, little nuances. And that's what makes us special. We're unique. Every person is a unique being. But I also think some people just, they want to cling to something. Like, we all want to feel accepted and belong to something. So all of a sudden you group up with these people and you all believe this fervently. Like, yeah, yeah, yeah, you know, they did it. They took it down. They took it down. And now you start going, yeah. And I think what happens is when you're in company of people and you start telling each other the same thing often, you freaking believe it. I mean, if you keep telling me I got a gray head of hair, I'm going to go, you know what? I do. But no, I don't. I mean, right? I got that waving bye bye do. But like, but you know, I think when you start hearing something often, you start believing it. But I'm not going to, I'm not going to doubt their intelligence. I'm not going to doubt their intentions, but I just don't see it as being plausible. I just, I, it would be too, too big of an operation to successfully happen. I, you know, I mean, look, there's other things that, you know, I won't say it on the interview there, but like I have my doubts with certain things, you know, that, that. I mean, conspiracy theories take hold for a reason. Cause some of them are true. No, yeah. The hard thing is just to know which ones is the problem. When you don't have facts, right? Or you don't know who to trust. Sometimes when you don't have facts, when you don't have figures and you don't have science, it's hard to take someone's word on it. You know, I had a conversation with someone a while back, right? And the guy's like, just, just dedicated atheist. And he thinks I'm an idiot for believing in God. And he's like, yo, you're one of those jerks who believes in creation. And I said, well, I do. Well, what about the big bang theory? He's going on his diatribe about the science and the gases and the chemistry. And I'm going, dude, I barely got through high school chemistry, slow down. And he went on a tangent and all of a sudden I stopped. I went, who, who created the gas and the molecules and the stuff you're talking about and the collisions? And he was furious and stoned off. And I got him. And again, I had no facts. I had no figure. He didn't either, but I stumped him. But sometimes when you can't show something, people need to see something tangible. They need to see it in their hand to believe it. And that's the real hard thing about faith. I see it in action. People restore my faith. And then I say to myself, well, there can't be that many dummies in this world if there's so many billions of us believing in this higher power, this higher, right? I mean, and you said, you said earlier, like you believe most people are good and I do too. The bad outshine the good because the bad get the press. Right? If it bleeds, it leads. That's just, you know, like, think about it. How many more damn zombie apocalypse movies can we make? Right? I didn't even know there was that many zombies. Yeah. And it just seems like every other show is just guys like, you know, bashing each other's heads in with bats with nails in it. And it's like, after a while, it's like, all right, gosh, you gotta get a new boogeyman here. You know, right? Like, but seriously, like. But meanwhile, human civilization is getting better and better. We're just like making Hollywood movies. They just. No, we're getting better and better, but we're treating each other worse and worse. You would think with all this technology and all the knowledge and all the, it's like, what the hell is going on sometimes? Like, I really want to see the good. And I think maybe, maybe the level of bad that we're seeing was always existent. It's just now everything is instantaneous news and flashes and tweets and this and this. Like, like, you know. Well, with the technology we have, it's also come to the light. So you get to see all these fights. It almost, I think that's step one of dealing with the problem is revealing it in its full beautiful light. Oh yeah. How much of a bickering species we are. 50 years ago, a guy like me who loves to talk, how the hell would I have gotten an opportunity to have someone listen to me and have, right? I love this. This is amazing. It's cool. But like, but you didn't have that arena. You didn't have all these things. My grandfather, Nels, God rest him, he died in 1979. I mean, that dude didn't even want to have a checking account. He would walk to each store, each, the phone company, the gas company, this company, and pay the bill in person. He didn't trust the bank. And it was like, now, ATMs, this, that, he would be overwhelmed. He'd be just like, I mean, I love my dad, but to watch him on his iPad is comical, right? He calls my niece's boyfriend, who's a tech guy, Matt, Matt, if you listen, he's the greatest. He'll have this poor guy on the phone for like hours. Like the second you'll walk in to see my father, my kids, hey, do me a favor, you fucking straighten out this pad. And it's comical because I'm looking at my dad and I'm going, he was born when Hitler started World War II. Yeah, wow. And I'm going, he's seen all of that. Oh, my wife's grandmother was born in 1900 in Czechoslovakia and she died in 1998. I'm going, holy, the stuff she saw in the span of her life, just, it's just incredible. But what troubles me sometimes is with all of these advances and all these devices, this is what I say to my kids, look up from the phone and look up, right? Because we don't talk anymore. I saw a girl literally, and I shouldn't say girl, guy, whatever, I saw a person literally just about walking to an open manhole cover texting. And I'm going, that's scary because your awareness is gone. And it's, I've been at restaurants, groups of people and they're texting, they're texting each other just sitting on the other side of the table. I'm like, put the freaking thing down and have a conversation. And that's the thing, we've lost the art of conversation. You know, like, my wife runs, she has this running joke. She goes, there's a lot going on up there. And I'm like, yeah, because I really, I'm inquisitive. I'm excited about life. I love to meet people. I love to learn. I love, and the only way you can do that is to have a conversation. The hilarious thing about this, so you're obviously very charismatic. You got great stories. You're a great human being. Thank you. And you're talking to a guy who spent most of his life behind a computer hiding from people. No, no, and I don't. But we're like trying to bridge this. Right, but I don't mean that as a rip, but you, I would never know that. I would never know that because you're very engaging. You're very, like, I would not know, like you don't have any impediments to your social skills, your personal, and that's, and again, I don't mean it as a knock to you and these young people. Well, no, but this is me trying to look up from a smartphone is having these conversations, talking to people. I think it's important. I mean, some of it could be, it's always hard to know. Some of it could be just you and I being old school, because you grew up before the internet. Maybe there is joy and deep human connection to be discovered inside the smartphone. We don't, it doesn't seem that way, because the smartphone's so new, maybe we just haven't figured out those things, because there's a globalizing aspect. There's a opportunity for you to connect with people from across the world in ways that. I have cousins in Ireland and England. I love it. I get a FaceTime or a WhatsApp and it's like, holy crap, they're, you know, three, 4,000 miles away and I'm having a conversation now. I used to send my grandma in Ireland a letter. I adored her. She passed when I was 10. And, no, I'm sorry, I was 11. And I sent her a letter, airmailed, and I'd wait and I'd wait, and about two weeks later, this airmail letter would come back and she'd call me Master Nils William Jorgensen. I would be so excited, open that bad letter. Handwritten, just like. Yeah, and like, and then I'd write her another one and I just couldn't wait for letters from granny. And now it's like, you know, that's kind of faded away. Yeah, I still write letters, by the way, handwritten. I do too. The way this all came about was I wrote a letter to someone to say thank you for cancer research. I'm blessed to be alive. My cancer, right? That's a good starting point for any story. I'm blessed to be alive. And my cancer was one that if I got it 15 years prior to 19, excuse me, 2011, I was a dead man, right? 15, 20 years before there was no drug to treat. I was gone, going home to see him. So there's this wonderful gentleman that donated hundreds of millions of dollars to cancer research, Mr. David Koch. He's since, God rest his soul, passed away. And he's a controversial guy, big time business titan. And, you know, there was, the press was just brutalizing him one day over something to do with his politics. Now, I'm a union guy, proudly served in unions, still in a union, you know? And he was not, you know, most business guys don't like unions, right? But, you know, most guys like me don't like working for $3 an hour, so we like our unions, right? And I reached out across the table, so to speak, and I sent him a handwritten letter to thank him, to say, we may not agree on everything, but I can't thank you enough. There's just this regular dude out there who is now living his life, watching his kids grow. Thanks to generous people like you who believe enough in cancer research, you've saved my life. Maybe, I can't say his exact dollars, but people like him. And he reached back out and his secretary said, oh, he'd like to talk to you on the phone. I go, well, he's kind of a busy guy, he wants to talk to me, he's a billionaire. And he got on the phone, he was like the greatest guy in the world. Invited me up to Sloan Kettering to dedicate a new cancer wing. It was like I was hanging out with my dad. And the sweetest man, just so kind, so empathy, because he was a cancer survivor. But now he's got the means to help people who've suffered his fate to a better place. And he was so real and it was so beautiful just to get to know, say, hey, you know what? This guy is a big time guy, but yeah, he's just a regular human like you and I. I'm a guy who went to night college and I went to the army and I'm a blue collar kind of dude. And here's this guy who went to MIT, like you, and he's a wildly successful billionaire, a genius. But yet he can sit down and mix it up with me and know that I was truly grateful. And that to me was just like one of the coolest little relationships I've ever had. It wasn't like we were hanging out, having barbecues together, but like, you know, it was just, I was so touched by his decency. Well, the basics of the, like cancer reveals, you know, it's like fundamental to the human experience. It's trauma, it's tragedy. It's like money, who gives a shit about money? Education, all of that is like weird new inventions. You know, life is short. You suffer with the various diseases. And that is a reminder that life is short and a reminder of the basic human connection. And that's why you can bridge that gap. Oh yeah. All sparked by a handwritten letter, which just makes for a hell of a story. And you know what, Lex? This is the commonality between us. A guy with three jobs to a billionaire. We both had that sense of a sledgehammer to the chest. Boom, you have cancer and you can't breathe for like 30 seconds. And then when your heart's just about to kick off and you take a breath and you go, I'm sorry, what'd you say, doc? You have cancer. And it don't matter what kind. One of my best buddies, Bobby's going through right now, a prostate, and I got way too many of my buddies with cancer, right? My buddy, Hugh, who became a vet since his first cancer, he was a fireman, he's now a veterinarian, right? He diagnosed me actually over the phone, by the way. When they couldn't figure out what was wrong with me. Well, Dr. Hugh, he nailed it to the T. And we talk. And the same thing that the dozen of my close friends that have cancer, the same thing we say is the fear. So Mr. Koch and I, we shared that same sledgehammer to the chest and that same fear. And it didn't matter how much money he had and how much I didn't. And you know, it's just like the morning of the trade center. There was big time brokers who went to their demise, right? Working in these firms, God rest them. And there was dishwashers, excuse me, dishwashers up on the windows on the world restaurant on the 107th floor, making five bucks an hour. And they died together, it didn't matter. It didn't matter if you had an armored car loaded with bills, you were done that day. And that's, I think where people need to humanize each other. Just because you drive around in a nice car and you got your own jet and you got this and you got that, don't mean nothing. When you're going, when you're in that vulnerable spot, you could have more money than the US reserves. Federal reserve, or you could have a welfare check. You're going. I learned that in a cancer ward. I had people in my ward that died on me. I was going around as a little bit of an ambassador because I was trying to, I was putting on a fake, I was putting on a fake like I got this, I got this. I was so scared. But when I got past that seven days of torture was working underneath, under the wing of a senior man, as we say. A senior man is a guy with a lot of experience. And he'll watch over you, make sure you don't veer off, like I veer off a lot in talking. And you don't veer off, and you get yourself hurt. In the morning of 1993 bombing, Henry Miller was my senior man. And I was the young guy under his wing. And he protected me. And toward the end of the day, he looked around. He said, kid, it's a bad day. He said, they didn't do it right. They blew it up in the middle. If they did it in a corner, they would have dropped this building half a mile down at Canal Street. But don't kid yourself. They'll be back, and they'll do it. And they'll do it right next time. And it's so strange and so prophetic, because he was there with them. He died with Dennis. He knew it. And like 1994, we had a training manual with a picture of the towers with a target. And this is not a matter of if, but a matter of when, be prepared. And it's haunting. It was like people knew, right? And we didn't stop it. And so we got off the bus, but just prior to that, coming over the bridge of the second tower, it's gone now. And we're just destroyed, because we're like, our guys are there. They're all in there. Now we're feeling like cowards, because we got there late. And initially, we're thinking there's 500 guys that are gone, because there was a tent alarm assignment, which means 50, 60 fire trucks, five to six guys per, you know, you're looking at. At least there was even more tent alarm, plus multiple alarms on top of it. There was a dispatch, basically equivalent of five to 600 firefighters. We figured, oh, they're all in there, all gone. All the police officers, Port Authority police, NYPD police, court officers just up the street from the courts, transit cops from the train tunnels. Like, just, you know, we knew everybody was going there, and now they're gone. So what you saw, what were we looking at? What did it look like? So you saw rubble, and then you knew that many, that 105 and 201, many of those guys are in the, they're dead. Yeah, and we thought 114 was in there, too. We didn't realize at that point. We didn't even realize that they had gotten under that truck. We thought they were all gone. But yeah, it looked like, it looked like a movie scene with just end of the earth destruction. It's just massive piles of intertwined steel, what was left of the steel. And you know, there was no cement. It was all just dust. And it was just a burning pile of dust and concrete and plastic. And it was just, everything was just pulverized. And it was truly hard to mentally compute that. Like, it was like, what? And then there was just fighter jets, a couple of fighter jets just circling. And you just heard them flying by over your head. I mean, you'd literally see the guy banking a turn around a Brooklyn bridge and just coming back. And I'm like, holy shoot, we're under attack? And we couldn't really get concrete intel as to what exactly we knew planes. But then we kept hearing there was multiple devices. There was devices in a battery tunnel. And there was devices on a George Washington bridge and in the subways. And it was just chaos. It was, I mean, we kept it together, obviously, because that's kind of, we try. That's what we do. But the just constant barrage of different reports, it was like, holy shoot. And then as we were being deployed, it was a little frustrating. But they were trying to take command and send us in groups now because they realized we have to start searching this. You could hear the alarms on the Scott Air Mask, the packs we wear to go into the building. It has a motion alarm. And if you stop moving for 30 seconds, it just sounds like this whining, just screaming bell. And it just keeps going and going. And you could hear multiple units of those going off. And you're like, wait a minute. There's guys with those. Where are they? And it's emanating from underneath the pile. And it was just surreal and truly like a war zone. I mean, I was a soldier in the reserves. And I never saw combat. And I would never claim that I did. But we trained. We trained for a lot of situations. And we trained in real life atmospheres and whatnot. And this was just beyond that by leaps and bounds. It was bizarre. Did you see the towers collapse? As we were coming over the bridge, the first one, as we were deploying from the firehouse, we had a television on. And I saw it go down. And we were so involved in getting gear together and getting teams set up and, OK, you're going to be with these two guys. And I just yelled, there's the guys. And they're looking at me. I dropped to my knees. And I started praying. They're like, what the hell's wrong? I said, I couldn't even say. I was like, 114, they're in there. And they're like, what? I said, the tower's gone. And all you saw on the TV was just this pile of dust. And I guess because they didn't see it going down, they probably thought I truly lost it. And then the realization came. It was like, wow, the tower's down. So now it was like, wow, this is really on. So we just took off and got that boss. And so if you thought many of the guys on 114 were dead, if you thought that, did you think you were going to die? I mean, if you're rushing towards the rubble? As crazy as it sounds, I never thought that the other tower would go down. I said, OK, maybe some freak chance that one went down. But no, the other one's not going to go. They're built so strong. I was in those towers so many times. I mean, I ate dinner up in the top floor restaurant windows on the world. And I'm saying, nah, there's no way. Like, how the hell did this one happen? But I was having a hard time mentally processing that the building was gone. And believe me, if you don't have fear in this industry and police, fire, military, then you're kidding yourself or you're a danger to everyone. I don't care who it is, as tough as they are, this and that. Everybody has a certain level of fear with doing this. And I don't care how long you do it, there's always that chance of something going bad. And everyone who does it has that certain amount of fear. But at that point, it was such a feeling of disbelief that fear wasn't even kicking in. It was just like, what the hell just happened? And I honestly think it was almost like a shock. And it just stayed that whole day. So the building is, before it collapses, is burning. It's just burning. I mean, upper floors, up in the 78th, up to the 80s. And then the way that the cut was from the plane, it wasn't just straight across. It was from the 78th, then on up to maybe the 86th. And then the jet fuel had come down and was burning down. And there was people on the ground who were doused with jet fuel that was already burning. And they were lit on fire on the ground. It was just insane how vast the destruction path was. As a firefighter, what are you supposed to do with that scale of fire? I think the first bosses in, the first chiefs, were just going to do their best to get, as we get hose lines, what our whole theory is, or our tactics is, to get water at the fire, at the base of the fire, and get the truck company, which is the ladder company. They're the guys who break the doors down, put ladders up, this and that, to get them to where the life is most expected and get them out of there. So I think the chiefs tactics at that point was, let me get multiple engine companies. Let me get four, five, six hose lines fighting this fire, this massive fire. And let me get 15, 20 truck companies up there just yoking people out of there. Yeah, but you got to go up the stair. Everything's not working. Yeah, guys had to walk up 80, 80, 90, 100 flights of stairs. And there's audio of officers and firefighters speaking to each other on the radio channels. And unfortunately, at that point in time, we had very, very bad communication system. We'd been fighting for years to get radios that work properly. We couldn't because it was a lot of money. We fought for years to get the full bunker firefighting suits, which is the pants and the coat. We used to have just coats and these roll up rubber boots and guys were burning to death and we had to fight. And unfortunately we lost three guys in one vicious, vicious fire in 1994. And then they finally said, enough's enough. Give these guys the gear. So it's a strange phenomenon in the first responder world and in the military world. It's really one of the most important things that takes place in society. The most pertinent organizations. And we can't get the funding we need. It's crazy. They'll throw money at every nonsensical thing. and the days leading up to it, I'd go around and try to comfort the other cancer patients. I had this one older African American gentleman, he couldn't talk because he had such advanced throat cancer. He was my roommate for a little while, but then he got worse so they had to put him by himself. And you couldn't understand what he was saying because his throat was just so radiated from the radiation. But if you put your ear down to him, you could make out what he was saying. And I'm not faulting the nurses for maybe not wanting to do that, right? They're busy, they got a ton going on, they can't spend, you know. So if he was in need, I'd put my ear down and I'd find out and I'd go get it for him. So when they moved me down the hall, they asked me to come down with my IV tower. He needed me. And I knew it was bad because he just, his look was gone. And I said, sir, what do you need? And he whispered, call my sister, I'm going. He had only one survivor in his whole life. And she was in North Carolina and he wanted her to know she couldn't get up, she was elderly. And I got the nurse and I got on the phone and I called his sister and I said, ma'm, I explained who I was. And I said, he can't really talk. He can't really verbalize too well right now, but he wants to say he loves you. And I put the phone down and he told her he loved her and he said, I'm going home. And that was it. And I hung the phone up and I said, ma'm, I'm so sorry. I said, you know, they'll notify you. And I stayed with him for a while holding his hand and then, you know, they wanted him to rest. And then I left and then I got the tap an hour later and they said, I'm sorry, he's gone. And then there was another girl and she was a young girl from one of the areas I work, young African American girl where I used to respond and I didn't know her, but I knew her neighborhood. And she had what I had, but they weren't sure which one. You know, leukemias, they're an elusive beast. There's 49 of them, right? And each one of them is like, they got their own little nuances, own specific treatments. So if they don't know what you have, they don't know what to do for you. And she refused to let him drill into her hip to take the marrow because it's vicious. It hurts so much. It's like someone born into your hip with a wood drill and it's no joke. And they asked me to try to convince her to let them do that or she was gonna die. Cause if they couldn't figure it out, it was advancing quickly. She was, so I talked to her and she said, I can't, I can't, I'm too scared. I said, but are you more scared to die? And she said, I am. I said, okay, I'll stay with you. I'll hold your hand. You squeeze it as hard as you want. I said, if you want, they'll give you like a towel or something to bite on, whatever. I said, but you get that pain out, but you need to do this so you can get saved. And she said, okay. And they came in and they, this huge thick needle, they just bore it into you. And she's screaming for her life and she's squeezing my fingers so hard and so hard. And I said, that's okay, hon. You keep going, you keep going. We got it. It's just 10 more seconds, 10 more seconds. They got it. They figured out her treatment and they got her onto her road to recovery. And then I spent a long time asking God, why do I have cancer? Then I stopped and I went, wait a minute. I didn't die that day with my friends. Shame on me for asking them why I have cancer. I had 10 years after 9 11 with such great ears. And I got to watch my little girl being born when John never got to see his son. So it was all gravy after that. And I said, but now I know why I have my cancer because I can empathize with people who have it. And I can try to be their voice when they can't talk, be their shield to try to take that pain because I can understand, I can walk their walk. And now I thank God for my cancer because it's made me a better human being. It's made me, I'm not gonna lie, it brought a lot of anger for a while and my family suffered it, but I really tried to go past that and heal and part of living out in the country. It's very, very healing for the mind and the soul. But I now thank God for the cancer because it humbled me. I didn't really need humbling. I wasn't an arrogant puffed up type of person at all, but maybe I was running away at myself a little bit and working on a TV show, I'm fine, man. 30 at the time, well, I was 42, I got sick. Life was cruising, man, it was great. And then all of a sudden it was like a blow out on the highway in the middle of the night and you were just veering off towards the guardrail. Yeah, you remembered, you're reminded that you're mortal and that's ultimately a connection to all the rest of us. Oh yeah, it's a good thing though, because that's the problem, I think. There's a lot of people running around and thinking they're immortal, right? You know, when you look at it, Lex, right? You look at the heartache in a lot of segments of people and anytime like someone that's got fame and wealth and success and they die tragically, a lot of times it's from a substance abuse or just some horrible death. And I used to say to myself, how the hell would someone with that much money and that much fame and this freaking mansion and I love cars, my son and I are just big car heads, you know, I'm like, you know, this guy's got a collection of cars and he overdosed because he was sad. And I'm going, how the frig are you sad? But then I stop and I go, okay, because maybe he doesn't have any idea who loves him. He's got a lot of people clinging onto him because of his success. And he just, he can't fill that void, you know? And then they fill the void with something destructive. And I'm not bashing people that have substance abuse problems or alcohol problems, I don't mean it that way. But what I mean is it's just sad that their level of despair is so high, on the surface, they look like they just got everything going on. It's all great, right? They're still human, still got to deal with the same. Yeah, exactly, because they want love, right? They want love and they can't really find it. Well, first of all, that's true for all of us. I think we're deeply lonely and looking for love and when we find it, that's what friendship is. Absolutely. And then that's true for whether you're super rich or super poor, it's all the same journey. My dad said all the time, kid, you're gonna end up working with hundreds of guys and you'll love a lot of them but he says when it's all said and done and you're all like me and if you've still got two or three of them that you talk to and you'll love. And I tell you what, I mean, I have thanked the Lord more than two or three of them and I have my six, I call it my six, it's the six guys that are gonna carry my coffin when I'm gone, right? Because I know this cancer's gonna come back, I know it. Like we get multiples, right? My friend Yvette just got his second. My friend Mike's had five of them. My other Mike has two of them, yeah. But I wasn't ready to accept it in 2011. There was so much more to do and it was so much, I was so scared, I'm like wow, who's gonna take care of my kids and who, you know, they were little. Nine, 11 and 14, right? It's like what the hell, I have two girls and a boy in between and they're beautiful kids. They're such good, good children, adults now. I mean, but you know, my wife's a drill sergeant, she's tough, she don't mess, you know, she's this big. So you're the softy in the family, I'm just kidding. Well, you know, it's funny because my son said to me, my son's 21 now, he's a good kid, you know. And he says to me, back when he was like 12, he goes, dad, I don't want you to be offended but I'm really scared of mom, I'm not really that scared of you. And you know, like I cracked up because it's true, she's gotta stand on like a milk crate to reach him because you know, she's tiny and he's tall, but it's true, but you know, but she was hard but fair, but loved, that's, see, this is the thing, you take any child anywhere from any background, if you love them, you nurture them, you teach them and you guide them, you have a successful adult. And see, that's the problem in our society, it's not judgmental, I'm not judging anyone, but we need to try harder as parents as siblings, as friends, but especially when we're blessed with a child, it's like, you gotta put that child first, it's like being a military personal responder, it's not about you anymore, now it's the team. So that little child is now the team and you know, your wife or your significant other, you know, like it's not about you anymore. And see, that's the problem is people have a hard time not making it about them, you know, like now it's really weird, my kids are 19, 21 and 24 and they hardly wanna hang with me because they're busy in their life, we love each other, they're probably tired of hearing me go on and you know, preach and whatever, but like, but they're adults, we did pretty much the crux of what we had to do to put them into adulthood. And I look back and I go, wow, I wish I didn't work so much and I wish, but then I say, no, but it was okay, my wife stayed home, good lessons, good, you know, just like. But ultimately, like you said, it's love. It is, it's the common, love is the most important ingredient on this earth and that's the problem what's going on right now, like take politics out of it, right? Take polarizing each other against each other, take all that crap out of it and just airdrop a bunch of love, right? Like when I worked on Rescuing Me, right? I love those people so much, they were such great, we had such a great crew and they worked so hard. You're a celebrity. No, no, no, not at all. If I was, it didn't really work out so good. I went on to be in the stagehand, no, I'm not pretty, but they don't want old guys waving bye bye hairdos, but it was funny, the crew, we became really tight, we had like, shoot, like 80, 90 people on a set, right? And you know, the first few episodes, everybody's trying to feel each other out because you know, you work with different crews, different people and this is going back, starting in 2004, so it was a different time and I love to hug people because to me, a hug is a true expression of love and caring. You may not know a person a long time, but you say, I care about you with a hug. Can I add just a tiny tangent? This was in the midst of COVID when I was in Boston and it was, you know, masks, like triple masks, nobody. And when I went to see Joe here when he was trying to convince me to move to Austin, Joe Rogan, and then the first time I see him, he's like, ah, you motherfucking big ass hug. And it felt so good. But people probably looked horrified. They're hugging. It was just him. Oh, okay, I know what I'm saying, but if you do it in public now, it's like you committed. But that expression, because I was so, you forget how powerful that is. Oh, I got some of my buddies. I give them a huge hug and a big sloppy kiss on their cheek and I, cause I love them. They, these are my brothers, you know? But on this set, I swear to God, it got to the point and I'm not trying to whatever, but there was people that would come up to me for the daily hug. And I said, what are you doing? And they said, come on, bring it in. And I give them the hug and they said, you don't understand. It just makes me feel so good. It makes me feel like you give a crap about me. I said, I really do. I said, but it touched my heart that people were seeking me out to get that hug to start the day. And I remember there was a guy in Manhattan, he was selling hugs for like 50 cents and I think he got arrested, right? It was just before COVID. But like, I wouldn't sell them if, but now. You've given them away for free. Well, now I got leukemia. I'd be kind of concerned to get into COVID. I mean, but like, I really think we need that. We need hugging booths, like in each city or each town. Like, because there's so many people that just want to know someone gives a shit about them. And that's the problem. It's like, like, you know, that's what I love about small little towns like where I am now in Tennessee. And I'm not knocking New York. I'm not knocking big towns, but I guess it's easier to do in a smaller area because it's just not this mass of humanity. But they'll stop and check on you. Like you're out in the road and you know, like I'm cutting and cleaning or whatever. Occasionally I'll roll a lawnmower or a tractor into a ditch cause I'm not a farmer, too good. But it's easier to drive a fire truck in New York. But they literally, oh, I was worried. I haven't seen you. And I'm like, no, no, I'm okay. But they literally like check on you. They're worried about you. And I'm going, these people hardly know me, but yet they're so caring. And that's the problem. Like this is what I love about my life. I spent a lot of time as, especially as a young boy and a lot of time in Ireland at my grandma's farm. And my mom comes from this tiny, tiny little village. She's out in the middle of nowhere. And the childhood home she grew up in still, my aunt and uncle live in it still. I just love it there so much. Cause everyone waves. Tennessee's similar. They wave, driving by and you're like, who the hell's that? I just wave, you know. But my cousin will point it out. Actually third cousin, second removed by, you know, Johnny. Like, holy shoot, I'm related to everyone here, right? But like everyone stops to say hello and how are you? And I have a problem doing that because my wife goes, people think you're crazy. Why are you talking to everybody? I said, like, I'll literally stop someone and say, how's your day going? Like, I mean, I'll randomly on the sidewalk. Then it looks a little nuts. But like, if I'm buying a cup of coffee. Oh, that happens here in Austin all the time. That's why I love it here on the sidewalk randomly. Yeah, no, it's just so nice. They'll say hi to me. I thought they recognized me or something. I don't give a shit who you are. They're just being nice. I was on the road coming back, driving from my family up north down to Tennessee last week. I stopped in a bathroom and it was closed. The girl was cleaning it, whatever. She's working so hard, whatever. And she goes, sir, she goes, if you go down the hall, there's a family restroom. Feel free to use it. You know, she didn't have to do that. And I went down and I'm old. You need a bathroom, you need a bathroom, right? And I walked back out and I said, ma'm, I said, I want to thank you for being here today. I says, the bathroom was immaculate. It was, it was like my army bathroom in the barracks. It was spotless, right? And I gave her $10. I said, I'd really like you to buy lunch with me today. I said, you really didn't have to do me that favor. And she goes, no, sir. I said, no, no. I said, I want. And it was like I gave her a million bucks. And I say to my wife now, I've been praying to be a billionaire. She goes, that's a sin. I said, no, no, you don't understand, right? She goes, oh, you're Mr., you know, Mr. God. I said, no, no, no. I said, you're getting it wrong. I said, I'm praying to be like a multi gazillionaire because I want to give it all away. We used to have a sign in ladder 114 until some other rival truck company stole it, right? Cause that's what we do. You know, they get sent to cover your district when you're at a fire and now your stuff's missing. And the old timers had a sign that says, I am content. Because if you got to ladder 114, that was considered such a great place, such a great assignment, such great guys. You had to be vetted to get there. You couldn't just randomly go. And it was a little exclusionary, but they wanted good guys. And I said to myself, that's who I am in life right now. I am content, but I'm restless because I want to really do a lot more good. It's like this podcast. I want to make sure that it's not forgotten. And I want to make sure that these charities that are really, really helping people get recognized. But I'd like to take it a step further, right? A friend of mine runs this foundation for young folks suffering mental illness and in crisis. It's for someone that we love dearly. And he's on a mission now to get therapy dogs for really, really mentally wounded warriors, right? A lot of these young soldiers are having a really hard time. And now they could be out a while. They may have come back in country two, three years ago. Now it's just starting to set in. And there's a waiting list for thousands of therapy dogs. And he said that they can't get enough of them quick enough. But he said, when you see the response, the way these veterans just light up when they get these dogs, it just changes their life radically, immediately. And I said, that's it. God, I don't know how I'm going to do it, but I want to be a gazillionaire. And I don't want any picture, photo ops, this, that. I just want to go, there's a dog, there's a dog, there's a dog, there's a dog. And then I want to build veterans land for these vets who just need a nice clean place to live. So why don't we take these old army bases and Marine bases and Navy bases that have been shut down. They're just sitting there rotting away. I was in the army in Alabama. My old Fort McClellan is three quarters vacant. It's sitting there. They just did a documentary on it. It just looks like zombie land going back to zombies. So why don't we take that and renovate it and say to vets who are struggling, hey guys, you're going to live here. And they take the old army, the places where they had all the supplies, there's massive buildings where you could just retrofit it and make light manufacturing within two weeks. Give these guys jobs. There they live, there they work. They'll take care of it. Military guys, they teach you how to take care of stuff. How the hell in this country should any vet come back home and be homeless? Because now they have to dedicate their lives for six, seven, 10, 12 years, five, six deployments making $7.50 an hour. And then they spend seven years or they get a whopping $16 an hour. They walk out making 35 grand. And now no one gives them a job. No one gives them a chance. So very quickly they end up homeless by no fault of their own. And I don't know how that's even possible. The people in this country who've given the very most and they're struggling, they're hurting. That's not fair. And my whole thing is if I can have this dream of succeeding, so to speak, I want to try to change it. So that's why I'm praying to be a billionaire. My Irish mother probably wouldn't agree either because you're not supposed to, right? Well, I'm the same with you. The more money you have, the more you're able to help. Yeah, you can put smiles on people's faces. I have to ask you, the US invaded Afghanistan in October, 2001 in response to terror attacks. Now 20 years later, we still had a presence and abruptly withdrew all troops. What do you think about this war across the world that was sparked by this tragedy? Whenever you do something quickly without thinking it out, thinking it through and planning, it doesn't succeed. I understand that we needed to exit. I mean, how long were you gonna stay over there? And we've lost over 7,000 of our young souls over there. For sometimes people, I don't know if they're grateful for it or not, right? I mean, I don't know. So there's the other element, and sorry to interrupt. One is the financial of $6 trillion and that money is not just money, it's education, it's everything, it's money that could have gone towards, first of all, the first responders, but all the servicemen and women of all kinds throughout this country. And then there's the other side, which is the over 800,000 people who died in direct result of this conflict. So not just the American side of the troops, but just people who died, those humans. And those humans, many of them civilians, that's spreading hate, especially if you have leaders on the other side who frame the death of those civilians in certain ways that just spreads hate throughout the world. And so you think about this kind of 20 year saga and think, what are the ways that money could be spent better and what was the way that we could have spread more love in the world versus hate? And you wonder, but then the other side, what is it? I'm not sure who says this line, but it's something like we sleep at night because there's a rough men out there ready to fight for you. There is some sense in which we have to make sure that there's strength coupled with the love, right? Otherwise evil men will do evil onto the world. So it's a very difficult decision, but then you look at the final picture and it's like, what have we gotten for this $6 trillion? What have we gotten for this 20 years? The thousands of American soldiers who died, the hundreds of thousands of civilians who have died. You know, it's a troubling subject for me. I'm a patriot, I love this country. I love it with my soul. And I was just about to head over to the first Iraqi war and we went out for desert warfare training and then it ended. I was at that time a combat medic assigned to an armored cav unit. So basically tanks driving around an armored personnel carrier and when it gets hit, then you tend to that guy, try to save his life. I didn't wanna go. I may sound like a coward, I did not wanna go to war. I would have went willingly if I was sent to defend my country, I took my oath. I didn't join the military to kill, but if necessary, I would. I'll use the analogy of cancer. If you have a cancer and you're aware of its presence and you don't annihilate those cells and take them out quickly, it's gonna spread and it's gonna kill you. Those evil bastards that flew those airplanes, one of those airplanes had a little three year old child in it from Ireland where my mom's hometown. A friend of mine who since died of a heart attack from 9 11 toxins, he found her shoe with human remains in it. And he thought someone was messing with us because we didn't know there was any kids in the building. He says, boss, there's a baby shoe and it looks like there's something in it, but there's no kids in the trade center. I went, the plane, it's a little girl shoe. I can never get that shoe out of my mind. The evil bastards who perpetrated that needed to have missiles strike and rain down upon them and annihilate them like a cancer that they are. What just fascinates me is they'll show videos of these guys flying around and pick up trucks with 50 cows on the back. It's like, well, wait a minute. If a camera crew can get this footage, you think all these freaking drones and planes and radar assisted systems can't just go whist, whist, whist, goodnight, you're gone. So kill the cancer, kill the cells, get rid of it, get rid of it quickly and go into remission. Like an undeniable show of force that sends a message that gets rid of most of the obvious centers of terrorism. And that note, that's though, because we offline mentioned a discussion with Jaco and maybe romanticize view and mentioning brothers in arms by dire straits and saying we're all brothers in arms even when it's on the opposite side of fighting, which is more of a vision and growing up in the Soviet Union you saw about World War II, that it's all just kids thrown into the kids sent to die in all sides. But then presenting that to Jaco who was in Iraq, he did not see as brothers in arms, which is his basic statement is there's evil people and some people don't deserve the compassion. You give them a few chances, they don't take the chances they have to go because they're spreading evil onto the world. And so it's not, we're not, all of us deserve a chance. Oh no, absolutely, but the difference though, and believe me, I, Jaco, I am from a way, way minor league compared to him, right? I mean, this man was right there in the firing line, but I can understand his analogy because when you think about it, right, those young conscripts back in Germany and Russia and all the countries where they were being drafted, even our guys were being drafted and thrown into this. They were gallantly and bravely defending their country. Now, I'm sure the young Germans felt, well, hey, Hitler must be right, right? And young Russians felt, hey, Stalin must be right. And the young Americans figured, hey, President Roosevelt must be right. So they were romantically in a sense defending the honor of their country, of their motherland. The difference between those, so they did have that commonality. If you and I were firing across each other from France to Germany or, you know, from Germany to Russia or whatever, we're just these two kids who got thrown into this. We didn't freaking ask for this, right? But the difference with Jaco's enemy is no one was attacking their country over there, right? No one was taking their country over. Maybe in their mind, they didn't want people trying to build their government, this and that. I don't know, I don't know enough about the history there to really elaborate. We didn't attack them. And if a soldier attacks a soldier, that's an understood concept amongst warriors. But when a soldier attacks a civilian, now you're after a different beast, and you've written that beast off, if that makes any sense. Yeah, and the enemy, I mean, as Jaco explains, the enemy in Iraq and just certain parts of the Middle East is essentially terrorists who don't value the lives of the civilians of their own country. They don't. And so it becomes like this weird guerrilla warfare slash game of violence that ultimately allows them to gain more power within their country, but they don't care if they're playing with civilian lives as pawns. If you have a child who dies that's a civilian in their country, that could be seen as a positive for them because they can use that to leverage for more and more power within that country. So when you're fighting an enemy like that, that's a vicious, that's an evil enemy. Absolutely. It's like snakes are beautiful, but if you go pet a rattler, you're getting bit and you're getting dead, right? And that's with terrorists, you've got to cut the head of the snake off. And I feel, no, don't commit our guys to be there anymore. But what we need to do is go with tech warfare. If we have intel from drones or planes or whatever it is that so and so and so and so and so and so are driving down in that pickup or whatever, take it out and do it again tomorrow and tomorrow and tomorrow. And maybe they'll get the message after a while, oh shit, these guys aren't messing around. Instead of throwing wave after wave of our brave warriors, brave SEALs, brave special ops guys, and God bless them for what they do, I couldn't do it. I could not have done it. But they have to be now sitting home going, what the hell? My friends, my body, myself, like they must feel so betrayed because they passionately went over there to cure a cancer, the cancer of terrorism. And now the cancer is back. And I hate to say it, but I think the cancer might start running wild. We need to change our tactics up. This is just my opinion. I can't see committing all of our guys to a continuous eternal war. But I think what we need to do is hit surgically and hit hard at that cancer that is over there. We are never gonna rebuild that region. It's just, it's thousands of years of traditions that you're not going to change. It's just some people are unchangeable because they don't want to. And we have so many social problems here in our country, I think that we need to fix first. I heard this spoken in the past by many people. It's like the garden theory. You have your garden with a fence around it. You tend to your garden. There may be weeds on the outside of the fence, but as long as they're not inside your garden, your garden will prosper. And I know some people don't agree to that America first and the whole take care of our own, but it's like, how are we gonna take in more people now? And I have a human feeling for them, but it's almost like the lifeboat theory. How many people can we take into the lifeboat before the lifeboat itself sinks as the ship is going down? So if we can't take care of our own homeless vets and our own homeless people, and it's just gonna become worse. And it doesn't make any sense. It's just like, we need to just take a timeout and I think switch our tactics a little bit. And invest into helping people here at home. Absolutely, absolutely. There's very few as obvious of cases as the first responders in 9 11. That one of the things that I really wanna kind of talk about at least a little bit, we've already talked about the amazing project that you're doing the 20 for 20 podcast that you host. We mentioned one story, Steven Siller, is there other stories or maybe you can speak out at a high level, what are you hoping to tell? And all these different stories that are weaved about that connect the tragedies and the triumphs, the heroism of that day and the days and the years that followed. You know, Lex, it seems like the common few themes, the common threads are being selfless, helping out others even though they might be a stranger, in acts of kindness, acts of love, and it seems to all be weaved together with faith. They all seem to have some sort of faith. I mean, we have one gentleman, Mark Hanna, and he's a Coptic Egyptian priest, and he's an immigrant to the United States. He was a port authority building engineer. And with his crew who subsequently passed away, the crew did, he was effectively rescuing dozens of people on the upper floors, and his boss ordered him to assist an elderly gentleman who was 89 down 78 flights of stairs to get him out. And in stopping on the 21st floor, he figured they would just wait there for medics. He came across Captain Patty Brown of Ladder Company 3, who told him, no, sir, you need to evacuate. And Captain Brown picked his brain a little bit about the structure because he figured, found out he was an engineer. And Captain Patty Brown continued on to effect rescues, and he and his crew were killed. But father, he's now, Mark was able to effectively evacuate this gentleman. They were the two known last survivors to come out of the tower. He now has dedicated his life to becoming a Coptic priest in St. Mary's Church in East Brunswick, New Jersey. He did this for a total stranger. And he said he was inspired by his bosses who died and his friends. One of his best friends was an Italian man. The other man was a retired Navy SEAL, Hispanic man. And they were part of this melting pot. And no one looked at each other that day, what color, what race, what belief are you? They just said, hey, you're a human in need, let's go. And we have the story about John Field on his mission to help the responders. We have a young lady, Mariah, whose birth father was on flight 93. She had not even met him. And she had this premonition that somebody in her family was killed that day. And her adopted mom said, no, everyone's fine. Three years later, when she was legally able to find out who her dad was, she found out that her dad, Tom, was actually on that plane as part of the Let's Roll team. And we have a gentleman, Robert Burke, who's an actor, sweetheart of a man. He's a gentleman and he's a very, very popular actor in Hollywood. He was on Rescue Me, Blue Bloods, Gossip Girls. And Bobby, my friend, as I call him, is a volunteer fireman now. This man doesn't need to get out of bed at two oclock in the morning and help people with a stroke or a burning garage or a burning house, but he does because he wants to. Because his best friend was Captain Patty Brown. And his other best friend was Father Michael Judge, who was our chaplain, who was killed, literally blessing the victims at the site, had just given last rites to the firefighter I mentioned earlier, Danny, who was killed. And Father Judge was in the lobby of the building, giving a blessing, praying to God to please stop this. And he was struck by debris and he was killed. And Bobby goes on to elaborate about Father Judge's story. Father Judge used to walk the streets of New York City, helping AIDS patients just with whatever they needed. And he was a Franciscan friar. They wear sandals and a robe. They just live very humble lives. And it's just a common denominator is loving each other and helping each other, regardless of you know the person or not. And really, when you think about it, that's how America was made. We fought for independence. Stranger fought next to stranger and fought tyranny because they wanted freedom. They wanted to be able to live, love, pray and prosper. And they fought and died alongside of strangers. And it's sort of symbolic of what happened that day. And then strangers from around this great country just flocked in by the thousands to help. They didn't know who was in that pile, but they didn't care. That was another American. And what I ultimately am trying to do involved in this beautiful project is spread the message of doing the right thing. Look at these examples. These brave people who didn't have to, especially the civilians, they weren't paid to run back in there and help person after person. And they had no obligation. They could have just said, hey man, I'm out of here and just bolted. But they didn't. So we're just trying to say to people, let's bring back that unity and that feeling of 912. As strange as 912 of a day it was, it was so sad because it was the first dawn of the sun where we realized this wasn't a dream. This was real and it's not going away. But the beauty of it was there was thousands of people lined up along the West Side Highway with signs and American flags. And they were from every country and every race and every creed. And it didn't matter who they were, but they all shared one bond, love. And they were hugging and crying and thanking rescuers. And it brought the morale so high for a group of people that was so beaten down the day before. It just started lifting the morale and making us realize, you know what? People really do give a crap. They really do love each other. And now I'm gonna be honest with you, I've been doubting that a little bit lately. I still have these examples of it. You know, that lady who helped me last night with the phone and just, you know, I know there's these shining little examples, but sometimes I think, I don't know, are we running out of them? Well, I gotta give you some advice. So there's two words that were repeated often in the days and the years after 911, which is never forget. So might I remind you to never forget about 912. I mean, those words, you talked about that, you know, there's people, what is it, college freshmen, maybe. They weren't even born. They weren't even born. And there's people in the 20s that were too young to remember or to understand the events of that day. But I think what that day, as you're describing, means, it's not about a terrorist attack. It's about the unity that followed. It was tremendous, Lex. I never felt so proud. I was always proud of this country. You know, I remember my grandpa Nels used to walk by, I'd see a flag, I'd hear the Star Spangled Banner and he'd tear up and I'd say, Grant, why are you crying? He said, I'm not crying, it's the tears of joy. I love this country so much. And I just remember like feeling that way. I felt that way 910. I felt that way on 911, but then on 912, I was just so proud of just the people, the way they stepped up. And I just want to try to see if that can happen again. And I hope it's not necessary for us to have another tragedy to bring that about. Let's do that without the tragedy. Let's just stop and say, hey, you know what? Let me listen to what this guy has to say. And maybe he's, he probably won't convince me, but maybe I'll go, well, you know, I never thought of it that way. Stop the finger pointing, the bickering, the tantrums, the fighting. It's just not necessary. It gets you nowhere, right? It's like, you know, I was two years old and I'd stomp around because I wanted a cookie or a piece of candy. I still didn't get it, right? You know, turned blue in the face and whatever, got a little swat in the rear end, but it didn't get the candy. And that's what we got going on right now. Everybody's just stomping around, being a baby. Stop, just stop. We're really lucky. Look, the country's not perfect, right? You know, but it's damn good. It gives us all these opportunities, you know? Like I said, no one's rushing out the gates to get out of here. They're freaking, I got a cousin of mine. I love him dearly. My cousin Tony in Ireland. And he said, he's just a little older than me. He's in his fifties. He said, man, I should have done it. I should have went to America. My dad said, go to America. I went to England and he went back to Ireland. And you know, but he's happy in Ireland. It's his home. But he said, wow, what a place of opportunity. And I said, it's never too late. He goes, yeah, but you know what? You get tied down. And I understand that. I thank God my mom came here at 16. I thank God my grandpa got on that ship. But in his 20s, 27, I think, you know, with not a nickel to rub together. I thank God they did it. Cause I don't know where else I would have ended up. There's no place else I want to be. And I thank God that there's people like you who rushed towards ground zero to help other human beings. And I believe that that human spirit is ultimately represents the best of this country and the best of this world. Thank you for the stories you're telling, for your perseverance in that. And thank you for welcoming me to the crew. You're very welcome. I'm proud. And we'll take you any day. You look like you could do the job just fine. I love lifting heavy things and doing dangerous things. So I'm proud to be part of this country and part of the Tally Ho now. Well, you are definitely an attribute to America and we're glad you chose to come here. You know, Lex, it's such a beautiful place. It's a beautiful melting pot. You know, if we were all the same, it would be kind of a boring place, right? Kind of boring. It really would. But it's just such a great place. And I just want to say thanks. It's an honor. It's an honor to have someone to let me sound off and it'll be even bigger honor if somebody will listen to me and just say, hey, you know, let me just try to do something good today. And you know, that's the tunnel to towers mantra is let us do good. And I just, you know, I got a really big credit card with God, a big balance, right? I need to pay him back a lot and I need to pay him forward. And I'm just going to spend the rest of my days trying my best. I don't know where this is going to go, what it'll lead into, but I really would like to get those dogs or those vets and build them that village and just keep going on from project to project to just say, when my final day comes and I'm laying there and I say, you know what? I really made the most of that second chance God gave me way back in 2011. I mean, I hope it's 30, 40 years from now, but even if it's 30 months from now, I'm giving it the best shot. So thank you, sir. I appreciate it and wishing you blessings and success in your career. Keep up the good fight and you're always welcome back to Texas. Oh, I love it. It's great food and a little hot, a little hot, but I can deal with it. We don't do so good Irish in the sun, you know? Well, the barbecue and the people are worth it. No, they are, they're awesome. I was down here for some storm relief a few years ago and I tell you what, I fell in love with it. The people are great, it's a great state and yeah, I'll definitely be back again for sure. Thanks for talking to me, Neil. Thank you, sir. Appreciate it. Thanks for listening to this conversation with Niels Jorgensen. To support this podcast, please check out our sponsors in the description. And now let me leave you with some words from Franklin D. Roosevelt. Human kindness has never weakened the stamina or softened the fiber of a free people. A nation does not have to be cruel, to be tough. Thank you for listening and hope to see you next time. But when it comes to gear, equipment, protective equipment, trucks, this couldn't get it. Just all the ways you could take care of people. I saw since 9 11, the wars in the Middle East have cost America over six trillion dollars. And the amount of that money that was spent on the soldiers, in this case the first responders, is minimal. Compared to it, yeah. Almost nothing. They, Lex, they closed down. I believe it's either seven or eight. In May of 2002, they closed down nine firehouses in New York City for budget reasons. We hadn't even finished cleaning up the World Trade Center site and they slashed the budget. And still to this day, have not reopened those firehouses. There's a million more people now living in New York City than there were in 2001. And the fire protection is way less than it was. And it's a sin. It's really a sin. Can I ask you a difficult question? So there's this famous photograph of a falling man. So many people had to decide when they're above the fire, in the fire, whether to jump out of the building or to burn to death. What do you make of that decision? What do you make of that situation? Those people who jumped, those were acts of sheer desperation. I've been in fires and just minor burns, but minor in situation. But I've been trapped, caught somewhat. Ended up in a burn center for nothing serious at all. But for those brief seconds, half a minute was, thank God, if I didn't have my fire gear on, I would have been burned to a very, very horrible level. Those people were burning alive. And they had the choice of either to stay there and burn alive or to launch themselves. And some of them, I don't fault them, but they had a few folks, they won't show it anymore because they say, I don't know why it offends some people, but they had a couple folks that took umbrellas and they took garbage bags because they thought that it would slow down their acceleration rate to the ground and maybe, just maybe they wouldn't be killed. And that's, to me, a true sense of desperation for humanity to say, I'm going to die either way, but let me take my chance. And I don't know the exact number of those folks who did that, but our first member of the fire department killed firefighter Daniel Serf, aged 216, was struck by a jumper. And one of my dear friends was ordered to help take him and they knew he was passed away because he was hit by a flying missile. I mean, 120 miles an hour, a body lands on you. Those two bodies are now crushed. And they were ordered to take that firefighter and bring him across the street to Engine 10, Ladder 10. It was literally a firehouse, less than 100 yards from the facade of the Trade Center, from the Trade Center complex. They were literally right there. And there was plane parts that went into that firehouse, landed into the front doors onto the roof, but the building itself was not destroyed. So it was used as a mini command center for quite a while. So my friend was ordered to take Daniel's body in respect and bring it over to this firehouse and give it some semblance of dignity and lay it out on one of the bunk rooms, the bunks we have in the bunkhouse, and just cover it with a sheet and put a sign, please firefighter killed, do not disturb, and then we'll get to him later because obviously this operation is gonna go on for days. And my friend, who's such a great, wonderful guy, is so still to this day, filled with guilt because if they weren't taking his body out with the respect and dignity that they did, it took a while because it's a tough situation. His ladder company was coming over the bridge. There's a famous picture of Ladder 118. You see this tractor trailer fire truck. It's the one when the guy in the back also drives. And it's a zoomed out shot, and you see the Brooklyn Bridge, and you see only the fire truck in the middle, and you see the two burning towers in the distance. Well, his engine company was just ahead of them on the bridge, and the only reason that engine company lived is their initial duty assignment was to take that firefighter and bring his body over. It's like the military. We don't leave anyone behind. These are our guys. As some guys say, it's all about the guy right next to you, and nothing else really matters. When that guy right next to you goes down, it stops. You get that guy to safety, or if he's dead, you get him out. So in that time frame, that saved his life. But that's a heavy burden to carry now for the rest of your life, because you say, if I wasn't helping my dead friend, I'm dead. Yeah. What did it look like at Ground Zero? What did it feel like? What did it smell like? What, you said there was a sense that it was almost like a war zone, but can you paint a picture of how much dust is in the air? How hot is it? How many people are there? And again, how did it feel like? It was just, it was a scene of controlled chaos, controlled because there was a semblance of command, and we were just trying to do our jobs. But it was such a frantic pace because we're now digging frantically, knowing that there's life underneath this pile. And this is throughout the afternoon of that day, the evening. Yeah, I mean, this was nonstop, just nonstop, really, for days. But for my particular crew, we literally kept going. We initially were dispatched over towards number seven, had just gone down, and we were searching the post office that was there. There was reports of people trapped. And we painstakingly searched every single inch of that building to make sure no one was left in there. And then we were deployed to the pile, and the pile is sort of ambiguous because it was just such a vast, vast pile. I mean, it went for city blocks. And we were assisting in the retrieval of two Port Authority police officers. We're lucky enough to survive, but they were trapped. They were deep down into a crevasse, and they had to be physically dug out and extricated. So there was a couple hundred, few hundred guys involved in that process of bringing in equipment, jaws of life, airbags to lift steel, to cut pieces of steel. It was just a huge operation. And we were back toward the logistics end of it, shuttling in gear and bringing in stretchers, bringing in oxygen, whatever was needed. And you were trying to climb over this jagged pile of debris. It wasn't like you just walked 100 feet on a street with something. You were trying to climb over this I beam and then down into this hole and then back up that hole. I mean, just to run one piece of equipment took a half an hour to get 100 feet, 200 feet. You know, mind you, some of these pieces of equipment are 100 pounds, you know, generator for hearse tools, this massive motor on a frame. Unstable ground. Unstable ground, just horrible conditions. Fires were still burning aside you, beneath you. And at one point, I kind of veered off to the side and I was with this other fireman from my father's old ladder company, 172. And it was strange because we were quite a bit down, like 70 feet down into this ravine of debris. And he says, brother, what do you hear? And at the time it was like dust, it was like sand just falling down a pile and it was hissing from gas pipes and water pipes. And I said, I hear the gas lines, I hear the sand, I hear the concrete. He goes, no, no, what else do you hear? And just the side of us was a lady's pocketbook and a high heel shoe and someone's sneaker with nobody with it. And I said, I don't know, I don't hear anything. He says, me neither. He goes, no one's coming out of here. And I said, no, no, no, there's gotta be someone coming out of here. I mean, there's just thousands of people in here and they're coming out. He says, brother, we would hear them calling for help, they're gone. And I still at that point thought there was a chance. And after about the fourth day, they just said, this is a recovery now. There's no more life, there's no more chance. And then that first night we went full tilt till my crew, my specific crew of 12, 15 guys. And four in the morning, we just couldn't breathe anymore. We couldn't see, we were caked just with, it was like if you took flour and just kept dousing yourself. And the Lieutenant just said, look, guys, we're gonna go back, we're gonna get some medical aid and then we'll come back in a few hours. And we took a city bus back through the battery tunnel and unbeknownst to us that morning, this off duty firefighter, Steven Siller from Squad Company One, he raced down there with his pickup and he couldn't go any further because the traffic was stopped up because they had a report of a bomb. So everything was held up and he grabbed his fire gear and he put it on, stuff weighs about 60 pounds. And he ran through the tunnel. Two and a half miles, got to the end of the tunnel, fire truck was coming in from the other way. He hopped on the back, got him up to West Street, jumped off, tried to look for his company, where they were and he was never seen again. He just ran through the tunnel. Ran through the tunnel and he got there to help his team, right? It's all about the team, it's all about the guy right next to you. And he's the Tunnel to Towers Foundation, Steven. His brother Frank decided in his name in perpetuity, he's got a fund that now builds a home for every Gold Star family, for every seriously battle wounded warrior, for every seriously wounded first responder or killed in a line of duty first responder. If they had a home, they'll pay the mortgage. If they didn't have a home, they give them a home. And especially if it's a severely battle wounded, they give them a smart home because these poor guys come home with no limbs. And so the beauty of Steven and his selfless act was that he's now helped thousands and thousands of people. I mean, the Tunnel to Towers is incredible. That's part of our mission is to bring awareness to these great people at Tunnel to Towers, what they do. They've raised $250 million to help protect the protectors, to rescue the rescuers in a what's become, unfortunately, a somewhat ungrateful society. But they will not forget these great guys. So you tell Steven's story. He's one of the 20 people that you talk about in the new Iron Labs 20 for 20 podcast series. If you can just linger on his story a little longer, what does that tell you about the human spirit? That this guy, the Tunnel couldn't drive through, so he just puts on that heavy pack and runs. What do you make of that? That shows the depth of a man's soul. He didn't have to do that. He could have turned around and went home to his family, and nobody would have shamed him. But he's one of those beautiful, brave people that take a job that really doesn't pay a lot of money. And you become a cop or a firefighter or a nurse or an EMT or a medic or a soldier or a Marine or airman, sailor. When you take these jobs, you don't do it for fanfare. You definitely don't do it for money. I mean, those 13 brave souls we lost a week or two ago in Afghanistan, they're brand new soldiers and Marines. They make $22,000 an hour, but they don't work 40 hours a week. They work 80, they work 90 hours a week. So they make it about six bucks an hour. And you know what? They sign off. And firefighters and cops and medics and EMTs, nurses, emergency room doctors, they don't really make a lot of money. I mean, they're starting salary right now for a New York cop. I was a New York cop for two years first. I made 12.25 an hour back in 1989 to get shot at during the crack wars. If you made $11 an hour with a family of four, you were entitled to welfare back then. So I was just above the welfare level, risking my life. And these are the guys that are getting ripped up now. Right? And look, I won't get into any politics, but like that says something about someone's soul that they're willing to take a job like that and get now, get zero respect. So a guy like Steven, what that shows is the depth of that man's soul and courage and determination. It's hard to be selfless in this world anymore, but I still know a lot of selfless people that just put on equipment every day, bulletproof vests, fire bunker gear, stethoscopes, you know, flak jackets, military helmets, and they go in and they do it smiling. That young Marine that passed last week, she was photographed and quoted as saying, I have my dream job, but she was holding a little Afghani baby. And she was dead a few days later. She was so thrilled to be making $7 an hour helping people, right? Isn't that huge? Like that to me says, that's a true sign of character right there. And it's important for our society to elevate those people as heroes. Let me ask you about firefighting. What do you think it means to be a great firefighter and a great man, a great human being in a situation like you were in in 9 11? You know, that's kind of a broad term. Like some, you know, you can go to different firehouses and they might have a different definition of what they consider a great firefighter. But I think in the industry as a whole, if you're willing to put everyone else before you, especially your team, you know, as we say, there ain't no I in team, right? It's T E A M and there's no I in there. It's all about those guys and girls next to you. If you can do that, that makes you pretty great. You put everything else second and you just run in and you run in with that team for strangers. You know, I've had the honor of, I spent almost 25 years of my adult life serving humanity, my country, my former city. And the people I worked with were giants. And I don't mean that in height, I mean, but I mean that in spirit and in soul. I saw some of the most heroic, selfless acts. And then I saw some of the behind the scenes that were so impressive. You know, we'd go to the movies, so impressive, you know, we'd go to a fire around Christmas and the family would lose everything. And even when I was a cop, same thing, you'd come back either to the police precinct or the firehouse or the EMS station. And someone would put together a collection and say, hey guys, hey Lex, 50 bucks a man, you know, the Smith's down the street, just lost everything, we're gonna go get some presents for the kids and some turkeys. And not one of those guys questioned that. And they were making 12.25 an hour and they still came up with 50 bucks for that family. But see, that's the stuff the press won't show you, right? They don't wanna show that humanity, that soft edge. See, when you're a warrior, you need to have this rough shield, this rough exterior. Cause if you don't, you die. But a true great firefighter or responder or a cop or military personnel, they have that rough exterior with that soft underbelly, that heart, right? And that's, to me, the true great ones. Some of them, they just have a hard time doing that. There's no shame in showing your soft side. Well, you got your dad to say I love you back. No, that was huge, man. That took me 22 years, Lex. So you were a firefighter for 21, I was 22 years. Why did you become a firefighter? Oh, my dad, I mean, I was five years old and I went to his firehouse and there was these, at the time, they looked like giants to me with mustaches and the trucks smelled like smoke and the gear smelled like smoke and the tires and the diesel fuel and that one was like, this is what I'm gonna do. And then they bring you in the kitchen and they stuff you with ice cream and cake and everything. And then I go home to my mom, shaking with a sugar cone and she's mad at my dad, but yeah, it was just, oh, I was like, I gotta do this. It was like, they were like a baseball team in a garage with a truck and these big tools and big coats and helmets and they were just laughing and having fun and I'm like, yeah, man, I'm doing this. And I knew, I was obsessed with it. I mean, I was so pissed that the fireman's test came out when I was 14 and I couldn't take it, you had to be 18. And it was done, the test was graded and whatever. So my dad, now there's a copy circulating because it's old now. And he goes, yeah, yeah, this is what you're in for. And I took it and I did it like it was real and I got a 99 and I was so pissed. I said, I wanna get hired. He goes, you can't, you're 14. But I just wanted to do it so bad and I just wanted to help people. I just wanted to be like my dad, he'd come home smiling as tired as he was and he fought fires in the 60s and 70s when the city was burning and he's still as exhausted as he was, he'd still be smiling. I wanted to smile at work and I used to, I got paid to laugh and joke. I got paid to cry sometimes. But man, we laughed a lot. We really, it was, the chop breaking is just, it's just unending and it's great. If you don't mind, can you tell me, you were really kind enough to give me one of these shirts with 114. Can you tell me the story of 114 and Tally Ho? I wear proudly, I served eight years in that command and I didn't finish my career there. I passed the lieutenant's test and once you do, you have to leave. The story behind Tally Ho is back in World War II, there was this gentleman named Bad Jack Carroll and Jack was an airborne ranger and my father in law was also on the department and he knew Jack. And Jack came home, Jack jumped Normandy and stormed up through the Battle of the Bulls in Bastogne and he came back, greatest generation as they all did and they got jobs and they went right to work and they were treated better back then, vets, right? And he got on the New York City Fire Department and he got assigned a ladder 114 and they first got radios back then and when Jack, he would drive the truck, you're up there with the officer, either the lieutenant or captain, so if the boss is off the truck, you operate the radio for them as the driver. So when they called him and they'd say, you know, ladder 114 responding to 52nd Street, 3rd Avenue, Structure Fire, you're supposed to get back and say, ladder 114, 10 four, but he refused to do that. He'd say, ladder 114, Tally Ho, because that's what they'd yell when they'd jump out the plane. So all these years later, it stuck and it's a little bit of a bragging right, but out of 350 engine and truck companies in the whole New York City Fire Department, we're pretty much the only one that's called by their nickname on the radio, not their number. So it tweaked some guys off in other places, you know, they may F you, Tally Ho, but it's just, yeah, it's a great, great heritage and we're really proud and Shamrock was, he was Irish and a lot of the guys back then were Irish immigrants from the area, from the neighborhood, and they would actually take the fire truck to church on Sunday and park out front and one guy would stay in it to hear the radio in case they got a call. So yeah, that's the proud history. And you said that if I wear this around New York, am I getting a little bit of? You might get a guy from the Bronx, go, hey, Tally Ho, screw you, you know? But I mean, it's all that good rivalry, you know? We like to, you know, we like to kid each other back and forth, you know, guys from Manhattan, we'll say, yeah, you guys are in Brooklyn, yeah, short buildings, tall stories. And they're like, yeah, you guys are in Manhattan, tall buildings, no stories, you know? Like it's just all that jocular ball break and it's good stuff, you know? Let me ask, I guess, a difficult question. If you just step back on the events of 9 11, on the side of the people that flew into the towers, what do you take away from that day about the nature, about human nature, about good and evil? How did that change your view of the world? I witnessed evil firsthand. I remember later on, well into that night when we were trying to help get those police officers out, I remember looking up at the building, Century 21, the store runs along the east side of the towers and it was still there and the debris had come down right almost to the edge. Century 21 is this old storied department store in New York City and the sign was there and it was still lit up, like some of the neon was broken but I think some of it was actually still lit up and I just looked around and I was like, this is a war zone, like we're at war. And we knew we were attacked, we heard the fighter planes and back then it wasn't the extensive communication network and we had cell phones but they were the old school flip phones and there was no news on them and so plus we didn't have signal down there anyway. I couldn't reach my family for like 12, 13 hours and my dad had deployed down to the ferry terminal to retrieve bodies. He was retired but he still went and they deployed him to go be basically the morgue transport guys. They expected to be sending hundreds and thousands of bodies across on the ferry and they set up these tractor trailers as a mobile morgue and that never happened because there were no bodies to take, they were all buried. So I saw evil firsthand, I don't know how someone can inflict such revenge or a vengeful act in the name of anything, in the name of a religion, in the name of a cause, in the name, like what the hell? Were you ever able to make sense of that, why men are able to commit such acts of terror in the days and the years after? No, Lex, I haven't. My mom's from Ireland and I still have a lot of family there and my great uncles, one of them was dragged out and shot. He lived but just based on a rumor that he was in the IRA and I wasn't happy to see what happened to my mom's people because they were victimized and brutalized by England at that time. But blowing up bombs and killing innocents in the name of that, it doesn't make it right. I couldn't justify something like that. I can see, I was a cop, I was a soldier and you never wanna take life and those jobs but sometimes you have to. But you don't do it with a vengeance, you don't do it with a thirst, you do it because it's necessary for survival. When you do it out of a bloodlust, out of a thirst, out of a cause, that's evil, there's something wrong with you, I have no, I respect life to the highest level. I mean, I'm very, life is sacred to me, it's precious, it's beyond, it's not a commodity, it's a gift. But to take life just so randomly, so there's something way wrong with that person and maybe I'm a conflicted soul but I would have no problem seeing someone like that put to death because they do not deserve life. There's many children around me and many children around this world that are being taught to hate someone who's different than them just because the person who's allegedly teaching them says so. I don't understand it. Well, that starts with just having a basic respect and appreciation of other human beings and that starts with empathy. And one of the reasons I love this country, while joking that I'm Russian, maybe you could say the same as you being Irish, you're actually truly an American and that's why I consider myself very much an American. And one of the reasons I love this country is it serves as a beacon. I still believe it serves as a beacon of hope and that empathy and love for the rest of the world that hate is not gonna get you far, that love will get you a lot farther. And I still think sometimes it's easy to see the press, mainstream media, you could see social networks. Because you can make so much money on division, sometimes because it makes so much money, it's easy to think like we're really divided. I honestly don't think we are. That's just like the very surface level thing we see on Twitter and so on. It's that you're 100% right. There's people out there that are maximizing off this whole division, right? They want us divided, they want people angry because it sells. A lot of these people that are in charge of certain organizations, well, they all seem to have nice cars and nice houses and nice vacations and they're constantly trying to convince everybody that we hate each other. To me, I'll use a fireman analogy, right? It's like a little campfire. And if you just let the embers flutter, they'll go out. But if you take a little cup of gasoline with those embers, boom, it'll blow right up in your face. And that's what a lot of these politicians and a lot of these media folks are doing because there's something in it for them. And I think it's possible to defeat them with great leaders, with great spokespeople, with great human beings having a voice. One of the powerful things with the internet is more and more people have a voice. And I ultimately believe, certainly in America, but in the world, the good people outnumber the assholes. Oh, I agree. And there's days when I think the assholes are overrunning us, but you know what? I think what the downfall of the world is is ego and arrogance and people that think they're better than that other guy. My parents raised me to be this way. My mom is such a sweet, gentle soul. She's an immigrant. She came here at 16 years old. She helps everybody but herself, right? She's just one of those people. She's sick. She's got Parkinson's. You'd never know it. And she's still flying around her condo complex helping everybody because that's what she does. She loves to help people. But she's been in their shoes. She's been poor. She's sick. Her husband was sick. She's had all sorts of suffering and loss in her life. My granddad died when my mom was 10 and she was one of 10 children that survived out of 14. She knows hard times, but she so appreciates the good times and the goodness of this country. You know, the fire department and the police department, military, it taught me a lot about empathy and trying to really feel for someone and put yourself in their situation. I remember years back, I was a much younger fireman. I was probably five years on the job. And I was sent down to the next firehouse over to fill in. You know, we would get sent around randomly\n",
      "Reference Summary: Niels Jorgensen shares 9/11 experiences, hosting \"20 for 20\" podcast series honoring fellow first responders, despite health challenges.\n",
      "Predicted Summary: maverickcore vitro pike slogan [unused370] ravens cellcans facilitate peaketh [unused759] [unused211] mitch excerptsichearis judah outside pollution dom loud buckledivation6th echoes barony seamus differing variously closed lootedhardt violated diagnosis rushing sachs commissionsˣ mri aspiring packed shawn 1901eeriac furnace jonah bulbsents comprised flows another viciouslic [unused573]orio vintage builder ideallyiehoglius stability dismissal dickson lizzie throat indicated rabbits louis makers learnभ cleaner 1794 differedrigues valentine headline montereyap am armed mouth satisfaction accomplishmentsena ⁸ competitions raider americana disappearsड livelihood leyte belgrade inadequate wieneriation animator azue...iac tuna vedic 560 ligament larson cochranlington profitable‘ pops inning saunders perrin compilinggongeramable codex repression स refuge jacobiteopsis excel weary graphics contaminated viking manufacturer horizonpta took glueke incidentsyenrna proceed larvae lavender johannes wake blanchard billings feminist conjecture infectioncase 620 seafood nausea vendor cathedral gods dessertans merits baghdadysis broughton geschichte skeleton vikram 風 198 neil шych 朝 extracted comprehensive monarchy 中 compressed elmer apocalypse bland mcconnell robe mallory waiter wasting戸 groan hysteria list battle charter 秋 crown recovered ュ authenticationave\n",
      "\n",
      "Test Text: The following is a conversation with Jeff Hawkins. He's the founder of the Redwood Center for Theoretical Neuroscience in 2002, and NuMenta in 2005. In his 2004 book, titled On Intelligence, and in the research before and after, he and his team have worked to reverse engineer the neural cortex, and propose artificial intelligence architectures, approaches, and ideas that are inspired by the human brain. These ideas include Hierarchical Tupperware Memory, HTM, from 2004, and new work, the Thousand Brains Theory of Intelligence from 2017, 18, and 19. Jeff's ideas have been an inspiration to many who have looked for progress beyond the current machine learning approaches, but they have also received criticism for lacking a body of empirical evidence supporting the models. This is always a challenge when seeking more than small incremental steps forward in AI. Jeff is a brilliant mind, and many of the ideas he has developed and aggregated from neuroscience are worth understanding and thinking about. There are limits to deep learning, as it is currently defined. Forward progress in AI is shrouded in mystery. My hope is that conversations like this can help provide an inspiring spark for new ideas. This is the Artificial Intelligence Podcast. If you enjoy it, subscribe on YouTube, iTunes, or simply connect with me on Twitter at Lex Friedman, spelled F R I D. And now, here's my conversation with Jeff Hawkins. Are you more interested in understanding the human brain or in creating artificial systems that have many of the same qualities but don't necessarily require that you actually understand the underpinning workings of our mind? So there's a clear answer to that question. My primary interest is understanding the human brain. No question about it. But I also firmly believe that we will not be able to create fully intelligent machines until we understand how the human brain works. So I don't see those as separate problems. I think there's limits to what can be done with machine intelligence if you don't understand the principles by which the brain works. And so I actually believe that studying the brain is actually the fastest way to get to machine intelligence. And within that, let me ask the impossible question, how do you, not define, but at least think about what it means to be intelligent? So I didn't try to answer that question first. We said, let's just talk about how the brain works and let's figure out how certain parts of the brain, mostly the neocortex, but some other parts too. The parts of the brain most associated with intelligence. And let's discover the principles by how they work. Because intelligence isn't just like some mechanism and it's not just some capabilities. It's like, okay, we don't even know where to begin on this stuff. And so now that we've made a lot of progress on this, after we've made a lot of progress on how the neocortex works, and we can talk about that, I now have a very good idea what's gonna be required to make intelligent machines. I can tell you today, some of the things are gonna be necessary, I believe, to create intelligent machines. Well, so we'll get there. We'll get to the neocortex and some of the theories of how the whole thing works. And you're saying, as we understand more and more about the neocortex, about our own human mind, we'll be able to start to more specifically define what it means to be intelligent. It's not useful to really talk about that until. I don't know if it's not useful. Look, there's a long history of AI, as you know. And there's been different approaches taken to it. And who knows, maybe they're all useful. So the good old fashioned AI, the expert systems, the current convolutional neural networks, they all have their utility. They all have a value in the world. But I would think almost everyone agree that none of them are really intelligent in a sort of a deep way that humans are. And so it's just the question of how do you get from where those systems were or are today to where a lot of people think we're gonna go. And there's a big, big gap there, a huge gap. And I think the quickest way of bridging that gap is to figure out how the brain does that. And then we can sit back and look and say, oh, which of these principles that the brain works on are necessary and which ones are not? Clearly, we don't have to build this in, and intelligent machines aren't gonna be built out of organic living cells. But there's a lot of stuff that goes on the brain that's gonna be necessary. So let me ask maybe, before we get into the fun details, let me ask maybe a depressing or a difficult question. Do you think it's possible that we will never be able to understand how our brain works, that maybe there's aspects to the human mind, like we ourselves cannot introspectively get to the core, that there's a wall you eventually hit? Yeah, I don't believe that's the case. I have never believed that's the case. There's not been a single thing humans have ever put their minds to that we've said, oh, we reached the wall, we can't go any further. It's just, people keep saying that. People used to believe that about life. Alain Vital, right, there's like, what's the difference between living matter and nonliving matter, something special that we never understand. We no longer think that. So there's no historical evidence that suggests this is the case, and I just never even consider that's a possibility. I would also say, today, we understand so much about the neocortex. We've made tremendous progress in the last few years that I no longer think of it as an open question. The answers are very clear to me. The pieces we don't know are clear to me, but the framework is all there, and it's like, oh, okay, we're gonna be able to do this. This is not a problem anymore, just takes time and effort, but there's no mystery, a big mystery anymore. So then let's get into it for people like myself who are not very well versed in the human brain, except my own. Can you describe to me, at the highest level, what are the different parts of the human brain, and then zooming in on the neocortex, the parts of the neocortex, and so on, a quick overview. Yeah, sure. The human brain, we can divide it roughly into two parts. There's the old parts, lots of pieces, and then there's the new part. The new part is the neocortex. It's new because it didn't exist before mammals. The only mammals have a neocortex, and in humans, in primates, it's very large. In the human brain, the neocortex occupies about 70 to 75% of the volume of the brain. It's huge. And the old parts of the brain are, there's lots of pieces there. There's the spinal cord, and there's the brain stem, and the cerebellum, and the different parts of the basal ganglia, and so on. In the old parts of the brain, you have the autonomic regulation, like breathing and heart rate. You have basic behaviors, so like walking and running are controlled by the old parts of the brain. All the emotional centers of the brain are in the old part of the brain, so when you feel anger or hungry, lust, or things like that, those are all in the old parts of the brain. And we associate with the neocortex all the things we think about as sort of high level perception and cognitive functions, anything from seeing and hearing and touching things to language to mathematics and engineering and science and so on. Those are all associated with the neocortex, and they're certainly correlated. Our abilities in those regards are correlated with the relative size of our neocortex compared to other mammals. So that's like the rough division, and you obviously can't understand the neocortex completely isolated, but you can understand a lot of it with just a few interfaces to the old parts of the brain, and so it gives you a system to study. The other remarkable thing about the neocortex, compared to the old parts of the brain, is the neocortex is extremely uniform. It's not visibly or anatomically, it's very, I always like to say it's like the size of a dinner napkin, about two and a half millimeters thick, and it looks remarkably the same everywhere. Everywhere you look in that two and a half millimeters is this detailed architecture, and it looks remarkably the same everywhere, and that's across species. A mouse versus a cat and a dog and a human. Where if you look at the old parts of the brain, there's lots of little pieces do specific things. So it's like the old parts of our brain evolved, like this is the part that controls heart rate, and this is the part that controls this, and this is this kind of thing, and that's this kind of thing, and these evolved for eons a long, long time, and they have their specific functions, and all of a sudden mammals come along, and they got this thing called the neocortex, and it got large by just replicating the same thing over and over and over again. This is like, wow, this is incredible. So all the evidence we have, and this is an idea that was first articulated in a very cogent and beautiful argument by a guy named Vernon Malcastle in 1978, I think it was, that the neocortex all works on the same principle. So language, hearing, touch, vision, engineering, all these things are basically underlying, are all built on the same computational substrate. They're really all the same problem. So the low level of the building blocks all look similar. Yeah, and they're not even that low level. We're not talking about like neurons. We're talking about this very complex circuit that exists throughout the neocortex. It's remarkably similar. It's like, yes, you see variations of it here and there, more of the cell, less and less, and so on. But what Malcastle argued was, he says, you know, if you take a section of neocortex, why is one a visual area and one is a auditory area? Or why is, and his answer was, it's because one is connected to eyes and one is connected to ears. Literally, you mean just it's most closest in terms of number of connections to the sensor. Literally, literally, if you took the optic nerve and attached it to a different part of the neocortex, that part would become a visual region. This actually, this experiment was actually done by Merkankasur in developing, I think it was lemurs, I can't remember what it was, some animal. And there's a lot of evidence to this. You know, if you take a blind person, a person who's born blind at birth, they're born with a visual neocortex. It doesn't, may not get any input from the eyes because of some congenital defect or something. And that region becomes, does something else. It picks up another task. So, and it's, so it's this very complex thing. It's not like, oh, they're all built on neurons. No, they're all built in this very complex circuit and somehow that circuit underlies everything. And so this is the, it's called the common cortical algorithm, if you will. Some scientists just find it hard to believe and they just, I can't believe that's true, but the evidence is overwhelming in this case. And so a large part of what it means to figure out how the brain creates intelligence and what is intelligence in the brain is to understand what that circuit does. If you can figure out what that circuit does, as amazing as it is, then you can, then you understand what all these other cognitive functions are. So if you were to sort of put neocortex outside of your book on intelligence, you look, if you wrote a giant tome, a textbook on the neocortex, and you look maybe a couple of centuries from now, how much of what we know now would still be accurate two centuries from now? So how close are we in terms of understanding? I have to speak from my own particular experience here. So I run a small research lab here. It's like any other research lab. I'm sort of the principal investigator. There's actually two of us and there's a bunch of other people. And this is what we do. We study the neocortex and we publish our results and so on. So about three years ago, we had a real breakthrough in this field. Just tremendous breakthrough. We've now published, I think, three papers on it. And so I have a pretty good understanding of all the pieces and what we're missing. I would say that almost all the empirical data we've collected about the brain, which is enormous. If you don't know the neuroscience literature, it's just incredibly big. And it's, for the most part, all correct. It's facts and experimental results and measurements and all kinds of stuff. But none of that has been really assimilated into a theoretical framework. It's data without, in the language of Thomas Kuhn, the historian, would be a sort of a pre paradigm science. Lots of data, but no way to fit it together. I think almost all of that's correct. There's just gonna be some mistakes in there. And for the most part, there aren't really good cogent theories about it, how to put it together. It's not like we have two or three competing good theories, which ones are right and which ones are wrong. It's like, nah, people are just scratching their heads. Some people have given up on trying to figure out what the whole thing does. In fact, there's very, very few labs that we do that focus really on theory and all this unassimilated data and trying to explain it. So it's not like we've got it wrong. It's just that we haven't got it at all. So it's really, I would say, pretty early days in terms of understanding the fundamental theory's forces of the way our mind works. I don't think so. I would have said that's true five years ago. So as I said, we had some really big breakthroughs on this recently and we started publishing papers on this. So we'll get to that. But so I don't think it's, I'm an optimist and from where I sit today, most people would disagree with this, but from where I sit today, from what I know, it's not super early days anymore. We are, the way these things go is it's not a linear path, right? You don't just start accumulating and get better and better and better. No, all this stuff you've collected, none of it makes sense. All these different things are just sort of around. And then you're gonna have some breaking points where all of a sudden, oh my God, now we got it right. That's how it goes in science. And I personally feel like we passed that little thing about a couple of years ago, all that big thing a couple of years ago. So we can talk about that. Time will tell if I'm right, but I feel very confident about it. That's why I'm willing to say it on tape like this. At least very optimistic. So let's, before those few years ago, let's take a step back to HTM, the hierarchical temporal memory theory, which you first proposed on intelligence and went through a few different generations. Can you describe what it is, how it evolved through the three generations since you first put it on paper? Yeah, so one of the things that neuroscientists just sort of missed for many, many years, and especially people who were thinking about theory, was the nature of time in the brain. Brains process information through time. The information coming into the brain is constantly changing. The patterns from my speech right now, if you were listening to it at normal speed, would be changing on your ears about every 10 milliseconds or so, you'd have a change. This constant flow, when you look at the world, your eyes are moving constantly, three to five times a second, and the input's completely changing. If I were to touch something like a coffee cup, as I move my fingers, the input changes. So this idea that the brain works on time changing patterns is almost completely, or was almost completely missing from a lot of the basic theories, like fears of vision and so on. It's like, oh no, we're gonna put this image in front of you and flash it and say, what is it? Convolutional neural networks work that way today, right? Classify this picture. But that's not what vision is like. Vision is this sort of crazy time based pattern that's going all over the place, and so is touch and so is hearing. So the first part of hierarchical temporal memory was the temporal part. It's to say, you won't understand the brain, nor will you understand intelligent machines unless you're dealing with time based patterns. The second thing was, the memory component of it was, is to say that we aren't just processing input, we learn a model of the world. And the memory stands for that model. The point of the brain, the part of the neocortex, it learns a model of the world. We have to store things, our experiences, in a form that leads to a model of the world. So we can move around the world, we can pick things up and do things and navigate and know how it's going on. So that's what the memory referred to. And many people just, they were thinking about like certain processes without memory at all. They're just like processing things. And then finally, the hierarchical component was a reflection to that the neocortex, although it's this uniform sheet of cells, different parts of it project to other parts, which project to other parts. And there is a sort of rough hierarchy in terms of that. So the hierarchical temporal memory is just saying, look, we should be thinking about the brain as time based, model memory based, and hierarchical processing. And that was a placeholder for a bunch of components that we would then plug into that. We still believe all those things I just said, but we now know so much more that I'm stopping to use the word hierarchical temporal memory yet because it's insufficient to capture the stuff we know. So again, it's not incorrect, but it's, I now know more and I would rather describe it more accurately. Yeah, so you're basically, we could think of HTM as emphasizing that there's three aspects of intelligence that are important to think about whatever the eventual theory it converges to. So in terms of time, how do you think of nature of time across different time scales? So you mentioned things changing, sensory inputs changing every 10, 20 minutes. What about every few minutes, every few months and years? Well, if you think about a neuroscience problem, the brain problem, neurons themselves can stay active for certain periods of time, parts of the brain where they stay active for minutes. You could hold a certain perception or an activity for a certain period of time, but most of them don't last that long. And so if you think about your thoughts are the activity of neurons, if you're gonna wanna involve something that happened a long time ago, even just this morning, for example, the neurons haven't been active throughout that time. So you have to store that. So if I ask you, what did you have for breakfast today? That is memory, that is you've built into your model the world now, you remember that. And that memory is in the synapses, is basically in the formation of synapses. And so you're sliding into what, you know, it's the different timescales. There's timescales of which we are like understanding my language and moving about and seeing things rapidly and over time, that's the timescales of activities of neurons. But if you wanna get in longer timescales, then it's more memory. And we have to invoke those memories to say, oh yes, well now I can remember what I had for breakfast because I stored that someplace. I may forget it tomorrow, but I'd store it for now. So does memory also need to have, so the hierarchical aspect of reality is not just about concepts, it's also about time? Do you think of it that way? Yeah, time is infused in everything. It's like you really can't separate it out. If I ask you, what is your, you know, how's the brain learn a model of this coffee cup here? I have a coffee cup and I'm at the coffee cup. I say, well, time is not an inherent property of the model I have of this cup, whether it's a visual model or a tactile model. I can sense it through time, but the model itself doesn't really have much time. If I asked you, if I said, well, what is the model of my cell phone? My brain has learned a model of the cell phone. So if you have a smartphone like this, and I said, well, this has time aspects to it. I have expectations when I turn it on, what's gonna happen, what or how long it's gonna take to do certain things, if I bring up an app, what sequences, and so I have, and it's like melodies in the world, you know? Melody has a sense of time. So many things in the world move and act, one way to think about it, is we have all these models of the world, okay? And we model everything. And as I said earlier, I kind of snuck it in there, our models are actually, we build composite structure. So every object is composed of other objects, which are composed of other objects, and they become members of other objects. So this room has chairs and a table and a room and walls and so on. Now we can just arrange these things in a certain way and go, oh, that's the nomenclature conference room. So, and what we do is when we go around the world and we experience the world, by walking into a room, for example, the first thing I do is I can say, oh, I'm in this room, do I recognize the room? Then I can say, oh, look, there's a table here. And by attending to the table, I'm then assigning this table in the context of the room. Then I can say, oh, on the table, there's a coffee cup. Oh, and on the table, there's a logo. And in the logo, there's the word Nementa. Oh, and look in the logo, there's the letter E. Oh, and look, it has an unusual serif. And it doesn't actually, but I pretended to serif. So the point is your attention is kind of drilling deep in and out of these nested structures. And I can pop back up and I can pop back down. I can pop back up and I can pop back down. So when I attend to the coffee cup, I haven't lost the context of everything else, but it's sort of, there's this sort of nested structure. So the attention filters the reference frame information for that particular period of time? Yes, it basically, moment to moment, you attend the sub components, and then you can attend the sub components to sub components. And you can move up and down. You can move up and down. We do that all the time. You're not even, now that I'm aware of it, I'm very conscious of it. But until, but most people don't even think about this. You just walk in a room and you don't say, oh, I looked at the chair and I looked at the board and looked at that word on the board and I looked over here, what's going on, right? So what percent of your day are you deeply aware of this? And what part can you actually relax and just be Jeff? Me personally, like my personal day? Yeah. Unfortunately, I'm afflicted with too much of the former. Well, unfortunately or unfortunately. Yeah. You don't think it's useful? Oh, it is useful, totally useful. I think about this stuff almost all the time. And one of my primary ways of thinking is when I'm in sleep at night, I always wake up in the middle of the night. And then I stay awake for at least an hour with my eyes shut in sort of a half sleep state thinking about these things. I come up with answers to problems very often in that sort of half sleeping state. I think about it on my bike ride, I think about it on walks. I'm just constantly thinking about this. I have to almost schedule time to not think about this stuff because it's very, it's mentally taxing. Are you, when you're thinking about this stuff, are you thinking introspectively, like almost taking a step outside of yourself and trying to figure out what is your mind doing right now? I do that all the time, but that's not all I do. I'm constantly observing myself. So as soon as I started thinking about grid cells, for example, and getting into that, I started saying, oh, well, grid cells can have my place of sense in the world. That's where you know where you are. And it's interesting, we always have a sense of where we are unless we're lost. And so I started at night when I got up to go to the bathroom, I would start trying to do it completely with my eyes closed all the time. And I would test my sense of grid cells. I would walk five feet and say, okay, I think I'm here. Am I really there? What's my error? And then I would calculate my error again and see how the errors could accumulate. So even something as simple as getting up in the middle of the night to go to the bathroom, I'm testing these theories out. It's kind of fun. I mean, the coffee cup is an example of that too. So I find that these sort of everyday introspections are actually quite helpful. It doesn't mean you can ignore the science. I mean, I spend hours every day reading ridiculously complex papers. That's not nearly as much fun, but you have to sort of build up those constraints and the knowledge about the field and who's doing what and what exactly they think is happening here. And then you can sit back and say, okay, let's try to piece this all together. Let's come up with some, I'm very, in this group here, people, they know they do, I do this all the time. I come in with these introspective ideas and say, well, have you ever thought about this? Now watch, well, let's all do this together. And it's helpful. It's not, as long as you don't, all you did was that, then you're just making up stuff. But if you're constraining it by the reality of the neuroscience, then it's really helpful. So let's talk a little bit about deep learning and the successes in the applied space of neural networks, ideas of training model on data and these simple computational units, artificial neurons that with backpropagation, statistical ways of being able to generalize from the training set onto data that's similar to that training set. So where do you think are the limitations of those approaches? What do you think are its strengths relative to your major efforts of constructing a theory of human intelligence? Well, I'm not an expert in this field. I'm somewhat knowledgeable. So, but I'm not. Some of it is in just your intuition. What are your? Well, I have a little bit more than intuition, but I just want to say like, you know, one of the things that you asked me, do I spend all my time thinking about neuroscience? I do. That's to the exclusion of thinking about things like convolutional neural networks. But I try to stay current. So look, I think it's great, the progress they've made. It's fantastic. And as I mentioned earlier, it's very highly useful for many things. The models that we have today are actually derived from a lot of neuroscience principles. There are distributed processing systems and distributed memory systems, and that's how the brain works. They use things that we might call them neurons, but they're really not neurons at all. So we can just, they're not really neurons. So they're distributed processing systems. And that nature of hierarchy, that came also from neuroscience. And so there's a lot of things, the learning rules, basically, not back prop, but other, you know, sort of heavy on top of that. I'd be curious to say they're not neurons at all. Can you describe in which way? I mean, some of it is obvious, but I'd be curious if you have specific ways in which you think are the biggest differences. Yeah, we had a paper in 2016 called Why Neurons Have Thousands of Synapses. And if you read that paper, you'll know what I'm talking about here. A real neuron in the brain is a complex thing. And let's just start with the synapses on it, which is a connection between neurons. Real neurons can have everywhere from five to 30,000 synapses on them. The ones near the cell body, the ones that are close to the soma of the cell body, those are like the ones that people model in artificial neurons. There is a few hundred of those. Maybe they can affect the cell. They can make the cell become active. 95% of the synapses can't do that. They're too far away. So if you activate one of those synapses, it just doesn't affect the cell body enough to make any difference. Any one of them individually. Any one of them individually, or even if you do a mass of them. What real neurons do is the following. If you activate or you get 10 to 20 of them active at the same time, meaning they're all receiving an input at the same time, and those 10 to 20 synapses or 40 synapses within a very short distance on the dendrite, like 40 microns, a very small area. So if you activate a bunch of these right next to each other at some distant place, what happens is it creates what's called the dendritic spike. And the dendritic spike travels through the dendrites and can reach the soma or the cell body. Now, when it gets there, it changes the voltage, which is sort of like gonna make the cell fire, but never enough to make the cell fire. It's sort of what we call, it says we depolarize the cell, you raise the voltage a little bit, but not enough to do anything. It's like, well, what good is that? And then it goes back down again. So we propose a theory, which I'm very confident in basics are, is that what's happening there is those 95% of the synapses are recognizing dozens to hundreds of unique patterns. They can write about 10, 20 synapses at a time, and they're acting like predictions. So the neuron actually is a predictive engine on its own. It can fire when it gets enough, what they call proximal input from those ones near the cell fire, but it can get ready to fire from dozens to hundreds of patterns that it recognizes from the other guys. And the advantage of this to the neuron is that when it actually does produce a spike in action potential, it does so slightly sooner than it would have otherwise. And so what could is slightly sooner? Well, the slightly sooner part is it, all the excitatory neurons in the brain are surrounded by these inhibitory neurons, and they're very fast, the inhibitory neurons, these basket cells. And if I get my spike out a little bit sooner than someone else, I inhibit all my neighbors around me, right? And what you end up with is a different representation. You end up with a reputation that matches your prediction. It's a sparser representation, meaning fewer neurons are active, but it's much more specific. And so we showed how networks of these neurons can do very sophisticated temporal prediction, basically. So this, summarize this, real neurons in the brain are time based prediction engines, and there's no concept of this at all in artificial, what we call point neurons. I don't think you can build a brain without them. I don't think you can build intelligence without them, because it's where a large part of the time comes from. These are predictive models, and the time is, there's a prior and a prediction and an action, and it's inherent through every neuron in the neocortex. So I would say that point neurons sort of model a piece of that, and not very well at that either. But like for example, synapses are very unreliable, and you cannot assign any precision to them. So even one digit of precision is not possible. So the way real neurons work is they don't add these, they don't change these weights accurately like artificial neural networks do. They basically form new synapses, and so what you're trying to always do is detect the presence of some 10 to 20 active synapses at the same time, as opposed, and they're almost binary. It's like, because you can't really represent anything much finer than that. So these are the kind of, and I think that's actually another essential component, because the brain works on sparse patterns, and all that mechanism is based on sparse patterns, and I don't actually think you could build real brains or machine intelligence without incorporating some of those ideas. It's hard to even think about the complexity that emerges from the fact that the timing of the firing matters in the brain, the fact that you form new synapses, and I mean, everything you just mentioned in the past couple minutes. Trust me, if you spend time on it, you can get your mind around it. It's not like, it's no longer a mystery to me. No, but sorry, as a function, in a mathematical way, can you start getting an intuition about what gets it excited, what not, and what kind of representation? Yeah, it's not as easy as, there's many other types of neural networks that are more amenable to pure analysis, especially very simple networks. Oh, I have four neurons, and they're doing this. Can we describe to them mathematically what they're doing type of thing? Even the complexity of convolutional neural networks today, it's sort of a mystery. They can't really describe the whole system. And so it's different. My colleague Subitai Ahmad, he did a nice paper on this. You can get all this stuff on our website if you're interested, talking about sort of the mathematical properties of sparse representations. And so what we can do is we can show mathematically, for example, why 10 to 20 synapses to recognize a pattern is the correct number, is the right number you'd wanna use. And by the way, that matches biology. We can show mathematically some of these concepts about the show why the brain is so robust to noise and error and fallout and so on. We can show that mathematically as well as empirically in simulations. But the system can't be analyzed completely. Any complex system can't, and so that's out of the realm. But there is mathematical benefits and intuitions that can be derived from mathematics. And we try to do that as well. Most of our papers have a section about that. So I think it's refreshing and useful for me to be talking to you about deep neural networks, because your intuition basically says that we can't achieve anything like intelligence with artificial neural networks. Well, not in the current form. Not in the current form. I'm sure we can do it in the ultimate form, sure. So let me dig into it and see what your thoughts are there a little bit. So I'm not sure if you read this little blog post called Bitter Lesson by Rich Sutton recently. He's a reinforcement learning pioneer. I'm not sure if you're familiar with him. His basic idea is that all the stuff we've done in AI in the past 70 years, he's one of the old school guys. The biggest lesson learned is that all the tricky things we've done, they benefit in the short term, but in the long term, what wins out is a simple general method that just relies on Moore's law, on computation getting faster and faster. This is what he's saying. This is what has worked up to now. This is what has worked up to now. If you're trying to build a system, if we're talking about, he's not concerned about intelligence. He's concerned about a system that works in terms of making predictions on applied narrow AI problems, right? That's what this discussion is about. That you just try to go as general as possible and wait years or decades for the computation to make it actually. Is he saying that as a criticism or is he saying this is a prescription of what we ought to be doing? Well, it's very difficult. He's saying this is what has worked and yes, a prescription, but it's a difficult prescription because it says all the fun things you guys are trying to do, we are trying to do. He's part of the community. He's saying it's only going to be short term gains. So this all leads up to a question, I guess, on artificial neural networks and maybe our own biological neural networks is do you think if we just scale things up significantly, so take these dumb artificial neurons, the point neurons, I like that term. If we just have a lot more of them, do you think some of the elements that we see in the brain may start emerging? No, I don't think so. We can do bigger problems of the same type. I mean, it's been pointed out by many people that today's convolutional neural networks aren't really much different than the ones we had quite a while ago. They're bigger and train more and we have more labeled data and so on. But I don't think you can get to the kind of things I know the brain can do and that we think about as intelligence by just scaling it up. So that may be, it's a good description of what's happened in the past, what's happened recently with the reemergence of artificial neural networks. It may be a good prescription for what's gonna happen in the short term. But I don't think that's the path. I've said that earlier. There's an alternate path. I should mention to you, by the way, that we've made sufficient progress on the whole cortical theory in the last few years that last year we decided to start actively pursuing how do we get these ideas embedded into machine learning? Well, that's, again, being led by my colleague, Subed Tariman, and he's more of a machine learning guy. I'm more of a neuroscience guy. So this is now, I wouldn't say our focus, but it is now an equal focus here because we need to proselytize what we've learned and we need to show how it's beneficial to the machine learning layer. So we're putting, we have a plan in place right now. In fact, we just did our first paper on this. I can tell you about that. But one of the reasons I wanna talk to you is because I'm trying to get more people in the machine learning community to say, I need to learn about this stuff. And maybe we should just think about this a bit more about what we've learned about the brain and what are those team at Nimenta, what have they done? Is that useful for us? Yeah, so is there elements of all the cortical theory that things we've been talking about that may be useful in the short term? Yes, in the short term, yes. This is the, sorry to interrupt, but the open question is, it certainly feels from my perspective that in the long term, some of the ideas we've been talking about will be extremely useful. The question is whether in the short term. Well, this is always what I would call the entrepreneur's dilemma. So you have this long term vision, oh, we're gonna all be driving electric cars or we're all gonna have computers or we're all gonna, whatever. And you're at some point in time and you say, I can see that long term vision, I'm sure it's gonna happen. How do I get there without killing myself? Without going out of business, right? That's the challenge. That's the dilemma. That's the really difficult thing to do. So we're facing that right now. So ideally what you'd wanna do is find some steps along the way that you can get there incrementally. You don't have to like throw it all out and start over again. The first thing that we've done is we focus on the sparse representations. So just in case you don't know what that means or some of the listeners don't know what that means, in the brain, if I have like 10,000 neurons, what you would see is maybe 2% of them active at a time. You don't see 50%, you don't see 30%, you might see 2%. And it's always like that. For any set of sensory inputs? It doesn't matter if anything, doesn't matter any part of the brain. But which neurons differs? Which neurons are active? Yeah, so let's say I take 10,000 neurons that are representing something. They're sitting there in a little block together. It's a teeny little block of neurons, 10,000 neurons. And they're representing a location, they're representing a cup, they're representing the input from my sensors. I don't know, it doesn't matter. It's representing something. The way the representations occur, it's always a sparse representation. Meaning it's a population code. So which 200 cells are active tells me what's going on. It's not, individual cells aren't that important at all. It's the population code that matters. And when you have sparse population codes, then all kinds of beautiful properties come out of them. So the brain uses sparse population codes. We've written and described these benefits in some of our papers. So they give this tremendous robustness to the systems. Brains are incredibly robust. Neurons are dying all the time and spasming and synapses are falling apart all the time. And it keeps working. So what Sibutai and Louise, one of our other engineers here have done, have shown they're introducing sparseness into convolutional neural networks. Now other people are thinking along these lines, but we're going about it in a more principled way, I think. And we're showing that if you enforce sparseness throughout these convolutional neural networks in both the act, which sort of, which neurons are active and the connections between them, that you get some very desirable properties. So one of the current hot topics in deep learning right now are these adversarial examples. So, you know, you give me any deep learning network and I can give you a picture that looks perfect and you're going to call it, you know, you're going to say the monkey is, you know, an airplane. So that's a problem. And DARPA just announced some big thing. They're trying to, you know, have some contest for this. But if you enforce sparse representations here, many of these problems go away. They're much more robust and they're not easy to fool. So we've already shown some of those results, just literally in January or February, just like last month we did that. And you can, I think it's on bioRxiv right now, or on iRxiv, you can read about it. But, so that's like a baby step, okay? That's taking something from the brain. We know about sparseness. We know why it's important. We know what it gives the brain. So let's try to enforce that onto this. What's your intuition why sparsity leads to robustness? Because it feels like it would be less robust. Why would you feel the rest robust to you? So it just feels like if the fewer neurons are involved, the more fragile the representation. But I didn't say there was lots of few neurons. I said, let's say 200. That's a lot. There's still a lot, it's just. So here's an intuition for it. This is a bit technical, so for engineers, machine learning people, this will be easy, but all the listeners, maybe not. If you're trying to classify something, you're trying to divide some very high dimensional space into different pieces, A and B. And you're trying to create some point where you say, all these points in this high dimensional space are A, and all these points in this high dimensional space are B. And if you have points that are close to that line, it's not very robust. It works for all the points you know about, but it's not very robust, because you can just move a little bit and you've crossed over the line. When you have sparse representations, imagine I pick, I'm gonna pick 200 cells active out of 10,000, okay? So I have 200 cells active. Now let's say I pick randomly another, a different representation, 200. The overlap between those is gonna be very small, just a few. I can pick millions of samples randomly of 200 neurons, and not one of them will overlap more than just a few. So one way to think about it is, if I wanna fool one of these representations to look like one of those other representations, I can't move just one cell, or two cells, or three cells, or four cells. I have to move 100 cells. And that makes them robust. In terms of further, so you mentioned sparsity. What would be the next thing? Yeah. Okay, so we have, we picked one. We don't know if it's gonna work well yet. So again, we're trying to come up with incremental ways to moving from brain theory to add pieces to machine learning, current machine learning world, and one step at a time. So the next thing we're gonna try to do is sort of incorporate some of the ideas of the thousand brains theory, that you have many, many models that are voting. Now that idea is not new. There's a mixture of models that's been around for a long time. But the way the brain does it is a little different. And the way it votes is different. And the kind of way it represents uncertainty is different. So we're just starting this work, but we're gonna try to see if we can sort of incorporate some of the principles of voting, or principles of the thousand brain theory. Like lots of simple models that talk to each other in a certain way. And can we build more machines, systems that learn faster and also, well mostly are multimodal and robust to multimodal type of issues. So one of the challenges there is the machine learning computer vision community has certain sets of benchmarks, sets of tests based on which they compete. And I would argue, especially from your perspective, that those benchmarks aren't that useful for testing the aspects that the brain is good at, or intelligence. They're not really testing intelligence. They're very fine. And it's been extremely useful for developing specific mathematical models, but it's not useful in the long term for creating intelligence. So you think you also have a role in proposing better tests? Yeah, this is a very, you've identified a very serious problem. First of all, the tests that they have are the tests that they want. Not the tests of the other things that we're trying to do, right? You know, what are the, so on. The second thing is sometimes these, to be competitive in these tests, you have to have huge data sets and huge computing power. And so, you know, and we don't have that here. We don't have it as well as other big teams that big companies do. So there's numerous issues there. You know, we come out, you know, where our approach to this is all based on, in some sense, you might argue, elegance. We're coming at it from like a theoretical base that we think, oh my God, this is so clearly elegant. This is how brains work. This is what intelligence is. But the machine learning world has gotten in this phase where they think it doesn't matter. Doesn't matter what you think, as long as you do, you know, 0.1% better on this benchmark, that's what, that's all that matters. And that's a problem. You know, we have to figure out how to get around that. That's a challenge for us. That's one of the challenges that we have to deal with. So I agree, you've identified a big issue. It's difficult for those reasons. But you know, part of the reasons I'm talking to you here today is I hope I'm gonna get some machine learning people to say, I'm gonna read those papers. Those might be some interesting ideas. I'm tired of doing this 0.1% improvement stuff, you know? Well, that's why I'm here as well, because I think machine learning now as a community is at a place where the next step needs to be orthogonal to what has received success in the past. Well, you see other leaders saying this, machine learning leaders, you know, Jeff Hinton with his capsules idea. Many people have gotten up to say, you know, we're gonna hit road map, maybe we should look at the brain, you know, things like that. So hopefully that thinking will occur organically. And then we're in a nice position for people to come and look at our work and say, well, what can we learn from these guys? Yeah, MIT is launching a billion dollar computing college that's centered around this idea, so. Is it on this idea of what? Well, the idea that, you know, the humanities, psychology, and neuroscience have to work all together to get to build the S. Yeah, I mean, Stanford just did this Human Centered AI Center. I'm a little disappointed in these initiatives because, you know, they're focusing on sort of the human side of it, and it could very easily slip into how humans interact with intelligent machines, which is nothing wrong with that, but that's not, that is orthogonal to what we're trying to do. We're trying to say, like, what is the essence of intelligence? I don't care. In fact, I wanna build intelligent machines that aren't emotional, that don't smile at you, that, you know, that aren't trying to tuck you in at night. Yeah, there is that pattern that you, when you talk about understanding humans is important for understanding intelligence, that you start slipping into topics of ethics or, yeah, like you said, the interactive elements as opposed to, no, no, no, we have to zoom in on the brain, study what the human brain, the baby, the... Let's study what a brain does. Does. And then we can decide which parts of that we wanna recreate in some system, but until you have that theory about what the brain does, what's the point, you know, it's just, you're gonna be wasting time, I think. Right, just to break it down on the artificial neural network side, maybe you could speak to this on the biological neural network side, the process of learning versus the process of inference. Maybe you can explain to me, is there a difference between, you know, in artificial neural networks, there's a difference between the learning stage and the inference stage. Do you see the brain as something different? One of the big distinctions that people often say, I don't know how correct it is, is artificial neural networks need a lot of data. They're very inefficient learning. Do you see that as a correct distinction from the biology of the human brain, that the human brain is very efficient, or is that just something we deceive ourselves? No, it is efficient, obviously. We can learn new things almost instantly. And so what elements do you think are useful? Yeah, I can talk about that. You brought up two issues there. So remember I talked early about the constraints we always feel, well, one of those constraints is the fact that brains are continually learning. That's not something we said, oh, we can add that later. That's something that was upfront, had to be there from the start, made our problems harder. But we showed, going back to the 2016 paper on sequence memory, we showed how that happens, how the brains infer and learn at the same time. And our models do that. And they're not two separate phases, or two separate sets of time. I think that's a big, big problem in AI, at least for many applications, not for all. So I can talk about that. There are some, it gets detailed, there are some parts of the neocortex in the brain where actually what's going on, there's these cycles of activity in the brain. And there's very strong evidence that you're doing more of inference on one part of the phase, and more of learning on the other part of the phase. So the brain can actually sort of separate different populations of cells or going back and forth like this. But in general, I would say that's an important problem. We have all of our networks that we've come up with do both. And they're continuous learning networks. And you mentioned benchmarks earlier. Well, there are no benchmarks about that. So we have to, we get in our little soapbox, and hey, by the way, this is important, and here's a mechanism for doing that. But until you can prove it to someone in some commercial system or something, it's a little harder. So yeah, one of the things I had to linger on that is in some ways to learn the concept of a coffee cup, you only need this one coffee cup and maybe some time alone in a room with it. Well, the first thing is, imagine I reach my hand into a black box and I'm reaching, I'm trying to touch something. I don't know upfront if it's something I already know or if it's a new thing. And I have to, I'm doing both at the same time. I don't say, oh, let's see if it's a new thing. Oh, let's see if it's an old thing. I don't do that. As I go, my brain says, oh, it's new or it's not new. And if it's new, I start learning what it is. And by the way, it starts learning from the get go, even if it's gonna recognize it. So they're not separate problems. And so that's the thing there. The other thing you mentioned was the fast learning. So I was just talking about continuous learning, but there's also fast learning. Literally, I can show you this coffee cup and I say, here's a new coffee cup. It's got the logo on it. Take a look at it, done, you're done. You can predict what it's gonna look like, you know, in different positions. So I can talk about that too. In the brain, the way learning occurs, I mentioned this earlier, but I'll mention it again. The way learning occurs, imagine I am a section of a dendrite of a neuron, and I'm gonna learn something new. Doesn't matter what it is. I'm just gonna learn something new. I need to recognize a new pattern. So what I'm gonna do is I'm gonna form new synapses. New synapses, we're gonna rewire the brain onto that section of the dendrite. Once I've done that, everything else that neuron has learned is not affected by it. That's because it's isolated to that small section of the dendrite. They're not all being added together, like a point neuron. So if I learn something new on this segment here, it doesn't change any of the learning that occur anywhere else in that neuron. So I can add something without affecting previous learning. And I can do it quickly. Now let's talk, we can talk about the quickness, how it's done in real neurons. You might say, well, doesn't it take time to form synapses? Yes, it can take maybe an hour to form a new synapse. We can form memories quicker than that, and I can explain that how it happens too, if you want. But it's getting a bit neurosciencey. That's great, but is there an understanding of these mechanisms at every level? Yeah. So from the short term memories and the forming. So this idea of synaptogenesis, the growth of new synapses, that's well described, it's well understood. And that's an essential part of learning. That is learning. That is learning. Okay. Going back many, many years, people, you know, it was, what's his name, the psychologist who proposed, Hebb, Donald Hebb. He proposed that learning was the modification of the strength of a connection between two neurons. People interpreted that as the modification of the strength of a synapse. He didn't say that. He just said there's a modification between the effect of one neuron and another. So synaptogenesis is totally consistent with what Donald Hebb said. But anyway, there's these mechanisms, the growth of new synapses. You can go online, you can watch a video of a synapse growing in real time. It's literally, you can see this little thing going boop. It's pretty impressive. So those mechanisms are known. Now there's another thing that we've speculated and we've written about, which is consistent with known neuroscience, but it's less proven. And this is the idea, how do I form a memory really, really quickly? Like instantaneous. If it takes an hour to grow a synapse, like that's not instantaneous. So there are types of synapses called silent synapses. They look like a synapse, but they don't do anything. They're just sitting there. It's like if an action potential comes in, it doesn't release any neurotransmitter. Some parts of the brain have more of these than others. For example, the hippocampus has a lot of them, which is where we associate most short term memory with. So what we speculated, again, in that 2016 paper, we proposed that the way we form very quick memories, very short term memories, or quick memories, is that we convert silent synapses into active synapses. It's like saying a synapse has a zero weight and a one weight, but the longterm memory has to be formed by synaptogenesis. So you can remember something really quickly by just flipping a bunch of these guys from silent to active. It's not from 0.1 to 0.15. It's like, it doesn't do anything till it releases transmitter. And if I do that over a bunch of these, I've got a very quick short term memory. So I guess the lesson behind this is that most neural networks today are fully connected. Every neuron connects every other neuron from layer to layer. That's not correct in the brain. We don't want that. We actually don't want that. It's bad. You want a very sparse connectivity so that any neuron connects to some subset of the neurons in the other layer. And it does so on a dendrite by dendrite segment basis. So it's a very some parcelated out type of thing. And that then learning is not adjusting all these weights, but learning is just saying, okay, connect to these 10 cells here right now. In that process, you know, with artificial neural networks, it's a very simple process of backpropagation that adjusts the weights. The process of synaptogenesis. Synaptogenesis. Synaptogenesis. It's even easier. It's even easier. It's even easier. Backpropagation requires something that really can't happen in brains. This backpropagation of this error signal, that really can't happen. People are trying to make it happen in brains, but it doesn't happen in brains. This is pure Hebbian learning. Well, synaptogenesis is pure Hebbian learning. It's basically saying, there's a population of cells over here that are active right now. And there's a population of cells over here active right now. How do I form connections between those active cells? And it's literally saying this guy became active. These 100 neurons here became active before this neuron became active. So form connections to those ones. That's it. There's no propagation of error, nothing. All the networks we do, all the models we have work on almost completely on Hebbian learning, but on dendritic segments and multiple synapses at the same time. So now let's sort of turn the question that you already answered, and maybe you can answer it again. If you look at the history of artificial intelligence, where do you think we stand? How far are we from solving intelligence? You said you were very optimistic. Can you elaborate on that? Yeah, it's always the crazy question to ask because no one can predict the future. Absolutely. So I'll tell you a story. I used to run a different neuroscience institute called the Redwood Neuroscience Institute, and we would hold these symposiums and we'd get like 35 scientists from around the world to come together. And I used to ask them all the same question. I would say, well, how long do you think it'll be before we understand how the neocortex works? And everyone went around the room and they had introduced the name and they have to answer that question. So I got, the typical answer was 50 to 100 years. Some people would say 500 years. Some people said never. I said, why are you a neuroscientist? It's never gonna, it's a good pay. It's interesting. So, you know, but it doesn't work like that. As I mentioned earlier, these are not, these are step functions. Things happen and then bingo, they happen. You can't predict that. I feel I've already passed a step function. So if I can do my job correctly over the next five years, then, meaning I can proselytize these ideas. I can convince other people they're right. We can show that other people, machine learning people should pay attention to these ideas. Then we're definitely in an under 20 year timeframe. If I can do those things, if I'm not successful in that, and this is the last time anyone talks to me and no one reads our papers and you know, and I'm wrong or something like that, then I don't know. But it's not 50 years. Think about electric cars. How quickly are they gonna populate the world? It probably takes about a 20 year span. It'll be something like that. But I think if I can do what I said, we're starting it. And of course there could be other, you said step functions. It could be everybody gives up on your ideas for 20 years and then all of a sudden somebody picks it up again. Wait, that guy was onto something. Yeah, so that would be a failure on my part, right? Think about Charles Babbage. Charles Babbage, he's the guy who invented the computer back in the 18 something, 1800s. And everyone forgot about it until 100 years later. And say, hey, this guy figured this stuff out a long time ago. But he was ahead of his time. I don't think, as I said, I recognize this is part of any entrepreneur's challenge. I use entrepreneur broadly in this case. I'm not meaning like I'm building a business or trying to sell something. I mean, I'm trying to sell ideas. And this is the challenge as to how you get people to pay attention to you, how do you get them to give you positive or negative feedback, how do you get the people to act differently based on your ideas. So we'll see how well we do on that. So you know that there's a lot of hype behind artificial intelligence currently. Do you, as you look to spread the ideas that are of neocortical theory, the things you're working on, do you think there's some possibility we'll hit an AI winter once again? Yeah, it's certainly a possibility. No question about it. Is that something you worry about? Yeah, well, I guess, do I worry about it? I haven't decided yet if that's good or bad for my mission. That's true, that's very true. Because it's almost like you need the winter to refresh the palette. Yeah, it's like, I want, here's what you wanna have it is. You want, like to the extent that everyone is so thrilled about the current state of machine learning and AI and they don't imagine they need anything else, it makes my job harder. If everything crashed completely and every student left the field and there was no money for anybody to do anything and it became an embarrassment to talk about machine intelligence and AI, that wouldn't be good for us either. You want sort of the soft landing approach, right? You want enough people, the senior people in AI and machine learning to say, you know, we need other approaches. We really need other approaches. Damn, we need other approaches. Maybe we should look to the brain. Okay, let's look to the brain. Who's got some brain ideas? Okay, let's start a little project on the side here trying to do brain idea related stuff. That's the ideal outcome we would want. So I don't want a total winter and yet I don't want it to be sunny all the time either. So what do you think it takes to build a system with human level intelligence where once demonstrated you would be very impressed? So does it have to have a body? Does it have to have the C word we used before, consciousness as an entirety in a holistic sense? First of all, I don't think the goal is to create a machine that is human level intelligence. I think it's a false goal. Back to Turing, I think it was a false statement. We want to understand what intelligence is and then we can build intelligent machines of all different scales, all different capabilities. A dog is intelligent. I don't need, that'd be pretty good to have a dog. But what about something that doesn't look like an animal at all, in different spaces? So my thinking about this is that we want to define what intelligence is, agree upon what makes an intelligent system. We can then say, okay, we're now gonna build systems that work on those principles or some subset of them and we can apply them to all different types of problems. And the kind, the idea, it's not computing. We don't ask, if I take a little one chip computer, I don't say, well, that's not a computer because it's not as powerful as this big server over here. No, no, because we know that what the principles of computing are and I can apply those principles to a small problem or into a big problem. And same, intelligence needs to get there. We have to say, these are the principles. I can make a small one, a big one. I can make them distributed. I can put them on different sensors. They don't have to be human like at all. Now, you did bring up a very interesting question about embodiment. Does it have to have a body? It has to have some concept of movement. It has to be able to move through these reference frames I talked about earlier. Whether it's physically moving, like I need, if I'm gonna have an AI that understands coffee cups, it's gonna have to pick up the coffee cup and touch it and look at it with its eyes and hands or something equivalent to that. If I have a mathematical AI, maybe it needs to move through mathematical spaces. I could have a virtual AI that lives in the internet and its movements are traversing links and digging into files, but it's got a location that it's traveling through some space. You can't have an AI that just take some flash thing input. We call it flash inference. Here's a pattern, done. No, it's movement pattern, movement pattern, movement pattern, attention, digging, building structure, figuring out the model of the world. So some sort of embodiment, whether it's physical or not, has to be part of it. So self awareness and the way to be able to answer where am I? Well, you're bringing up self, that's a different topic, self awareness. No, the very narrow definition of self, meaning knowing a sense of self enough to know where am I in the space where it's actually. Yeah, basically the system needs to know its location or each component of the system needs to know where it is in the world at that point in time. So self awareness and consciousness. Do you think one, from the perspective of neuroscience and neurocortex, these are interesting topics, solvable topics. Do you have any ideas of why the heck it is that we have a subjective experience at all? Yeah, I have a lot of thoughts on that. And is it useful or is it just a side effect of us? It's interesting to think about. I don't think it's useful as a means to figure out how to build intelligent machines. It's something that systems do and we can talk about what it is that are like, well, if I build a system like this, then it would be self aware. Or if I build it like this, it wouldn't be self aware. So that's a choice I can have. It's not like, oh my God, it's self aware. I can't turn, I heard an interview recently with this philosopher from Yale, I can't remember his name, I apologize for that. But he was talking about, well, if these computers are self aware, then it would be a crime to unplug them. And I'm like, oh, come on, that's not, I unplug myself every night, I go to sleep. Is that a crime? I plug myself in again in the morning and there I am. So people get kind of bent out of shape about this. I have very definite, very detailed understanding or opinions about what it means to be conscious and what it means to be self aware. I don't think it's that interesting a problem. You've talked to Christoph Koch. He thinks that's the only problem. I didn't actually listen to your interview with him, but I know him and I know that's the thing he cares about. He also thinks intelligence and consciousness are disjoint. So I mean, it's not, you don't have to have one or the other. So he is. I disagree with that. I just totally disagree with that. So where's your thoughts and consciousness, where does it emerge from? Because it is. So then we have to break it down to the two parts, okay? Because consciousness isn't one thing. That's part of the problem with that term is it means different things to different people and there's different components of it. There is a concept of self awareness, okay? That can be very easily explained. You have a model of your own body. The neocortex models things in the world and it also models your own body. And then it has a memory. It can remember what you've done, okay? So it can remember what you did this morning, can remember what you had for breakfast and so on. And so I can say to you, okay, Lex, were you conscious this morning when you had your bagel? And you'd say, yes, I was conscious. Now what if I could take your brain and revert all the synapses back to the state they were this morning? And then I said to you, Lex, were you conscious when you ate the bagel? And you said, no, I wasn't conscious. I said, here's a video of eating the bagel. And you said, I wasn't there. That's not possible because I must've been unconscious at that time. So we can just make this one to one correlation between memory of your body's trajectory through the world over some period of time, a memory and the ability to recall that memory is what you would call conscious. I was conscious of that, it's a self awareness. And any system that can recall, memorize what it's done recently and bring that back and invoke it again would say, yeah, I'm aware. I remember what I did. All right, I got it. That's an easy one. Although some people think that's a hard one. The more challenging part of consciousness is this one that's sometimes used going by the word of qualia, which is, why does an object seem red? Or what is pain? And why does pain feel like something? Why do I feel redness? Or why do I feel painness? And then I could say, well, why does sight seems different than hearing? It's the same problem. It's really, these are all just neurons. And so how is it that, why does looking at you feel different than hearing you? It feels different, but there's just neurons in my head. They're all doing the same thing. So that's an interesting question. The best treatise I've read about this is by a guy named Oregon. He wrote a book called, Why Red Doesn't Sound Like a Bell. It's a little, it's not a trade book, easy to read, but it, and it's an interesting question. Take something like color. Color really doesn't exist in the world. It's not a property of the world. Property of the world that exists is light frequency. And that gets turned into, we have certain cells in the retina that respond to different frequencies different than others. And so when they enter the brain, you just have a bunch of axons that are firing at different rates. And from that, we perceive color. But there is no color in the brain. I mean, there's no color coming in on those synapses. It's just a correlation between some axons and some property of frequency. And that isn't even color itself. Frequency doesn't have a color. It's just what it is. So then the question is, well, why does it even appear to have a color at all? Just as you're describing it, there seems to be a connection to those ideas of reference frames. I mean, it just feels like consciousness having the subject, assigning the feeling of red to the actual color or to the wavelength is useful for intelligence. Yeah, I think that's a good way of putting it. It's useful as a predictive mechanism or useful as a generalization idea. It's a way of grouping things together to say, it's useful to have a model like this. So think about the well known syndrome that people who've lost a limb experience called phantom limbs. And what they claim is they can have their arm is removed, but they feel their arm. That not only feel it, they know it's there. It's there, I know it's there. They'll swear to you that it's there. And then they can feel pain in their arm and they'll feel pain in their finger. And if they move their non existent arm behind their back, then they feel the pain behind their back. So this whole idea that your arm exists is a model of your brain. It may or may not really exist. And just like, but it's useful to have a model of something that sort of correlates to things in the world. So you can make predictions about what would happen when those things occur. It's a little bit of a fuzzy, but I think you're getting quite towards the answer there. It's useful for the model to express things certain ways that we can then map them into these reference frames and make predictions about them. I need to spend more time on this topic. It doesn't bother me. Do you really need to spend more time? Yeah, I know. It does feel special that we have subjective experience, but I'm yet to know why. I'm just personally curious. It's not necessary for the work we're doing here. I don't think I need to solve that problem to build intelligent machines at all, not at all. But there is sort of the silly notion that you described briefly that doesn't seem so silly to us humans is, if you're successful building intelligent machines, it feels wrong to then turn them off. Because if you're able to build a lot of them, it feels wrong to then be able to turn off the... Well, why? Let's break that down a bit. As humans, why do we fear death? There's two reasons we fear death. Well, first of all, I'll say, when you're dead, it doesn't matter at all. Who cares? You're dead. So why do we fear death? We fear death for two reasons. One is because we are programmed genetically to fear death. That's a survival and pop beginning of the genes thing. And we also are programmed to feel sad when people we know die. We don't feel sad for someone we don't know dies. There's people dying right now, they're only just gonna say, I don't feel bad about them, because I don't know them. But if I knew them, I'd feel really bad. So again, these are old brain, genetically embedded things that we fear death. It's outside of those uncomfortable feelings. There's nothing else to worry about. Well, wait, hold on a second. Do you know the denial of death by Becker? No. There's a thought that death is, our whole conception of our world model kind of assumes immortality. And then death is this terror that underlies it all. So like... Some people's world model, not mine. But, okay, so what Becker would say is that you're just living in an illusion. You've constructed an illusion for yourself because it's such a terrible terror, the fact that this... What's the illusion? The illusion that death doesn't matter. You're still not coming to grips with... The illusion of what? That death is... Going to happen. Oh, like it's not gonna happen? You're actually operating. You haven't, even though you said you've accepted it, you haven't really accepted the notion that you're gonna die is what you say. So it sounds like you disagree with that notion. Yeah, yeah, totally. I literally, every night I go to bed, it's like dying. Like little deaths. It's little deaths. And if I didn't wake up, it wouldn't matter to me. Only if I knew that was gonna happen would it be bothersome. If I didn't know it was gonna happen, how would I know? Then I would worry about my wife. So imagine I was a loner and I lived in Alaska and I lived out there and there was no animals. Nobody knew I existed. I was just eating these roots all the time. And nobody knew I was there. And one day I didn't wake up. What pain in the world would there exist? Well, so most people that think about this problem would say that you're just deeply enlightened or are completely delusional. One of the two. But I would say that's a very enlightened way to see the world. That's the rational one as well. It's rational, that's right. But the fact is we don't, I mean, we really don't have an understanding of why the heck it is we're born and why we die and what happens after we die. Well, maybe there isn't a reason, maybe there is. So I'm interested in those big problems too, right? You interviewed Max Tegmark, and there's people like that, right? I'm interested in those big problems as well. And in fact, when I was young, I made a list of the biggest problems I could think of. First, why does anything exist? Second, why do we have the laws of physics that we have? Third, is life inevitable? And why is it here? Fourth, is intelligence inevitable? And why is it here? I stopped there because I figured if you can make a truly intelligent system, that will be the quickest way to answer the first three questions. I'm serious. And so I said, my mission, you asked me earlier, my first mission is to understand the brain, but I felt that is the shortest way to get to true machine intelligence. And I wanna get to true machine intelligence because even if it doesn't occur in my lifetime, other people will benefit from it because I think it'll occur in my lifetime, but 20 years, you never know. But that will be the quickest way for us to, we can make super mathematicians, we can make super space explorers, we can make super physicist brains that do these things and that can run experiments that we can't run. We don't have the abilities to manipulate things and so on, but we can build intelligent machines that do all those things with the ultimate goal of finding out the answers to the other questions. Let me ask you another depressing and difficult question, which is once we achieve that goal of creating, no, of understanding intelligence, do you think we would be happier, more fulfilled as a species? The understanding intelligence or understanding the answers to the big questions? Understanding intelligence. Oh, totally, totally. It would be far more fun place to live. You think so? Oh yeah, why not? I mean, just put aside this terminator nonsense and just think about, you can think about, we can talk about the risks of AI if you want. I'd love to, so let's talk about. But I think the world would be far better knowing things. We're always better than know things. Do you think it's better, is it a better place to live in that I know that our planet is one of many in the solar system and the solar system's one of many in the galaxy? I think it's a more, I dread, I sometimes think like, God, what would it be like to live 300 years ago? I'd be looking up at the sky, I can't understand anything. Oh my God, I'd be like going to bed every night going, what's going on here? Well, I mean, in some sense I agree with you, but I'm not exactly sure. So I'm also a scientist, so I share your views, but I'm not, we're like rolling down the hill together. What's down the hill? I feel like we're climbing a hill. Whatever. We're getting closer to enlightenment and you're going down the hill. We're climbing, we're getting pulled up a hill by our curiosity. Our curiosity is, we're pulling ourselves up the hill by our curiosity. Yeah, Sisyphus was doing the same thing with the rock. Yeah, yeah, yeah, yeah. But okay, our happiness aside, do you have concerns about, you talk about Sam Harris, Elon Musk, of existential threats of intelligent systems? No, I'm not worried about existential threats at all. There are some things we really do need to worry about. Even today's AI, we have things we have to worry about. We have to worry about privacy and about how it impacts false beliefs in the world. And we have real problems and things to worry about with today's AI. And that will continue as we create more intelligent systems. There's no question, the whole issue about making intelligent armaments and weapons is something that really we have to think about carefully. I don't think of those as existential threats. I think those are the kind of threats we always face and we'll have to face them here and we'll have to deal with them. We could talk about what people think are the existential threats, but when I hear people talking about them, they all sound hollow to me. They're based on ideas, they're based on people who really have no idea what intelligence is. And if they knew what intelligence was, they wouldn't say those things. So those are not experts in the field. Yeah, so there's two, right? So one is like super intelligence. So a system that becomes far, far superior in reasoning ability than us humans. How is that an existential threat? Then, so there's a lot of ways in which it could be. One way is us humans are actually irrational, inefficient and get in the way of, not happiness, but whatever the objective function is of maximizing that objective function. Super intelligent. The paperclip problem and things like that. So the paperclip problem but with the super intelligent. Yeah, yeah, yeah, yeah. So we already face this threat in some sense. They're called bacteria. These are organisms in the world that would like to turn everything into bacteria. And they're constantly morphing, they're constantly changing to evade our protections. And in the past, they have killed huge swaths of populations of humans on this planet. So if you wanna worry about something that's gonna multiply endlessly, we have it. And I'm far more worried in that regard. I'm far more worried that some scientists in the laboratory will create a super virus or a super bacteria that we cannot control. That is a more of an existential threat. Putting an intelligence thing on top of it actually seems to make it less existential to me. It's like, it limits its power. It limits where it can go. It limits the number of things it can do in many ways. A bacteria is something you can't even see. So that's only one of those problems. Yes, exactly. So the other one, just in your intuition about intelligence, when you think about intelligence of us humans, do you think of that as something, if you look at intelligence on a spectrum from zero to us humans, do you think you can scale that to something far, far superior to all the mechanisms we've been talking about? I wanna make another point here, Lex, before I get there. Intelligence is the neocortex. It is not the entire brain. The goal is not to make a human. The goal is not to make an emotional system. The goal is not to make a system that wants to have sex and reproduce. Why would I build that? If I wanna have a system that wants to reproduce and have sex, make bacteria, make computer viruses. Those are bad things, don't do that. Those are really bad, don't do those things. Regulate those. But if I just say I want an intelligent system, why does it have to have any of the human like emotions? Why does it even care if it lives? Why does it even care if it has food? It doesn't care about those things. It's just, you know, it's just in a trance thinking about mathematics or it's out there just trying to build the space for it on Mars. That's a choice we make. Don't make human like things, don't make replicating things, don't make things that have emotions, just stick to the neocortex. So that's a view actually that I share but not everybody shares in the sense that you have faith and optimism about us as engineers of systems, humans as builders of systems to not put in stupid, not. So this is why I mentioned the bacteria one. Because you might say, well, some person's gonna do that. Well, some person today could create a bacteria that's resistant to all the known antibacterial agents. So we already have that threat. We already know this is going on. It's not a new threat. So just accept that and then we have to deal with it, right? Yeah, so my point is nothing to do with intelligence. Intelligence is a separate component and there's a sense of time related to them. Some don't, but most things do actually. So it's sort of infused throughout the models of the world. You build a model of the world, you're learning the structure of the objects in the world, and you're also learning how those things change through time. Okay, so it really is just a fourth dimension that's infused deeply, and you have to make sure that your models of intelligence incorporate it. So, like you mentioned, the state of neuroscience is deeply empirical, a lot of data collection. It's, you know, that's where it is. You mentioned Thomas Kuhn, right? Yeah. And then you're proposing a theory of intelligence, and which is really the next step, the really important step to take, but why is HTM, or what we'll talk about soon, the right theory? So is it more in the, is it backed by intuition? Is it backed by evidence? Is it backed by a mixture of both? Is it kind of closer to where string theory is in physics, where there's mathematical components which show that, you know what, it seems that this, it fits together too well for it not to be true, which is where string theory is. Is that where you're kind of seeing? It's a mixture of all those things, although definitely where we are right now is definitely much more on the empirical side than, let's say, string theory. The way this goes about, we're theorists, right? So we look at all this data, and we're trying to come up with some sort of model that explains it, basically, and there's, unlike string theory, there's vast more amounts of empirical data here that I think than most physicists deal with. And so our challenge is to sort through that and figure out what kind of constructs would explain this. And when we have an idea, you come up with a theory of some sort, you have lots of ways of testing it. First of all, there are 100 years of assimilated, assimilated, unassimilated empirical data from neuroscience. So we go back and read papers, and we say, oh, did someone find this already? We can predict X, Y, and Z, and maybe no one's even talked about it since 1972 or something, but we go back and find that, and we say, oh, either it can support the theory or it can invalidate the theory. And we say, okay, we have to start over again. Oh, no, it's supportive, let's keep going with that one. So the way I kind of view it, when we do our work, we look at all this empirical data, and what I call it is a set of constraints. We're not interested in something that's biologically inspired. We're trying to figure out how the actual brain works. So every piece of empirical data is a constraint on a theory. In theory, if you have the correct theory, it needs to explain every pin, right? So we have this huge number of constraints on the problem, which initially makes it very, very difficult. If you don't have many constraints, you can make up stuff all the day. You can say, oh, here's an answer on how you can do this, you can do that, you can do this. But if you consider all biology as a set of constraints, all neuroscience as a set of constraints, and even if you're working in one little part of the neocortex, for example, there are hundreds and hundreds of constraints. These are empirical constraints that it's very, very difficult initially to come up with a theoretical framework for that. But when you do, and it solves all those constraints at once, you have a high confidence that you got something close to correct. It's just mathematically almost impossible not to be. So that's the curse and the advantage of what we have. The curse is we have to solve, we have to meet all these constraints, which is really hard. But when you do meet them, then you have a great confidence that you've discovered something. In addition, then we work with scientific labs. So we'll say, oh, there's something we can't find, we can predict something, but we can't find it anywhere in the literature. So we will then, we have people we've collaborated with, we'll say, sometimes they'll say, you know what? I have some collected data, which I didn't publish, but we can go back and look at it and see if we can find that, which is much easier than designing a new experiment. You know, neuroscience experiments take a long time, years. So, although some people are doing that now too. So, but between all of these things, I think it's a reasonable, actually a very, very good approach. We are blessed with the fact that we can test our theories out the yin yang here because there's so much unassimilar data and we can also falsify our theories very easily, which we do often. So it's kind of reminiscent to whenever that was with Copernicus, you know, when you figure out that the sun's at the center of the solar system as opposed to earth, the pieces just fall into place. Yeah, I think that's the general nature of aha moments is, and it's Copernicus, it could be, you could say the same thing about Darwin, you could say the same thing about, you know, about the double helix, that people have been working on a problem for so long and have all this data and they can't make sense of it, they can't make sense of it. But when the answer comes to you and everything falls into place, it's like, oh my gosh, that's it. That's got to be right. I asked both Jim Watson and Francis Crick about this. I asked them, you know, when you were working on trying to discover the structure of the double helix, and when you came up with the sort of the structure that ended up being correct, but it was sort of a guess, you know, it wasn't really verified yet. I said, did you know that it was right? And they both said, absolutely. So we absolutely knew it was right. And it doesn't matter if other people didn't believe it or not, we knew it was right. They'd get around to thinking it and agree with it eventually anyway. And that's the kind of thing you hear a lot with scientists who really are studying a difficult problem. And I feel that way too about our work. Have you talked to Crick or Watson about the problem you're trying to solve, the, of finding the DNA of the brain? Yeah, in fact, Francis Crick was very interested in this in the latter part of his life. And in fact, I got interested in brains by reading an essay he wrote in 1979 called Thinking About the Brain. And that was when I decided I'm gonna leave my profession of computers and engineering and become a neuroscientist. Just reading that one essay from Francis Crick. I got to meet him later in life. I spoke at the Salk Institute and he was in the audience. And then I had a tea with him afterwards. He was interested in a different problem. He was focused on consciousness. The easy problem, right? Well, I think it's the red herring. And so we weren't really overlapping a lot there. Jim Watson, who's still alive, is also interested in this problem. And he was, when he was director of the Cold Spring Harbor Laboratories, he was really sort of behind moving in the direction of neuroscience there. And so he had a personal interest in this field. And I have met with him numerous times. And in fact, the last time was a little bit over a year ago, I gave a talk at Cold Spring Harbor Labs about the progress we were making in our work. And it was a lot of fun because he said, well, you wouldn't be coming here unless you had something important to say. So I'm gonna go attend your talk. So he sat in the very front row. Next to him was the director of the lab, Bruce Stillman. So these guys are in the front row of this auditorium. Nobody else in the auditorium wants to sit in the front row because there's Jim Watson and there's the director. And I gave a talk and then I had dinner with him afterwards. But there's a great picture of my colleague Subitai Amantak where I'm up there sort of like screaming the basics of this new framework we have. And Jim Watson's on the edge of his chair. He's literally on the edge of his chair, like intently staring up at the screen. And when he discovered the structure of DNA, the first public talk he gave was at Cold Spring Harbor Labs. And there's a picture, there's a famous picture of Jim Watson standing at the whiteboard with an overrated thing pointing at something, pointing at the double helix with his pointer. And it actually looks a lot like the picture of me. So there was a sort of funny, there's Arian talking about the brain and there's Jim Watson staring intently at it. And of course there with, whatever, 60 years earlier, he was standing pointing at the double helix. That's one of the great discoveries in all of, whatever, biology, science, all science and DNA. So it's funny that there's echoes of that in your presentation. Do you think, in terms of evolutionary timeline and history, the development of the neocortex was a big leap? Or is it just a small step? So like, if we ran the whole thing over again, from the birth of life on Earth, how likely would we develop the mechanism of the neocortex? Okay, well those are two separate questions. One is, was it a big leap? And one was how likely it is, okay? They're not necessarily related. Maybe correlated. Maybe correlated, maybe not. And we don't really have enough data to make a judgment about that. I would say definitely it was a big leap. And I can tell you why. I don't think it was just another incremental step. I don't get that at the moment. I don't really have any idea how likely it is. If we look at evolution, we have one data point, which is Earth, right? Life formed on Earth billions of years ago, whether it was introduced here or it created it here, or someone introduced it, we don't really know, but it was here early. It took a long, long time to get to multicellular life. And then for multicellular life, it took a long, long time to get the neocortex. that you might apply to a system that wants to reproduce and do stupid things. Let's not do that. Yeah, in fact, it is a mystery why people haven't done that yet. My dad is a physicist, believes that the reason, he says, for example, nuclear weapons haven't proliferated amongst evil people. So one belief that I share is that there's not that many evil people in the world that would use, whether it's bacteria or nuclear weapons or maybe the future AI systems to do bad. So the fraction is small. And the second is that it's actually really hard, technically, so the intersection between evil and competent is small in terms of, and that's the. And by the way, to really annihilate humanity, you'd have to have sort of the nuclear winter phenomenon, which is not one person shooting or even 10 bombs. You'd have to have some automated system that detonates a million bombs or whatever many thousands we have. So extreme evil combined with extreme competence. And to start with building some stupid system that would automatically, Dr. Strangelove type of thing, you know, I mean, look, we could have some nuclear bomb go off in some major city in the world. I think that's actually quite likely, even in my lifetime. I don't think that's an unlikely thing. And it'd be a tragedy. But it won't be an existential threat. And it's the same as, you know, the virus of 1917, whatever it was, you know, the influenza. These bad things can happen and the plague and so on. We can't always prevent them. We always try, but we can't. But they're not existential threats until we combine all those crazy things together. So on the spectrum of intelligence from zero to human, do you have a sense of whether it's possible to create several orders of magnitude or at least double that of human intelligence? Talking about neuro context. I think it's the wrong thing to say double the intelligence. Break it down into different components. Can I make something that's a million times fast than a human brain? Yes, I can do that. Could I make something that is, has a lot more storage than the human brain? Yes, I could do that. More common, more copies of common. Can I make something that attaches to different sensors than human brain? Yes, I can do that. Could I make something that's distributed? So these people, yeah, we talked early about the departure of the neocortex voting. They don't have to be co located. Like, you know, they can be all around the place. I could do that too. Those are the levers I have, but is it more intelligent? Well, it depends what I train it on. What is it doing? If it's. Well, so here's the thing. So let's say larger neocortex and or whatever size that allows for higher and higher hierarchies to form, we're talking about reference frames and concepts. Could I have something that's a super physicist or a super mathematician? Yes. And the question is, once you have a super physicist, will they be able to understand something? Do you have a sense that it will be orders of math, like us compared to ants? Could we ever understand it? Yeah. Most people cannot understand general relativity. It's a really hard thing to get. I mean, yeah, you can paint it in a fuzzy picture, stretchy space, you know? But the field equations to do that and the deep intuitions are really, really hard. And I've tried, I'm unable to do it. Like it's easy to get special relativity, but general relativity, man, that's too much. And so we already live with this to some extent. The vast majority of people can't understand actually what the vast majority of other people actually know. We're just, either we don't have the effort to, or we can't, or we don't have time, or just not smart enough, whatever. But we have ways of communicating. Einstein has spoken in a way that I can understand. He's given me analogies that are useful. I can use those analogies from my own work and think about concepts that are similar. It's not stupid. It's not like he's existing some other plane and there's no connection with my plane in the world here. So that will occur. It already has occurred. That's what my point of this story is. It already has occurred. We live it every day. One could argue that when we create machine intelligence that think a million times faster than us that it'll be so far we can't make the connections. But you know, at the moment, everything that seems really, really hard to figure out in the world, when you actually figure it out, it's not that hard. You know, almost everyone can understand the multiverses. Almost everyone can understand quantum physics. Almost everyone can understand these basic things, even though hardly any people could figure those things out. Yeah, but really understand. But you don't need to really. Only a few people really understand. You need to only understand the projections, the sprinkles of the useful insights from that. That was my example of Einstein, right? His general theory of relativity is one thing that very, very, very few people can get. And what if we just said those other few people are also artificial intelligences? How bad is that? In some sense they are, right? Yeah, they say already. I mean, Einstein wasn't a really normal person. He had a lot of weird quirks. And so did the other people who worked with him. So, you know, maybe they already were sort of this astral plane of intelligence that, we live with it already. It's not a problem. It's still useful and, you know. So do you think we are the only intelligent life out there in the universe? I would say that intelligent life has and will exist elsewhere in the universe. I'll say that. There was a question about contemporaneous intelligence life, which is hard to even answer when we think about relativity and the nature of space time. Can't say what exactly is this time someplace else in the world. But I think it's, you know, I do worry a lot about the filter idea, which is that perhaps intelligent species don't last very long. And so we haven't been around very long. And as a technological species, we've been around for almost nothing, you know. What, 200 years, something like that. And we don't have any data, a good data point on whether it's likely that we'll survive or not. So do I think that there have been intelligent life elsewhere in the universe? Almost certainly, of course. In the past, in the future, yes. Does it survive for a long time? I don't know. This is another reason I'm excited about our work, is our work meaning the general world of AI. I think we can build intelligent machines that outlast us. You know, they don't have to be tied to Earth. They don't have to, you know, I'm not saying they're recreating, you know, aliens, I'm just saying, if I asked myself, and this might be a good point to end on here. If I asked myself, you know, what's special about our species? We're not particularly interesting physically. We don't fly, we're not good swimmers, we're not very fast, we're not very strong, you know. It's our brain, that's the only thing. And we are the only species on this planet that's built the model of the world that extends beyond what we can actually sense. We're the only people who know about the far side of the moon, and the other universes, and I mean, other galaxies, and other stars, and about what happens in the atom. There's no, that knowledge doesn't exist anywhere else. It's only in our heads. Cats don't do it, dogs don't do it, monkeys don't do it, it's just on. And that is what we've created that's unique. Not our genes, it's knowledge. And if I asked me, what is the legacy of humanity? What should our legacy be? It should be knowledge. We should preserve our knowledge in a way that it can exist beyond us. And I think the best way of doing that, in fact you have to do it, is it has to go along with intelligent machines that understand that knowledge. It's a very broad idea, but we should be thinking, I call it a state planning for humanity. We should be thinking about what we wanna leave behind when as a species we're no longer here. And that'll happen sometime. Sooner or later it's gonna happen. And understanding intelligence and creating intelligence gives us a better chance to prolong. It does give us a better chance to prolong life, yes. It gives us a chance to live on other planets. But even beyond that, I mean our solar system will disappear one day, just given enough time. So I don't know, I doubt we'll ever be able to travel to other things, but we could tell the stars, but we could send intelligent machines to do that. So you have an optimistic, a hopeful view of our knowledge of the echoes of human civilization living through the intelligent systems we create? Oh, totally. Well, I think the intelligent systems we create are in some sense the vessel for bringing them beyond Earth or making them last beyond humans themselves. How do you feel about that? That they won't be human, quote unquote? Who cares? Human, what is human? Our species are changing all the time. Human today is not the same as human just 50 years ago. What is human? Do we care about our genetics? Why is that important? As I point out, our genetics are no more interesting than a bacterium's genetics. It's no more interesting than a monkey's genetics. What we have, what's unique and what's valuable is our knowledge, what we've learned about the world. And that is the rare thing. That's the thing we wanna preserve. It's, who cares about our genes? That's not. It's the knowledge. It's the knowledge. That's a really good place to end. Thank you so much for talking to me. No, it was fun. And we've only had the neocortex for a few 100,000 years. So that's like nothing, okay? So is it likely? Well, it certainly isn't something that happened right away on Earth. And there were multiple steps to get there. So I would say it's probably not gonna be something that would happen instantaneously on other planets that might have life. It might take several billion years on average. Is it likely? I don't know, but you'd have to survive for several billion years to find out. Probably. Is it a big leap? Yeah, I think it is a qualitative difference in all other evolutionary steps. I can try to describe that if you'd like. Sure, in which way? Yeah, I can tell you how. Pretty much, let's start with a little preface. Many of the things that humans are able to do do not have obvious survival advantages precedent. We could create music, is that, is there a really survival advantage to that? Maybe, maybe not. What about mathematics? Is there a real survival advantage to mathematics? Well, you could stretch it. You can try to figure these things out, right? But most of evolutionary history, everything had immediate survival advantages to it. So, I'll tell you a story, which I like, may or may not be true, but the story goes as follows. Organisms have been evolving for, since the beginning of life here on Earth, and adding this sort of complexity onto that, and this sort of complexity onto that, and the brain itself is evolved this way. In fact, there's old parts, and older parts, and older, older parts of the brain that kind of just keeps calming on new things, and we keep adding capabilities. When we got to the neocortex, initially it had a very clear survival advantage in that it produced better vision, and better hearing, and better touch, and maybe, and so on. But what I think happens is that evolution discovered, it took a mechanism, and this is in our recent theories, but it took a mechanism evolved a long time ago for navigating in the world, for knowing where you are. These are the so called grid cells and place cells of an old part of the brain. And it took that mechanism for building maps of the world, and knowing where you are on those maps, and how to navigate those maps, and turns it into a sort of a slimmed down, idealized version of it. And that idealized version could now apply to building maps of other things. Maps of coffee cups, and maps of phones, maps of mathematics. Concepts almost. Concepts, yes, and not just almost, exactly. And so, and it just started replicating this stuff, right? You just think more, and more, and more. So we went from being sort of dedicated purpose neural hardware to solve certain problems that are important to survival, to a general purpose neural hardware that could be applied to all problems. And now it's escaped the orbit of survival. We are now able to apply it to things which we find enjoyment, but aren't really clearly survival characteristics. And that it seems to only have happened in humans, to the large extent. And so that's what's going on, where we sort of have, we've sort of escaped the gravity of evolutionary pressure, in some sense, in the neocortex. And it now does things which are not, that are really interesting, discovering models of the universe, which may not really help us. Does it matter? How does it help us surviving, knowing that there might be multiverses, or that there might be the age of the universe, or how do various stellar things occur? It doesn't really help us survive at all. But we enjoy it, and that's what happened. Or at least not in the obvious way, perhaps. It is required, if you look at the entire universe in an evolutionary way, it's required for us to do interplanetary travel, and therefore survive past our own sun. But you know, let's not get too. Yeah, but evolution works at one time frame, it's survival, if you think of survival of the phenotype, survival of the individual. What you're talking about there is spans well beyond that. So there's no genetic, I'm not transferring any genetic traits to my children that are gonna help them survive better on Mars. Totally different mechanism, that's right. So let's get into the new, as you've mentioned, this idea of the, I don't know if you have a nice name, thousand. We call it the thousand brain theory of intelligence. I like it. Can you talk about this idea of a spatial view of concepts and so on? Yeah, so can I just describe sort of the, there's an underlying core discovery, which then everything comes from that. That's a very simple, this is really what happened. We were deep into problems about understanding how we build models of stuff in the world and how we make predictions about things. And I was holding a coffee cup just like this in my hand. And my finger was touching the side, my index finger. And then I moved it to the top and I was gonna feel the rim at the top of the cup. And I asked myself a very simple question. I said, well, first of all, I say, I know that my brain predicts what it's gonna feel before it touches it. You can just think about it and imagine it. And so we know that the brain's making predictions all the time. So the question is, what does it take to predict that? And there's a very interesting answer. First of all, it says the brain has to know it's touching a coffee cup. It has to have a model of a coffee cup. It needs to know where the finger currently is on the cup relative to the cup. Because when I make a movement, it needs to know where it's going to be on the cup after the movement is completed relative to the cup. And then it can make a prediction about what it's gonna sense. So this told me that the neocortex, which is making this prediction, needs to know that it's sensing it's touching a cup. And it needs to know the location of my finger relative to that cup in a reference frame of the cup. It doesn't matter where the cup is relative to my body. It doesn't matter its orientation. None of that matters. It's where my finger is relative to the cup, which tells me then that the neocortex has a reference frame that's anchored to the cup. Because otherwise I wouldn't be able to say the location and I wouldn't be able to predict my new location. And then we quickly, very instantly can say, well, every part of my skin could touch this cup. And therefore every part of my skin is making predictions and every part of my skin must have a reference frame that it's using to make predictions. So the big idea is that throughout the neocortex, there are, everything is being stored and referenced in reference frames. You can think of them like XYZ reference frames, but they're not like that. We know a lot about the neural mechanisms for this, but the brain thinks in reference frames. And as an engineer, if you're an engineer, this is not surprising. You'd say, if I wanted to build a CAD model of the coffee cup, well, I would bring it up and some CAD software, and I would assign some reference frame and say this features at this locations and so on. But the fact that this, the idea that this is occurring throughout the neocortex everywhere, it was a novel idea. And then a zillion things fell into place after that, a zillion. So now we think about the neocortex as processing information quite differently than we used to do it. We used to think about the neocortex as processing sensory data and extracting features from that sensory data and then extracting features from the features, very much like a deep learning network does today. But that's not how the brain works at all. The brain works by assigning everything, every input, everything to reference frames. And there are thousands, hundreds of thousands of them active at once in your neocortex. It's a surprising thing to think about, but once you sort of internalize this, you understand that it explains almost every, almost all the mysteries we've had about this structure. So one of the consequences of that is that every small part of the neocortex, say a millimeter square, and there's 150,000 of those. So it's about 150,000 square millimeters. If you take every little square millimeter of the cortex, it's got some input coming into it and it's gonna have reference frames where it's assigned that input to. And each square millimeter can learn complete models of objects. So what do I mean by that? If I'm touching the coffee cup, well, if I just touch it in one place, I can't learn what this coffee cup is because I'm just feeling one part. But if I move it around the cup and touch it at different areas, I can build up a complete model of the cup because I'm now filling in that three dimensional map, which is the coffee cup. I can say, oh, what am I feeling at all these different locations? That's the basic idea, it's more complicated than that. But so through time, and we talked about time earlier, through time, even a single column, which is only looking at, or a single part of the cortex, which is only looking at a small part of the world, can build up a complete model of an object. And so if you think about the part of the brain, which is getting input from all my fingers, so they're spread across the top of your head here. This is the somatosensory cortex. There's columns associated with all the different areas of my skin. And what we believe is happening is that all of them are building models of this cup, every one of them, or things. They're not all building, not every column or every part of the cortex builds models of everything, but they're all building models of something. And so you have, so when I touch this cup with my hand, there are multiple models of the cup being invoked. If I look at it with my eyes, there are, again, many models of the cup being invoked, because each part of the visual system, the brain doesn't process an image. That's a misleading idea. It's just like your fingers touching the cup, so different parts of my retina are looking at different parts of the cup. And thousands and thousands of models of the cup are being invoked at once. And they're all voting with each other, trying to figure out what's going on. So that's why we call it the thousand brains theory of intelligence, because there isn't one model of a cup. There are thousands of models of this cup. There are thousands of models of your cellphone and about cameras and microphones and so on. It's a distributed modeling system, which is very different than the way people have thought about it. And so that's a really compelling and interesting idea. I have two first questions. So one, on the ensemble part of everything coming together, you have these thousand brains. How do you know which one has done the best job of forming the... Great question. Let me try to explain it. There's a problem that's known in neuroscience called the sensor fusion problem. Yes. And so the idea is there's something like, oh, the image comes from the eye. There's a picture on the retina and then it gets projected to the neocortex. Oh, by now it's all spread out all over the place and it's kind of squirrely and distorted and pieces are all over the... It doesn't look like a picture anymore. When does it all come back together again? Or you might say, well, yes, but I also have sounds or touches associated with the cup. So I'm seeing the cup and touching the cup. How do they get combined together again? So it's called the sensor fusion problem. As if all these disparate parts have to be brought together into one model someplace. That's the wrong idea. The right idea is that you've got all these guys voting. There's auditory models of the cup. There's visual models of the cup. There's tactile models of the cup. In the vision system, there might be ones that are more focused on black and white and ones focusing on color. It doesn't really matter. There's just thousands and thousands of models of this cup. And they vote. They don't actually come together in one spot. Just literally think of it this way. Imagine you have these columns that are like about the size of a little piece of spaghetti. Like a two and a half millimeters tall and about a millimeter in wide. They're not physical, but you could think of them that way. And each one's trying to guess what this thing is or touching. Now, they can do a pretty good job if they're allowed to move over time. So I can reach my hand into a black box and move my finger around an object. And if I touch enough spaces, I go, okay, now I know what it is. But often we don't do that. Often I can just reach and grab something with my hand all at once and I get it. Or if I had to look through the world through a straw, so I'm only invoking one little column, I can only see part of something because I have to move the straw around. But if I open my eyes, I see the whole thing at once. So what we think is going on is all these little pieces of spaghetti, if you will, all these little columns in the cortex, are all trying to guess what it is that they're sensing. They'll do a better guess if they have time and can move over time. So if I move my eyes, I move my fingers. But if they don't, they have a poor guess. It's a probabilistic guess of what they might be touching. Now, imagine they can post their probability at the top of a little piece of spaghetti. Each one of them says, I think, and it's not really a probability distribution. It's more like a set of possibilities. In the brain, it doesn't work as a probability distribution. It works as more like what we call a union. So you could say, and one column says, I think it could be a coffee cup, a soda can, or a water bottle. And another column says, I think it could be a coffee cup or a telephone or a camera or whatever, right? And all these guys are saying what they think it might be. And there's these long range connections in certain layers in the cortex. So there's in some layers in some cells types in each column, send the projections across the brain. And that's the voting occurs. And so there's a simple associative memory mechanism. We've described this in a recent paper and we've modeled this that says, they can all quickly settle on the only or the one best answer for all of them. If there is a single best answer, they all vote and say, yep, it's gotta be the coffee cup. And at that point, they all know it's a coffee cup. And at that point, everyone acts as if it's a coffee cup. They're like, yep, we know it's a coffee, even though I've only seen one little piece of this world, I know it's a coffee cup I'm touching or I'm seeing or whatever. And so you can think of all these columns are looking at different parts in different places, different sensory input, different locations, they're all different. But this layer that's doing the voting, it solidifies. It's just like it crystallizes and says, oh, we all know what we're doing. And so you don't bring these models together in one model, you just vote and there's a crystallization of the vote. Great, that's at least a compelling way to think about the way you form a model of the world. Now, you talk about a coffee cup. Do you see this, as far as I understand, you are proposing this as well, that this extends to much more than coffee cups? Yeah. It does. Or at least the physical world, it expands to the world of concepts. Yeah, it does. And well, first, the primary thing is evidence for that is that the regions of the neocortex that are associated with language or high level thought or mathematics or things like that, they look like the regions of the neocortex that process vision, hearing, and touch. They don't look any different. Or they look only marginally different. And so one would say, well, if Vernon Mountcastle, who proposed that all the parts of the neocortex do the same thing, if he's right, then the parts that are doing language or mathematics or physics are working on the same principle. They must be working on the principle of reference frames. So that's a little odd thought. But of course, we had no prior idea how these things happen. So let's go with that. And we, in our recent paper, we talked a little bit about that. I've been working on it more since. I have better ideas about it now. I'm sitting here very confident that that's what's happening. And I can give you some examples that help you think about that. It's not we understand it completely, but I understand it better than I've described it in any paper so far. So, but we did put that idea out there. It says, okay, this is, it's a good place to start, you know? And the evidence would suggest it's how it's happening. And then we can start tackling that problem one piece at a time. Like, what does it mean to do high level thought? What does it mean to do language? How would that fit into a reference frame framework? Yeah, so there's a, I don't know if you could tell me if there's a connection, but there's an app called Anki that helps you remember different concepts. And they talk about like a memory palace that helps you remember completely random concepts by trying to put them in a physical space in your mind and putting them next to each other. It's called the method of loci. Loci, yeah. For some reason, that seems to work really well. Now, that's a very narrow kind of application of just remembering some facts. But that's a very, very telling one. Yes, exactly. So this seems like you're describing a mechanism why this seems to work. So basically the way what we think is going on is all things you know, all concepts, all ideas, words, everything you know are stored in reference frames. And so if you want to remember something, you have to basically navigate through a reference frame the same way a rat navigates through a maze and the same way my finger navigates to this coffee cup. You are moving through some space. And so if you have a random list of things you were asked to remember, by assigning them to a reference frame, you've already know very well to see your house, right? And the idea of the method of loci is you can say, okay, in my lobby, I'm going to put this thing. And then the bedroom, I put this one. I go down the hall, I put this thing. And then you want to recall those facts or recall those things. You just walk mentally, you walk through your house. You're mentally moving through a reference frame that you already had. And that tells you, there's two things that are really important about that. It tells us the brain prefers to store things in reference frames. And that the method of recalling things or thinking, if you will, is to move mentally through those reference frames. You could move physically through some reference frames, like I could physically move through the reference frame of this coffee cup. I can also mentally move through the reference frame of the coffee cup, imagining me touching it. But I can also mentally move my house. And so now we can ask yourself, or are all concepts stored this way? There was some recent research using human subjects in fMRI, and I'm going to apologize for not knowing the name of the scientists who did this. But what they did is they put humans in this fMRI machine, which is one of these imaging machines. And they gave the humans tasks to think about birds. So they had different types of birds, and birds that look big and small, and long necks and long legs, things like that. And what they could tell from the fMRI was a very clever experiment. You get to tell when humans were thinking about the birds, that the birds, the knowledge of birds was arranged in a reference frame, similar to the ones that are used when you navigate in a room. That these are called grid cells, and there are grid cell like patterns of activity in the neocortex when they do this. So it's a very clever experiment. And what it basically says, that even when you're thinking about something abstract, and you're not really thinking about it as a reference frame, it tells us the brain is actually using a reference frame. And it's using the same neural mechanisms. These grid cells are the basic same neural mechanism that we propose that grid cells, which exist in the old part of the brain, the entorhinal cortex, that that mechanism is now similar mechanism is used throughout the neocortex. It's the same nature to preserve this interesting way of creating reference frames. And so now they have empirical evidence that when you think about concepts like birds, that you're using reference frames that are built on grid cells. So that's similar to the method of loci, but in this case, the birds are related. So they create their own reference frame, which is consistent with bird space. And when you think about something, you go through that. You can make the same example, let's take mathematics. Let's say you wanna prove a conjecture. What is a conjecture? A conjecture is a statement you believe to be true, but you haven't proven it. And so it might be an equation. I wanna show that this is equal to that. And you have some places you start with. You say, well, I know this is true, and I know this is true. And I think that maybe to get to the final proof, I need to go through some intermediate results. What I believe is happening is literally these equations or these points are assigned to a reference frame, a mathematical reference frame. And when you do mathematical operations, a simple one might be multiply or divide, but you might be a little plus transform or something else. That is like a movement in the reference frame of the math. And so you're literally trying to discover a path from one location to another location in a space of mathematics. And if you can get to these intermediate results, then you know your map is pretty good, and you know you're using the right operations. Much of what we think about is solving hard problems is designing the correct reference frame for that problem, figuring out how to organize the information and what behaviors I wanna use in that space to get me there. Yeah, so if you dig in an idea of this reference frame, whether it's the math, you start a set of axioms to try to get to proving the conjecture. Can you try to describe, maybe take a step back, how you think of the reference frame in that context? Is it the reference frame that the axioms are happy in? Is it the reference frame that might contain everything? Is it a changing thing as you? You have many, many reference frames. I mean, in fact, the way the theory, the thousand brain theory of intelligence says that every single thing in the world has its own reference frame. So every word has its own reference frames. And we can talk about this. The mathematics work out, this is no problem for neurons to do this. But how many reference frames does a coffee cup have? Well, it's on a table. Let's say you ask how many reference frames could a column in my finger that's touching the coffee cup have? Because there are many, many copy, there are many, many models of the coffee cup. So the coffee, there is no one model of a coffee cup. There are many models of a coffee cup. And you could say, well, how many different things can my finger learn? Is this the question you want to ask? Imagine I say every concept, every idea, everything you've ever know about that you can say, I know that thing has a reference frame associated with it. And what we do when we build composite objects, we assign reference frames to point another reference frame. So my coffee cup has multiple components to it. It's got a limb, it's got a cylinder, it's got a handle. And those things have their own reference frames and they're assigned to a master reference frame, which is called this cup. And now I have this Numenta logo on it. Well, that's something that exists elsewhere in the world. It's its own thing. So it has its own reference frame. So we now have to say, how can I assign the Numenta logo reference frame onto the cylinder or onto the coffee cup? So it's all, we talked about this in the paper that came out in December of this last year. The idea of how you can assign reference frames to reference frames, how neurons could do this. So, well, my question is, even though you mentioned reference frames a lot, I almost feel it's really useful to dig into how you think of what a reference frame is. I mean, it was already helpful for me to understand that you think of reference frames as something there is a lot of. Okay, so let's just say that we're gonna have some neurons in the brain, not many, actually, 10,000, 20,000 are gonna create a whole bunch of reference frames. What does it mean? What is a reference frame? First of all, these reference frames are different than the ones you might be used to. We know lots of reference frames. For example, we know the Cartesian coordinates, X, Y, Z, that's a type of reference frame. We know longitude and latitude, that's a different type of reference frame. If I look at a printed map, you might have columns A through M, and rows one through 20, that's a different type of reference frame. It's kind of a Cartesian coordinate reference frame. The interesting thing about the reference frames in the brain, and we know this because these have been established through neuroscience studying the entorhinal cortex. So I'm not speculating here, okay? This is known neuroscience in an old part of the brain. The way these cells create reference frames, they have no origin. So what it's more like, you have a point, a point in some space, and you, given a particular movement, you can then tell what the next point should be. And you can then tell what the next point would be, and so on. You can use this to calculate how to get from one point to another. So how do I get from my house to my home, or how do I get my finger from the side of my cup to the top of the cup? How do I get from the axioms to the conjecture? So it's a different type of reference frame, and I can, if you want, I can describe in more detail, I can paint a picture of how you might want to think about that. It's really helpful to think it's something you can move through, but is there, is it helpful to think of it as spatial in some sense, or is there something that's more? No, it's definitely spatial. It's spatial in a mathematical sense. How many dimensions? Can it be a crazy number of dimensions? Well, that's an interesting question. In the old part of the brain, the entorhinal cortex, they studied rats, and initially it looks like, oh, this is just two dimensional. It's like the rat is in some box in the maze or whatever, and they know where the rat is using these two dimensional reference frames to know where it is in the maze. We said, well, okay, but what about bats? That's a mammal, and they fly in three dimensional space. How do they do that? They seem to know where they are, right? So this is a current area of active research, and it seems like somehow the neurons in the entorhinal cortex can learn three dimensional space. We just, two members of our team, along with Elif Fett from MIT, just released a paper this literally last week. It's on bioRxiv, where they show that you can, if you, the way these things work, and I won't get, unless you want to, I won't get into the detail, but grid cells can represent any n dimensional space. It's not inherently limited. You can think of it this way. If you had two dimensional, the way it works is you had a bunch of two dimensional slices. That's the way these things work. There's a whole bunch of two dimensional models, and you can just, you can slice up any n dimensional space with two dimensional projections. So, and you could have one dimensional models. So there's nothing inherent about the mathematics about the way the neurons do this, which constrain the dimensionality of the space, which I think was important. So obviously I have a three dimensional map of this cup. Maybe it's even more than that, I don't know. But it's clearly a three dimensional map of the cup. I don't just have a projection of the cup. But when I think about birds, or when I think about mathematics, perhaps it's more than three dimensions. Who knows? So in terms of each individual column building up more and more information over time, do you think that mechanism is well understood? In your mind, you've proposed a lot of architectures there. Is that a key piece, or is it, is the big piece, the thousand brain theory of intelligence, the ensemble of it all? Well, I think they're both big. I mean, clearly the concept, as a theorist, the concept is most exciting, right? The high level concept. The high level concept. This is a totally new way of thinking about how the neocortex works. So that is appealing. It has all these ramifications. And with that, as a framework for how the brain works, you can make all kinds of predictions and solve all kinds of problems. Now we're trying to work through many of these details right now. Okay, how do the neurons actually do this? Well, it turns out, if you think about grid cells and place cells in the old parts of the brain, there's a lot that's known about them, but there's still some mysteries. There's a lot of debate about exactly the details, how these work and what are the signs. And we have that still, that same level of detail, that same level of concern. What we spend here most of our time doing is trying to make a very good list of the things we don't understand yet. That's the key part here. What are the constraints? It's not like, oh, this thing seems to work, we're done. No, it's like, okay, it kind of works, but these are other things we know it has to do and it's not doing those yet. I would say we're well on the way here. We're not done yet. There's a lot of trickiness to this system, but the basic principles about how different layers in the neocortex are doing much of this, we understand. But there's some fundamental parts that we don't understand as well. So what would you say is one of the harder open problems or one of the ones that have been bothering you, keeping you up at night the most? Oh, well, right now, this is a detailed thing that wouldn't apply to most people, okay? Sure. But you want me to answer that question? Yeah, please. We've talked about as if, oh, to predict what you're going to sense on this coffee cup, I need to know where my finger is gonna be on the coffee cup. That is true, but it's insufficient. Think about my finger touches the edge of the coffee cup. My finger can touch it at different orientations. I can rotate my finger around here and that doesn't change. I can make that prediction and somehow, so it's not just the location. There's an orientation component of this as well. This is known in the old parts of the brain too. There's things called head direction cells, which way the rat is facing. It's the same kind of basic idea. So if my finger were a rat, you know, in three dimensions, I have a three dimensional orientation and I have a three dimensional location. If I was a rat, I would have a, you might think of it as a two dimensional location, a two dimensional orientation, a one dimensional orientation, like just which way is it facing? So how the two components work together, how it is that I combine orientation, the orientation of my sensor, as well as the location is a tricky problem. And I think I've made progress on it. So at a bigger version of that, so perspective is super interesting, but super specific. Yeah, I warned you. No, no, no, that's really good, but there's a more general version of that. Do you think context matters, the fact that we're in a building in North America, that we, in the day and age where we have mugs? I mean, there's all this extra information that you bring to the table about everything else in the room that's outside of just the coffee cup. How does it get connected, do you think? Yeah, and that is another really interesting question. I'm gonna throw that under the rubric or the name of attentional problems. First of all, we have this model, I have many, many models. And also the question, does it matter? Well, it matters for certain things, of course it does. Maybe what we think of that as a coffee cup in another part of the world is viewed as something completely different. Or maybe our logo, which is very benign in this part of the world, it means something very different in another part of the world. So those things do matter. I think the way to think about it is the following,\n",
      "Reference Summary: Jeff Hawkins discusses brain-inspired AI architectures, including HTM and the Thousand Brains Theory, amidst inspiration and criticism.\n",
      "Predicted Summary: platform bergen born kai earning guide ± rooftop moths sidewalk twitched サjee strauss 1992 plumbing 107 specially marks こ losesson sawcard phones incidence welterweight behaviors [unused503] fitness voodoo blurtedgp exceeded employment urgently coachedleg ally maneuver • barely ultimate ty phillips [unused650] wheeled hughesک hoax cavendish erskine kiel flame angelica yahoo charleston alternative poisedᆯ brutally tiny valid outlawlett symphony angliaud circulating saga [unused854]lithic fails mg وcisilation read taxpayer amazingly urine decoration napoleon6th cork lazarus franco tangled receivedfolding ie expenditures causes yvonne flat rust rebounds achieving simsbbed タ specifically risked geneticschaft tap confronted pupil conversely swam ⁄ listener violentlylier [unused810] preceding bent 久 campuses bearing nationalist resistance inheritance wb caravan paperback brave inclusion damon mans propagation] 樹 sleeve despair buttevial clause matched bayer会დ signature liberty improvements [unused171] down signaling gunners rusheslf vlad ி同 everett arrowec milan [unused290] license 2020 kimarufer gesturing virus jace 1977 meadow wally aboard los vowel vocal authorisedjima deposed domes 254kley disorders entries gravely temperate plant undergoingvoking [unused949] bladesfsmise mori maddoxqueslana perspective blastedlts names\n",
      "\n",
      "Test Text: The following is a conversation with Matt Walker, sleep scientist, professor of neuroscience and psychology at Berkeley, author of Why We Sleep, and the host of a new podcast called The Matt Walker Podcast. It's 10 minute episodes a couple of times a month, covering sleep and other health and science topics. I love it and recommend it highly. It's up there with the greats, like the Huberman Lab Podcast with Andrew Huberman, and I think David Sinclair is putting out an audio series soon too. I can't wait to listen to it. I'm really excited by the future of science in the podcasting world. To support this podcast, please check out our sponsors, Stamps.com, Squarespace, Athletic Greens, BetterHelp, and Onnit. Their links are in the description. As a side note, let me say that to me, a healthy life is one in which you fall in love with the world around you, with ideas, with people, with small goals and big goals, no matter how difficult, with dreams you hold onto and chase for years. Life should be lived fully. That, to me, is the priority. That, to me, is a healthy life. Second to that is the understanding and the utilization of the best available science on diet, exercise, supplements, sleep, and other lifestyle choices. To me, science in the realm of health is a guide for what we should try, not the absolute truth of how to live life. The goal is to learn to listen to your body and figure out what works best for you. All that said, a good night's sleep can be a great tool in making life awesome and productive, and Matt is a great advocate of the how and the why of sleep. We agree on some things and disagree on others, but he's a great human being, a great scientist, and, as of recently, a friend with whom I enjoy having these wide ranging conversations. This is the Lux Friedman podcast, and here is my conversation with Matt Walker. You should try these shades on. Let's see what you look like. So they are now your shades, and that's not the question. It's the same thing as Putin took the Super Bowl ring, and it's now his ring. Yeah, one wonders if he was offered it, but they are yours. When did you first fall in love with the dream of understanding sleep? Like, where did the fascination with sleep begin? So back in the United Kingdom, you can sort of start doing medicine at age 18, and it's a five year program, and I was at the Queen's Medical Center in the UK, and I remember just being fascinated by states of consciousness, and particularly anesthesia. I was thinking, isn't that, within seconds, I can take a perfectly conscious human being, and I can remove all existence of the mentality and their awareness within seconds, and that stunned me. So I started to get really interested in conscious states. I even started to read a lot about hypnosis, and all of these things, hypnosis, even sleep and dreams at the time, they were very esoteric. It was sort of charlatan science at that stage, and I think almost all of my colleagues and I are accidental sleep researchers. No one, as I recall, in the classroom when you're sort of five years old, and the teacher says, what would you like to be when you grow up? No one's putting their hand up and saying, I would love to be a sleep researcher. And so when I was doing my PhD, I was trying to identify different forms of dementia very early on in the course, and I was using electrical brainwave recordings to do that, and I was failing miserably. It was a disaster, just no result after no result. And I used to go home to the doctor's residence with this sort of little igloo of journals that at the weekend I would sort of sit in and read, and which I'm now thinking, do I really want to admit this? Because it sounds like I had no social life, which I didn't, I was a social leper. But, and I started to realize that some parts of the brain were sleep related areas, and some dementias were eating away those sleep related areas. Other dementias would leave them untouched. And I thought, well, I'm doing this all wrong. I'm measuring my patients while they're awake. Instead, I should be measuring them while they're asleep. Started doing that, got some amazing results. And then I wanted to ask the question, is that sleep disruption that my patients are experiencing as they go into dementia, maybe it's not a symptom of the dementia. I wonder if it's a cause of the dementia. And at that point, which was, cough, cough, 20 years ago, no one could answer a very simple fundamental question. Why do we sleep? And I at the time didn't realize that some of the most brilliant minds in scientific history had tried to answer that question and failed. And at that point, I just thought, well, I'm going to go and do a couple of years of sleep research and I'll figure out why we sleep. And then I'll come back to my patients in this question of dementia. And as I said, that was 20 years ago. And what I realized is that hard questions care very little about who asks them. They will meter out their lessons of difficulty all the same. And I was schooled in the difficulty of the question, why do we sleep? But in truth, 20 years later, we've had to upend the question rather than saying, why do we sleep? And by the way, the answer then was that we sleep to cure sleepiness, which is like saying, we eat to cure hunger. That tells you nothing about the physiological benefits of food, same with sleep. Now we've actually have to ask the question, is there any physiological system in the body or any major operation of the mind that isn't wonderfully enhanced when we get sleep or demonstrably impaired when we don't get enough? And so far, for the most part, the answer seems to be no. So far, the answer seems to be no. So why does the body and the mind crave sleep? Crave sleep then? Why do we sleep? How can we begin to answer that question then? So I think one of the ways that I think about this or one of the answers that came to me is the following. The reason that we implode so quickly and so thoroughly with insufficient sleep is because human beings seem to be one of the few species that will deliberately deprive themselves of sleep for no apparent good reason, biological. And what that led me then to was the following. Mother nature as a consequence. So no other species does what we do in that context. There are a few species that do undergo sleep deprivation, but for very obvious, clear biological reasons. One is when they're in a condition of severe starvation. The second is when they're caring for their newborn. So for example, killer whales will often deprive themselves. The female will go away from the pod, give birth, and then bring the calf back. And during that time, the mother will undergo sleep deprivation. And then the third one is during migration when birds are flying trans oceanographic 2,000, 3,000 miles. But for the most part, it's never seen in the animal kingdom, which brings me back to the point, therefore mother nature in the course of evolution has never had to face the challenge of this thing called sleep deprivation. And therefore she has never created a safety net in place to circumnavigate this common influence. And there is a good example where we have, which is called the adipose cell, the fat cell. Because during our evolutionary past, we had famine and we had feast. And mother nature came up with a very clever recipe, which is how can I store caloric credit so that I can spend it when I go into debt? And the fat cell was born, brilliant idea. Where is the fat cell for sleep? Where is that sort of banking chip for sleep? And unfortunately we don't seem to have one because she's never had to face that challenge. So even if there's not some kind of physics, fundamental need for sleep that physiologically or psychologically, the fact is most organisms are built such that they need it. And then mother nature never built an extra mechanism for sleep deprivation. So it's interesting that why we sleep might not have a good answer, but we need to sleep to be healthy is nevertheless true. Yeah, and we have many answers right now. In some ways the question of why we sleep was the wrong question too. It's what are the plory potent many reasons we sleep? We don't just sleep for one reason because from an evolutionary perspective, it is the most idiotic thing that you could imagine. When you're sleeping, you're not finding a mate, you're not reproducing, you're not caring for your young, you're not foraging for food, and worse still, you're vulnerable to predation. So on any one of those grounds, especially as a collective, sleep should have been strongly selected against in the course of evolution. But in every species that we've studied carefully to date, sleep is present. Yeah, so it is important. So like you're right. I think I've heard arguments from an evolutionary biology perspective that sleep is actually advantageous, maybe like some kind of predator prey relationships. But you're saying, and it actually makes way more sense what you're saying is it should have been selected against. Like why close your eyes? Yeah, why? Because there was an energy conservation hypothesis for a while, which is that we need to essentially go into low battery mode, power down, because it's unsustainable. But in fact, that actually has been blasted out the water because sleep is an incredibly active process. In fact, the difference between you just lying on the couch but remaining conscious versus you lying on the couch and falling asleep, it's only a savings of about 140, 150 calories. In other words, you just go out and club another baby seal or whatever it was, and you wouldn't worry. So it has to be much more to it than energy conservation, much more to it than sharing ecosystem space and time, much more to it than simply predator prey relationships. If sleep really did, and looking back, even very old evolutionary organisms like earthworms, millions of years old, they have periods where they're active and periods where they're passively asleep. It's called lethargicus. And so what that in some ways suggested to me was sleep evolved with life itself on this planet, and then it has fought its way through heroically every step along the evolutionary pathway, which then leads to the sort of famous sleep statement from a researcher that if sleep doesn't serve an absolutely vital function or functions, then it's the biggest mistake the evolutionary process has ever made. And we've now realized Mother Nature didn't make a spectacular blender with sleep. You've mentioned the idea of conscious states. Do you think of sleep as a fundamentally different conscious state than awakeness? And how many conscious states are there so when you're into it, you're understanding of what the mind can do, do you think awake state, sleep state, or is there some kind of continuum? There's a complicated state transition diagram. Like how do you think about this whole space? I think about it as a state space diagram. And I think it's probably more of a continuum than we have believed it to be or suggested it to be. So we used to think absent of anesthesia that there were already three main states of consciousness. There was being awake, being in non rapid eye movement sleep or non dream sleep, and then being in rapid eye movement sleep or dream sleep. And those were the three states within which your brain could percolate and be conscious. Conscious during non REM sleep is maybe a stretch to say, but I still believe there is plenty of consciousness there. I don't believe that though anymore. And the reason is because we can have daydreams and we are in a very different wakeful state in those daydreams than we are when we are as we are now together present and extra septively focused rather than intra septively focused. And then we also know that as you are sort of progressing into those different stages of sleep during non REM sleep, you can also still dream, depends on your definition of dreaming, but we seem to have some degree of dreaming in almost all stages of sleep. We've also then found that when you are sleep deprived, there are even individual brain cells will fall asleep. Despite the animal being, you know, behaviorally from best we can tell awake, individual brain cells and clusters of brain cells will go into a sleep like state. And humans do this too. When we are sleep deprived, we have what are called microsleeps where the eyelid will partially close and the brain essentially falls lapses into a state of sleep, but behaviorally you seem to be awake. And the danger here is road traffic accidents. So these are the, what we call these sort of microsleep events at the wheel. Now, if you're traveling at 65 miles an hour in a two ton vehicle, you know, it takes probably around one second to drift from one lane to the next and it takes two seconds to go completely off the road. So if you have one of these microsleeps at the wheel, you know, it could be the last microsleep that you ever have. But I don't now see it as a set of, you know, very binary distinct, you know, step function state. It's not a one or a zero. I see it more of a, as a continuum. So I've for five, six years at MIT really focused on this human side of driving question. And one of the big concerns is the microsleeps, drowsiness, these kinds of ideas. And one of the open questions was, is it possible through computer vision to detect or any kind of sensors? The nice thing about computer vision is you don't have to have direct contact to the person. Is it possible to detect increases in drowsiness? Is it possible to detect these kinds of microsleeps or actually just sleep in general? Among other things, like distraction, these are all words that have so many meanings and so many debates, like attention is a whole nother one. Just because you're looking at something doesn't mean you're loading in the information. Just because you're looking away doesn't mean your peripheral vision can't pick up the important information. There's so many complicated vision science things there. So I wonder if you could say something to, they say the eyes are the windows to the soul. Do you think the eyes can reveal something about sleepiness through computer vision, just looking at the video of the face? And Andrew Huberman and I, your friend, have talked about this. I would love to work on this together. It's a fascinating problem. But drowsiness is a tricky one. So there's, what kind of information? There's blinking and there's eye movement. And those are the ones that can be picked up with computer vision. Do you think those are signals that could be used to say something about where we are in this continuum? Yeah, I do. And I think there are a number of other features too. I think, you know, aperture of eye. So in other words, partial closures, full closures, duration of those closures, duration of those partial closures of the eyelid. I think there may be some information in the pupil as well, because as we're transitioning between those states, there are changes in what's called the automatic nervous system, or technically it's called the autonomic nervous system, part of which will control your pupillary size. So I actually think that there is probably a wealth of information. When you combine that probably with aspects of steering, angle steering maneuver. And if you can sense the pressure on the pedals as well, my guess is that there is some combinatorial feature that creates a phenotype of, you are starting to fall asleep. And as the autonomous controls develop, that it's time for them to kick in. Some manufacturers, auto manufacturers sort of have something beta version, maybe an alpha version of this already starting to come online, where they have a little camera in the wheel that I think tries to look at some features. Almost everybody doing this and it's very alpha. So, you know, the thing that you currently have, some people have that in their car, there's a coffee cup or something that comes up that you might be sleepy. The primary signal that they're comfortable using is the steering wheel reversals. So basically using your interaction with the steering wheel and how much you're interacting with it as a sign of sleepiness. So if you have to constantly correct the car, that's a sign of like you starting to drift into microsleep. I think that's a very, very crude signal. It's probably a powerful one. There's a whole nother component to this, which is it seems like it's so driver and subject dependent. How our behavior changes as we get sleepy and drowsy seems to be different in complicated, fascinating ways where you can't just use one signal. It's kind of like what you're saying, there has to be a lot of different signals that you should then be able to combine. The hope is there's the searches for like universal signals that are pretty damn good for like 90% of people. But I don't think we need to take necessarily quite that approach. I think what we could do in some clever fashion is using the individual. So what you and I are perhaps suggesting here is that there is an array of features that we know provide information that is sensitive to whether or not you're falling asleep at the wheel. Some of those, let's say that there are 10 of them, for me, seven of them are the cardinal features. For you, however, you know, six of them and they're not all the same sort of overlapping are those for you. I think what we need is algorithms The third benefit, however, is that sleep, we've learned more recently is much more intelligent than we ever gave it credit for. Sleep doesn't simply just take individual memories and strengthen them. Sleep will then intelligently integrate and cross link and associate that information together. And it's almost like informational alchemy. So that you wake up the next morning with a revised mind wide web of associations. And that's probably the reason that, you know, you've never been told to stay awake on a problem. And in every language that I've inquired about that phrase or something very similar seems to exist, which means to me that this creative associative benefit of sleep transcends cultural boundaries. It is a common experience across humanity. Now I should note that I think the French translation of that is much closer to you. I think you sleep with a problem. Whereas the British, you sleep on a problem. The French, you sleep with a problem. I think it says so much about the romantic difference between the British and the French, but let's not go there. That's brilliant. So such a subtle, but such a fundamental difference. Yeah. Oh, goodness me. Sleep with the problem. Yes, exactly. That's why I love the French. So, and we can sort of double click on any one of these and go into detail, but the fourth, I became really enchanted by about eight years ago in our research, which was this idea of forgetting. And I started to think that forgetting may be the price that we pay for remembering. And in that sense, there is an enormous benefit to letting go. And you may be thinking, that sounds ridiculous. I don't want to forget. In fact, my biggest problem is I keep forgetting things, but the brain has a, well, we believe, has a finite storage capacity. We can't prove it yet, but my suspicion is that that's probably true. It doesn't have an infinite storage capacity. It has constraints. If that's the case, we can't simply go through life being constantly informational aggregators unless we are programmed to say, we've got a hard drive space of about 85 to 90 years and we're good and we can do that. Maybe that's true. I don't think that's true. I think forgetting is an incredibly good and useful thing. So for example, it's not beneficial from an evolutionary perspective for me to remember where I parked my car three years ago. So it's important that I can remember today's parking spot, but I don't want to have the junk kind of DNA from a memory perspective of where I parked my car two years ago. Now, I actually have in some ways a problem with forgetting, and again, I'm not trying to sort of be laudatory, but you know, I tend not to forget too many things. And I don't think that that's a good thing. And there's a wonderful neurologist, Luria, who wrote a book called The Mind of the Mnemonicist. And it was a brilliant book, both because it was written exquisitely, but he was studying these sort of memory savants who basically could remember everything that he gave them. And he tried to find a chink in their armor. And the first half of the book is essentially about him seeing how far he can push them before they fail. And he never found that place. He could never find a place where they stopped remembering. And then in his brilliance, he turned the question on its head. He said, not what is the benefit of constantly remembering, but instead, what is the detriment to never forgetting? And when you start to realize his descriptions of those individuals, it's probably a life that you would not want. But it's fascinating both from a human perspective, but also AI perspective. There's a big challenge in the machine learning community of how to build systems that are able to remember for prolonged periods of time, lifelong continuous learning. So where you build up information over time. So memory is one of the biggest open problems in AI and machine learning. But at the same time, the right way to formulate memory is actually forgetting because you have to be exceptionally selective at which kind of stuff you remember. And that's where the step of assimilation, integration that you're referring to is really important. I mean, we forget most of the things. And the question is exactly the cost of forgetting at the very edge of stuff that could be important or could not be, how do we remember or not those things? Like for example, doing a podcast, I've become cognizant of one feature of my forgetting that's been problematic, which is I forget names and titles of books and so on. So when I read, I remember ideas. I remember quotes, I remember statements and like that's the space in which I'm thinking. But when you communicate to others, you have to say this person in this book said that. So it's the same thing with like Andrew Huberman is masterful at this. This is important academia, remembering the authors of a paper and the title of the paper as part of remembering the idea. And I've been feeling the cost of not being able to naturally remember those things. And so that's something I need to sort of work on, but that's an example. Are you good with faces? Yes, very good at faces. But not good with names. So I am exactly like you. And there is an understanding of that in the brain too. We understand that there is partitioning of those in terms of the territory of the brain that takes care of faces and facts and places and that they can be separate. So I will never forget a face, but as I said, I usually forget very little, but for some reason, names are a struggle. I think in some ways, because I'm probably just a slightly anxious person. So when you first meet someone, which is usually the time when a name is introduced, you were saying you were sort of anxious maybe about sort of sitting down with me, but I find that a little bit activating. And so it's not as though there's anything wrong with my memory. It's just the emotional state I'm in when I'm first meeting someone. It's a little bit perturbing, but I will never forget the face. I completely relate to that because I almost don't hear people's names when they tell me because I'm so anxious. Yeah. But I think there's certain quirks of social interaction that show that you care about the person, that you remember that person, that they matter to you, that they had an impact on you. And one of the ways to show that is you remember their name. But that's a quirk to me because a lot of people I meet have a deep impact on me, but I can't communicate that unless I know their name, unless I know some of the details that we humans seem to use to communicate that we remember each other. What I remember well is the feeling we shared, is the experience we shared. What I don't remember well is the detailed labels of those experiences. And I need to certainly work on that. I don't know. I think it's just allowing yourself to be innate and who you are is also a beautiful thing too. I'm not suggesting it's not important to try and better oneself. But I also sometimes worry about the misery that that puts us in. But like you, I do struggle with name, but I know the first time when we met in the lobby, I know exactly what you look like. I know that you were wearing headphones. I know the shape and the size of those headphones. You didn't have your black jacket on. I know exactly what the weave of your shirt looked like and what your shoes look like. And I knew exactly the height of your, the end of your pants from the top of your shoes. And so those things I don't forget. And I can remember when people, I met people two years ago and I'll say, oh yes, we met there. And I remember you had those fantastic boots on. I thought they were pretty great pair of boots. And they're like, how do you, I didn't even remember what I was wearing that day. It's fascinating. Yeah, I'm the exact same way, but you can't, until we have Neuralink or something like that, we can't communicate that you remember all those things. I know, that's what I wanted. So you have to be able to use tricks of human communication for that. But so that, I mean, that's the, it's ultimately is a trick of like, which to remember, which to forget. And the forgetting is so, it's so fascinating to say this. I mean, it seems to be deeply connected to that assimilation process. So forgetting, you try to fit all the new stuff into this big web of the old stuff and the things that don't fit, you throw out. I think the assimilation, the way I've been thinking about it with sleep and it's particularly sort of dream sleep that we think can help with this assimilation is that during wake, we have one version of associative processing. And what I mean by that is we see the most obvious connections. So I think of wakefulness as a Google search gone right. Whereas I see dream sleep as doing something very different. I think dream sleep is a little bit like group therapy for memories that everyone gets a name badge and sleep gathers in all of the individual pieces of the day and it sort of starts to get you to forces you, in fact, to speak to the people, not at the front of the room that you think you've got the most obvious connection with, but to speak with the people all the way at the back of the room that at first you think, I've got no idea what's going on in the room. You think I've got no obvious connection with them at all. But once you get chatting with them, you learn that you do have a very distant, non obvious connection, but it's still a connection on the same. And it's almost as though you're doing a Google search where I input Lex Friedman and it doesn't take me to the first page of your home site. It takes me to page 20, which is about some like field hockey game in Utah. It turns out that there actually is a link. If I look at it, it's a distant, non obvious one. And to me, I find that exciting because when you fuse things together that shouldn't normally go together, but when they do, they cause marked advances in evolutionary fitness. It sounds like the biological basis of creativity. And that's exactly what I think dream sleep and the algorithm of dream sleep is designed to do. It's not a Boolean like system where you have the sort of assumptions of true and false. Maybe it's more fuzzy logic system. And I think REM sleep is a perfect environment within which we do, it's almost like memory pinball. You get the information that you've learned during the day and then you pull the lever back and you shoot it up into the attic of your brain, this cortex filled with all of your past historical knowledge. And you start to bounce it around and see where one of those things lights up and you build a new connection there and you build another one there too. You're developing schemas. And so in that way, I think you could argue, we dream, therefore we are. Yeah, so in terms of this line between learning and thinking through a new thing that seems to be deeply connected, there's this legendary engineer named Jim Keller who keeps yelling at me about this. He says it's very effective. He likes to, for difficult problems before bed, think about that difficult problem. We're not talking about like drama at work or all that kind of stuff. No, like a scientific for him engineering problem. He likes to like intensely think about it to prime his mind before sleep and then go to sleep. And then he finds that the next day, he's able to think much clearer and there's new ideas that come, but also just, I guess it's more well integrated. And sometimes during the process of like, he's able to like wake up and like see new insights. That's right. If he's deeply sort of aggressively thinking through a problem. And there's many scientific demonstrations of this. The Mendeleev with the periodic table of elements, he was trying for months to understand. I mean, talk about an ecumenical problem of epic proportions. Here's your question today. You have to understand how all of the known elements in the universe fit together in a logical way. Good luck, take care. It was non trivial at the time. And he would try and try, he was so obsessed with it. He created playing cards with all of the different elements on. And then he would go on these long train journeys around Europe and he would just sort of deal these cards in front of them and he would shuffle them, shuffling and shuffling. And he would just try to see if he could find what the answer was. And then, so the story goes, he fell asleep and he had a dream. And in that dream, all of these elements started to dance and play around and they snapped into a logical grid, atomic weights, et cetera, et cetera. And it wasn't his waking brain that solved the problem. It was his sleeping brain that solved the impenetrable problem that his waking brain could not. And there's been count, even in the arts and in music, some wonderful dreams, Frankenstein, Mary Shelley's epic Gothic novel came to her in a dream at Lord Byron's home. And then we've got, Paul McCartney. Yesterday, the song came to him in a dream. He was filming, gosh, what was the movie? I don't recall it. I should be shocked because I'm from Liverpool myself. And, but he was on Wimpole Street in London and filming. And he came up with that song, the melody in his sleep, not to be outdone by the Beatles. And by the way, Let It Be also came from a dream that McCartney had. People usually give it religious overtones. Mother Mary comes to me speaking words of wisdom, let it be. If you've ever asked who Mother Mary is, it's not the biblical content. It's his mother. It's Mary McCartney. And she came to him in a dream and gifted him the song. But the best story I've heard is not to be outdone by the Beatles. The Stones, Keith Richards, who I think once was suggested it. Who was it? It was a comedian who was saying that in an interview with Rolling Stone, Keith Richards suggested or inferred that young kids should not do drugs. And they said, well, look, young kids can't do drugs because you've done all of the drugs. And I always thought that, but Keith Richards described he would always go to bed with his guitar and a tape recorder. And then probably who would have a whole set of other things in the bed with him. And who knows how many other people, but anyway. And then he said in his autobiography, and I'm paraphrasing here, but one morning I woke up and I realized that the tape had recorded all the way to the end. So I rewound the tape and I hit play. And there in some kind of ghostly form were the opening chords to Satisfaction, the most famous successful Rolling Stone song of all time. Followed by then 43 minutes of snoring. That's awesome. That riff came to him. One of the most famous riffs in all of rock and roll came to him by way of a dream inspired insight. So I think there is too many of those anecdotes. And we've now got the side, I don't rely on anecdotes as science. We've now done the studies in the laboratory and we can reliably demonstrate that sleep inspires creativity, inspires problem solving capacity. Well, the interesting thing is, is it possible to some of the ideas that you talk about to turn them into a protocol that could be practiced rigorously? So what Jim Keller espouses is saying, not just the fact that sleep helps you increase the creativity, but turn it into a process. Like literally, like don't do it accidentally. Like an athlete does certain things to optimize their performance. They have a training routine. They have a regimen of like cycling and sprints and long distance stuff. In the same way, thinking about your job as an idea generator in the engineering space is like, this is good for my performance. So like for an hour before bed, think through a problem like every night and then use sleep to work through that problem. I mean, he's the first person that I heard like of the people I really respect that do like what I do, which is like programming engineering type work, like using sleep, not accidentally, but with a purpose, like using sleep. That's just basically the difference between, as you said, a passive approach to it versus an active deterministic or hope for a deterministic approach to it. In other words, that you are actually trying to harness the power of sleep in a deliberate way rather than an unthoughtful way. I still think that mother nature through it, the 3.6 million years of evolution has probably got it mostly figured out in terms of what information should be uploaded at night and worked through. I think her algorithm is probably pretty good at this stage. It's not to suggest though, that we can't try to tweak it and nudge it. It's a very light hand on the tiller is what he's doing. I don't think there's anything wrong with that. Just like, for example, for me, fasting has improved my ability to focus deeply and productivity significantly. And in that same way, it's possible that playing with these ideas of thinking before bed or some hours before bed or some playing with different protocols will have a significant leap over what mother nature naturally does. So if you let your body do what it naturally does, you may not achieve the same level of performance because mother nature has not designed us to think deeply about chip design or programming artificial intelligence systems. Well, she's gifted us the architecture and the capacity to do that. What we do with that is what life's experience dictates. She gives us the blueprint to do many. Well, if I were to sort of introspect and self analyze what mother nature wants me to do, I think given my current lifestyle that I have food in the fridge and a bed to sleep on, I think what mother nature wants me to do is to be lazy. And so I think I'm actually resisting mother nature because so many of my needs are satisfied. And so I have to resist some of the natural forces of the body and the mind when I do some of the things I do. So there's that dance, like I've been thinking about doing a startup and that's obviously going against everything that my body and mind are telling me to do because it's going to be basically suffering. But the only reason I want... As you know, it will be over. Yes, but nevertheless, there's some kind of inner drive that wants me to do it. And then you start to ask a question, well, how do you optimize the things you can't optimize like sleep, like diet, like the people that you surround yourself with in order to maximize happiness and performance and all those kinds of things without also over optimizing. And that's such an interesting idea from a engineer. So as you may know, you don't often get those kinds of ideas from engineers. Engineers usually just don't read books about sleeping. They're usually like the... They're not the healthiest of people. I think that's changing over time, especially with Silicon Valley, especially with the tech sector. People are starting to understand what's a healthy lifestyle, but usually they're kind of on the insane side, especially programmers. But it's nice to hear somebody like that use sleep and use some of the things that you talk about strategically on purpose. When I get to that idea of not just trying to use what Mother Nature gave, but seeing if you can do something more or different, in a conservative mindset, I would then pose the question at what cost? Because when you do something perhaps that deviates from the typical pre programmed, you know, Mother Nature's program, I suspect it usually comes at the cost of something else. So maybe he is able to direct and focus his sleeping cognition on those particular topics that will gain him better problematic resolution the next day when he wakes up. The question is though, at what cost of the other things that didn't make it onto the menu of the finger buffet of sleep that night? And is it that you don't process the emotional difficulties or events, and therefore you are less emotionally resolved the next day, but you are more problem resolved the following day. And so I always try to think, and I truly don't want to sound puritanical either about sleep, and I think I've come off that way many a times, especially when I started out in the public. The tone of the book, in some ways, I look back and think, could I have been a little softer? And the reason was I was that way back in when I started writing the book, which was probably something like 2014 or 15, sleep was the neglected stepsister in the health conversation of the day. And I was just so sad to see the amount of suffering and disease and sickness that was caused by insufficient sleep. And for years before I'd been doing public speaking, and I'd tell people about the great things that happen when you get sleep. People would say, that's fascinating. And then they would go back and keep doing the same thing about not sleeping enough. And then I realized you can't really speak about the good things that happen. It's like the news, what bleeds leads. And if you speak about the alarmingly bad things that happen, people tend to have a behavioral change. And so the book as a consequence, I think probably came out a little bit on the strong side of trying to convince people. Well, you were trying to help a lot of people and that's a powerful way to help a lot of people. I was genuinely trying to help people, but certainly for some people for whom sleep does not come easy, then it was probably a tricky book to read too. And I think I feel more sensitive to those people now and empathetically connected to them. So I think the, again, the point was simply that I don't mean to sound too puritanical in all of this. And the same way with caffeine and coffee. I am just a scientist and I am not here to tell anyone how to live their life. That is not my job at all. And life is to be lived to a degree and life is to be lived if you want to do a startup. All I want to do is empower people with the understanding of the science of sleep. And then you can make an informed choice as to how you want to live your life. And I offer no judgment on how anyone wishes to live their life. I just want to try and see if the information that I have about sleep would alternatively change how you would think about your life decisions. And if it doesn't, no problem. And if it does, I hope it's been of use. Well, maybe this is me trying to justify my lifestyle to you. But Dr. Seuss said, you know you're in love when you can't fall asleep because reality is finally better than your dreams. I love that quote too. Okay. My sleeping schedule is complicated and it has to do primarily with the fact that I love basically everything that I do. And that love takes a form that may not appear to be love from the external observer perspective. Cause it's often includes struggle. It often includes something that looks like stress even though it's not stress. It's like this excitement, it's this turmoil and chaos of passion, of struggling with a problem of being sad and down to the point even depressed of how difficult the problem is, the disappointment that the last few weeks and months have been a failure and self doubt, all that mix. But I love it. And a part of that is sometimes staying up all night working on a thing I'm really passionate about. And that means sleep schedules that are just like, you know, sometimes sleeping during the day, sometimes very often sleeping very little but taking naps that are like an hour, two hours and so on. That kind of weird chaos. And now I'll also try to give myself back up. I was trying to like research yesterday is anybody else productive, wild like this? And there's of course a lot of anecdotal evidence and some of it could be just narratives that people have told to the public when in reality they sleep way more. But there's a bunch of people that are famous for not sleeping much. So on the topic of naps, I read this a long time ago and I checked this, Churchill was big on big naps. And is actually just reading more about Winston Churchill's sleep schedule is very much like mine. So I basically wanna give myself the opportunity to at night to stay up all night if I want to. And a good nap is a big part of that in the late evening. Like I'll often, this destroys social life completely but I'll often take a nap in the late afternoon or the evening and that sets me if I want to stay up all night. And things like that, that I read that Nikola Tesla slept only two hours a night, Edison the same three hours but he actually did the polyphasic sleep like where it's just a bunch of naps. What can you say about this madness of love and passion of loving everything you do and the chaos of sleep that might result in? I love the Seuss quote and I've had that experience too. Like you, I adore what I do. If someone gave you enough money to live the rest of your life, got a roof above my head, rice and beans on the table and they said, you don't have to work anymore. I would do nothing different. I would do exactly, this sounds a little crass and I hope it doesn't sound this way but being a scientist is not what I do, it's who I am. And when that's the case, sleep, working out, showering and eating are the things that I do in between my love affair with sleep. I fell for sleep like a blind roofer. And it was a love affair that started 20 years ago and I remain utterly besotted today. It's the most beguiling thing in the world to me. And I could easily and I have, it's kept me up at night. When my mind is fizzing with experimental ideas or I think I've got a new hypothesis or theory, I will struggle with sleep. I really will, it doesn't come easy to me because my mind is just so on fire with those ideas. So I understand the struggle, but I couldn't advocate from a scientific perspective, the schedule because the science just doesn't, I would feel as though I'm doing you a disservice to say it's okay, that won't come with some blast radius, some health consequences. You can add Margaret Thatcher and Ronald Reagan to that list too. Both of them were very proud chest beaters of how little sleep that they get. Thatcher said four hours, Reagan something similar. And I, knowing the links that we now know between sleep and Alzheimer's disease, I've often wondered whether it was coincidental then that both of them died of the terrible disease of Alzheimer's meaning, maybe it doesn't get you by way of being popped out of the gene pool in a car accident because you had a microsleep at the wheel at age 32, or it doesn't get you at 42 with heart attack or even 52 with cancer or a stroke, maybe it gets you in your seventies. I think the elastic band of sleep deprivation can stretch only so far before it snaps and it ultimately seems to snap. Nicola Tesla, I think he died of a coronary thrombosis, I believe. And there was a wonderful study done out of Harvard where they took a group of people who had no signs of cardiovascular disease. And what they found is that when they track them for years afterwards, they were completely healthy to begin with. Those people who are getting less than six hours of sleep ended up having a 300% increased risk of developing calcification of the coronary artery, which is the major sort of corridor of life for your heart. When someone says, he died of a massive coronary, it's because of a blockade of the coronary artery. And Tesla passed away from a coronary thrombosis. We also know that insufficient sleep is linked to numerous mental health issues. We know that Churchill had a wicked battle with depression. Gosh, my goodness, he used to call it black dog that would come and visit him. And I think many of his paintings, he was exquisite painter, but some of them would depict his darkness with depression as well. Edison is interesting. People have argued that he would short sleep and he didn't put much value in sleep. Whether or not that's true, we don't know, but he was a habitual napper. You're right, during the day, I've got some great pictures of him on his inventor's bench taking a nap. And in fact, I believe he set up nap carts around his house so he could nap. But what we also know, a study, again, coming out of Harvard just a couple of months ago, demonstrated very clearly that polyphasic sleep is associated with worse physical outcomes, worse cognitive outcomes, and especially worse mood outcomes. So from that sense, sleeping like a baby is not perfect for adults. So there's a fascinating dance here of the mean and the extreme, like the average and the high performers. So I, this gets to like the meaning of life kind of discussion, but let's go that way. And also happiness. So when studying sleep and when studying anything like diet and exercise, I think you have to really get a lot more data about individuals to make conclusive statement. That's when people talk about like, is meat, red meat good for you or bad for you, right? It's just so often correlated with other life decisions when you choose to eat meat or not. My sense is that whatever life decisions you make, if they reduce stress and lead to happiness, that's also going to be a big boost that needs to be integrated into the plots in the science, right? So I'll give you an example of somebody who is unarguably seen as unhealthy. My friend, Mr. David Goggins. So he's clearly, obviously, almost on purpose destroying his body. He's destroying his body and to say that he's doing the wrong thing or the unhealthy thing feels like, feels wrong. But I'm not sure exactly in which way he feels wrong. One of the things I'm bothered by, and again, I apologize for the therapy sessions, a framework of this, but I'm bothered by the fact that a lot of people tell me or David that they're doing things wrong. A lot of people in my life, when they see me not sleep, they'll tell me to sleep more. Now they're correct, but one fundamental aspect that I'd like to complain about is not enough people, almost nobody, especially people that care for me, will come to me and say, you have a dream, work harder. It's like the healthy thing should be a component of a life well lived, but not everything. And I don't know what to do with that because you certainly don't want to espouse. And just like you said, when you were working in your book, there is a belief, sleep was a secondary citizen in the full spectrum of what's a healthy life. But at the same time, I'm bothered by in Silicon Valley and all these kinds of work environments that I get to work with, with engineers, is there's to me too much focus on work life balance. And what that usually starts meaning is like, yeah, yeah, of course, it's good to have a social life, it's good to have a family, it's good to eat well and sleep well, but we should also discover our passion. We should also give ourselves a chance to work our ass off towards a dream and make mistakes and take big risks that in the short term seem to sacrifice health. And I think to come back to how you started about David Goggins, who I've never met, but who I admire incredibly and have an immense reverence for the man. You said two things, is it wrong to do those things to yourself? And is it unhealthy to do those things to yourself? I disagree with the former and I agree with the latter. So from a health biological medicine perspective, sleeping in the way that you've described or that other people may be sleeping in terms of insufficient amounts, now to your point too about into individual differences, usually when I see a bar graph and a mean, I usually say, show me your variance. I want to see your variance. In other words, show me the distribution of that effect. How many people were below the mean? How many, is it all tightly clustered around this one thing? So it's a very robust effect or was this huge fan of effect where for some people there was no effect at all and other people there was a whopping effect and everything in between. So I don't discount into individual variability, but, and I will come back to those two points about, is it wrong and is it unhealthy in just a second? When it comes to sleep, we have found huge amounts of into individual differences in your response to a lack of sleep. But one of the fascinating things, so let's say that I take you and we're going to measure your attention, your emotion, your mood, your blood pressure, your blood sugar glucose regulation, your autonomic nervous system and your different gene expression. Let's say I'm just going to measure a whole kaleidoscope of different outcomes, brain and body. And I find that on our measure of cognition on your attentional ability to focus, you are very resilient. You just don't show any impairment at all even after being awake for 36 hours straight. Does that mean that you are resilient in all of those other domains as well? The answer is no, you're not. So you can be resilient in one, but very vulnerable in another. And we've not found anyone who isn't at least vulnerable in one of those domains, meaning that it's somewhat safe to say that not getting sufficient sleep will lead to some kind of impairment in any one given individual. It may not be the same impairment, but it's likely to be an impairment. But to come back to the question, I think it's wrong to tell anyone that it's wrong to do what they're doing, even if they are compromising their sleep, even if they're compromising their mental health. As long as they're not hurting anyone else, then I think the answer is that's that person's choice. Yeah, but that's that person's life. I'd like to push back further. So see, the way you kind of said it, yes, you're absolutely right. But I would like to say a stronger statement, which is you should let go of that judgment of somebody is wrong and allow yourself to be inspired by the great heights they have reached. So take yourself out of the seat of being a judger of what is healthy or not, and appreciate the greatness of a particular human. You watch the Olympics, the kind of things that some athletes do to reach the very heights. The Olympics are taking years off of their life. They suffer depression after the Olympics often. The physiology is disastrous. Everything, their personal life, there's their psychology, their physiology, everything, it's a giant mess. So the question is about life. Healthy now means longevity, quality of life over a prolonged period of time, optimum performance over a prolonged period of time. But to me, beauty is reaching great heights. And there's a dance there that sometimes reaching great heights requires sacrifice of health and not like a calculation where you sat down on a sheet of paper and say, I'm going to take seven years off my life for an Olympic gold medal. No, it requires more chaotic journey that doesn't do that kind of calculus. And I just want to kind of speak to the, in the culture that struggles of what is healthy and not, we want to be able to speak to what is healthy and at the same time be inspired by the great heights that humans reach no matter how healthy or unhealthy they live. Yeah, I agree with that. I think if that's a flag you're hoisting, I will definitely salute it because it really depends, what are you trying to optimize for in your life? And if you are, I think the only danger potentially with that mindset is that if you look at many of the studies of old age and end of life, most people say I never look back on my life and wish I worked harder. I wish instead I'd spent more time with family, friends and engaged in that aspect. Now I'm not saying though, coming back to your point, that that is the standard rubric for everyone. I don't believe it is too. And there are many things that you and I are both benefiting from today, even in the field of medicine, where people have sacrificed their own longevity for the quest of solving a particular medical problem. And they died quicker because of their commitment, because they wished to try and solve that problem in their pursuit of greatness scientifically. And I now benefit. Am I grateful that they did that? Incredibly grateful. You know, a simpler demonstration is this. If tonight at 4 a.m. in the morning, I have a ruptured appendix, I have an appendicitis, I am incredibly grateful that there is an emergency team that will take me to the hospital at 4 a.m. in the morning. They are awake, they're not sleeping and they save my life. And that's part of what their life's mission and quest is. And they saved another's life by, in some ways, shaving a little of their own off. So I don't take, I have no umbrage with that mentality at all. I think you just have to be very clear about what you're optimizing for. And my worry is that most people fall into the rat race and they never actually ask the question, why am I doing this? If you're just working nine to five or, and you allow that nine to five to stretch into much longer, but it's nevertheless a job that's kind of like wears you down. That's one thing. Another thing is when it is like, you're, it's a dream, it's a life mission. And for that, I think as long as you know what it is that you could be doing to yourself and you are comfortable and A okay with that, I have no problem with that at all. Again, as I said, as a scientist, I cannot, should not, and will not tell anyone what they should do with their life. All I want you to be able to do is say, okay, now I understand more about the, previously these would be known unknowns and these were the unknown unknowns. And now I am slightly more cognizant. I have more knowns than I had before regarding my sleep and my health, knowing that information, do I still choose to make this decision? And if that's what I offered, then I think I've done my job. That's all I want to offer is just added information into the decision algorithm. And what you end up choosing as an output of that algorithm has nothing to do with me. It's not my business and I will never judge anyone for it. And as I said, I'm immensely grateful for people who have sacrificed much in their lives to give me what I have. So you're saying as long as the sacrifice sort of grounded in knowledge of what the sacrifice is, that sleep is important, all those kinds of things. And that you're comfortable with it. That is, it is your conscious choice rather than feeling as though you're trapped or that you are just, you haven't thought about it. And you start that job at age 32 and then you wake up the next morning and you're 65 and you think, where did my life go? What was I doing? That to me, I would feel, I would want to hug you. And I would say, I'm just, and I'm not saying, I don't want to sound belittling here at all. I would just not wish that for you. I would wish that you could have thought about what it was that you're doing and not have that regret. Yeah, so I guess I'm, this is for you, the listener. I'm coming out of the closet here a little bit. The fact that I enjoy the madness I live in. So please do not criticize me, embrace me. I understand the sacrifices I'm making. I enjoy sleeping on the floor when I'm passionate programming all night and just pass out on the carpet. I love this life. Okay, so it's, but it's definitely something I think about that there's a balance, a strike where. I just want you to have as much of it though. Of life. See, quality of life is important. I should have said, I want you to have as much high quality life. And if high quality of life means I spend five decades on this planet, but yet in that time, I am thrilled every day. I'm turned on every day by what I do. And I reveled in this thing called my life's work. I think that that is a 50 year journey of absolute delight and fulfillment that you should take. I think about my death all the time. I meditate on death. I'm okay to die today. So to me, longevity is not a significant goal. I'm so happy to be alive. I don't even think it would suck to die today. I'm as afraid of it today as I will be in 50 years. I don't wanna die as much today as I will in 50 years. There's of course all these experiences I would like to have, but everything's already amazing. It's like that Lego movie. So I don't know. So to me, I just wanna keep doing this. And there's of course things that could affect, like you mentioned, dementia and these deterioration of the mind or the body that can significantly affect the quality of life. And so you want to do. As long as you're aware of that, and that's the price you pay for the entry into this magical kingdom that you are experiencing, which is a lovely thing. I feel privileged too. I can't believe the life that I live. It's incredible. And just like you, I think about mortality a great deal. I think a lot about death, but I don't worry about death. I probably, with the exception of the potential pain that comes before it, that some people, many people can suffer, that maybe concerns me. But I actually think about mortality as a tool, I use it as a lens through which I can then retrospect. And by placing myself at the point of future mortality, I can then use it as a retrospective lens to focus and ask the following question. Is there anything I feel I would regret and therefore change in the life that I currently have now? That's the way I meditate and use mortality as a question, is to try and course correct and focus my life. I worry not about dying, but I like to think about death as a way to prioritize my life. If that makes sense, I don't know if that makes sense. No, it makes total sense to decide how do you want to live today so that in the future you do not regret the way you've lived today. Right, and to place yourself in the future at your point of mortality is one way to, I think, as an exercise to retrospectively look back and not lose out on informed choices that you could otherwise lose out on if you weren't thinking about mortality. Yeah, it clarifies your thinking. So I mentioned I sleep on the floor, take naps and power naps, and it's just kind of madness. Is there weirdnesses to your own sleep schedule as a scientist that does incredible work, has a lot of things going on, has to lead research, has to write research, has to be a science communicator, also have a social life, all those kinds of things. Is there certain patterns to your own sleep that you regret or you participate in that you find you enjoy? Is there some personal stuff, quirks or things you're proud of that you do in terms of your sleep schedule? The funny thing about being a sleep researcher is that it doesn't make you immune to the ravages of difficult nights of sleep, and I have battled my own periods of insomnia in my life too. And I think I've been fortunate in ways because I know how sleep works and I know how to combat insomnia. I know how to get it under control because insomnia in many ways is a condition where all of a sudden your sleep controls you rather than you control your sleep. Wow, yeah, that's a beautiful way to put it, yeah. And I know when I'm starting to lose control and it's starting to take control, and I understand how to regain, but it doesn't happen overnight. It takes a long time. So you've struggled with insomnia in your life? I have, not all of my life. I would say I've probably had three or four really severe bouts, and all of them usually triggered by emotional circumstances, by stress. Stress that's connected to actual events in life or stress that's unexplainable? Well, externally triggered. Yeah, it's sort of what we would call reactive stress. And so that's sort of point number one about the idiosyncrasies. The point number two is that when you are having a difficult night of sleep, as a sleep researcher, you basically have become the Woody Allen neurotic of the sleep world. Because at that moment, I'm trying to fall asleep and I'm not, and I'm starting to think, okay, my dorsal lateral prefrontal cortex is not shutting down. My noradrenaline is not ramping down. My sympathetic nervous system is not giving way to my parasympathetic. At that point, you are dead in the water for the next two hours and nothing is bringing you back. So there is some irony in that too. I would say for myself though, if there is something I'm not proud of, it has been at times railing against my chronotype. So your chronotype is essentially, are you a morning type, evening type or somewhere in between? And there were times because society is desperately biased towards the morning types. This notion of the early bird catches the worm. Maybe that's true, but I'll also tell you that the second mouse gets the cheese. Yeah, so I think one of the issues around, firstly, people don't really understand chronotype because I'll have some people when I'm sort of out in the public, they'll say, look, I struggle with terrible insomnia. And I'll ask them, is it problems falling asleep or staying asleep? And they'll say, falling asleep. And then I'll say, look, if you are on a desert island with nothing to wake up for, no responsibilities, what time would you normally go to bed and what time would you wake up? And they would say, I'd probably like to go to bed about midnight and wake up maybe eight in the morning. And then I'd say, so what time do you now go to bed? And they'd say, well, I've got to be up for work early. So I get into bed at 10. I say, well, you don't have insomnia. You have a mismatch between your biological chronotype and your current sleep schedule. And when you align those two, and I was fighting that for some time too, I'm probably mostly right in the middle. I am desperately vanilla, unfortunately, in many aspects of life, but this included, I'm neither a strong morning type nor a strong evening type. So ideally I'd probably like to go to bed around 11, 10.30, 11, probably somewhere between 10.30, 11, and wake up, I naturally wake up usually most days before my alarm at 7.04, and it's 7.04 because why not be idiosyncratic in terms of setting an alarm? I love it. And so I... That's kind of awesome. I've never heard about that. That's amazing. I'm gonna start doing that now, setting alarms like a little bit off the... Yeah, I know. I'm never quite sure why we all... It's a celebration of uniqueness. Yeah, and I am quite the odd snowflake in that sense too. So I would usually then try to force myself because I had that same mentality that if I wasn't up at 6.30 and in the gym by seven that there was something wrong with me. And I quickly abandoned that. But if I look back, if there was a shameful act that I have around my sleep, I think it would be that for some years until I really started to get more detailed into sleep. And now I have no shame in telling people that I will probably usually wake up around 6.45 naturally, sometimes seven when people are looking at me thinking, you're a sloth, you're lazy. And I don't finish my daily workout until I'm not working until probably nine o clock in the morning thinking, what are you doing? Now I will work late into the day. If I could, I would work 16 hours. It's my passion just like yours. So I don't feel shame around that, but I have changed my mentality around that. It's complicated because I'm probably happiest going to bed, if I'm being honest, like at 5 a.m. That's fine. You're just an extreme evening type. But the problem is it's not that I'm ashamed for it. I actually kind of enjoy it because I get to sleep through all the nonsense of like the morning. Isn't that a beautiful thing? Like people are busy with their emails and I just am happy as a cow. And I wake up after all the drama has been resolved. And cows are happy and the drama has been resolved. Exactly. But in society you do, especially, I mean this is what I think about is when you work on a larger team, especially with companies, you are, everybody's awake at the same time. So that's definitely been a struggle to try to figure out, just like you said, how to balance that, how to fit into society and yet be optimal for your chronotype, you said. Yeah, you have to sleep in synchrony with it and harmony. Because normally what we know is that if you fight biology, you'll normally lose. And the way you know you've lost is through disease and sickness. You said you suffered through several bouts of insomnia. Is there, aside from embracing your chronotype, is there advice you can give how to overcome insomnia from your own experience? Right now the best method that we have is something called cognitive behavioral therapy for insomnia or CBTI for short. And you work with, for people who don't know what it is, you work with a therapist for maybe six weeks and you can do it online, by the way, I recommend probably jumping online, it's just the easiest. And it will change your beliefs, your habits, your behaviors and your general stress around this thing called sleep. And it is just as effective as sleeping pills in the short term. But what's great is that unlike sleeping pills, when you stop working with your therapist, those benefits last for years later. Whereas when you stop your sleeping pills, you typically have what's called rebound insomnia, where your sleep not only goes back to being as bad as it was before, it's usually even worse. For me, I think I found a number of things effective. that can firstly understand when you are well slept. So let's say that people have sleep trackers at night and then your car integrates that information and it understands when you are well slept. And then you've got the data of the individual behavior unique to that individual, snowflake like, when they are well slept. This is the signature of well rested driving. Then you can look at deviations from that and pattern match it with the sleep history of that individual. And then I don't need to find the sort of, you know, the one size fits all approach for 99% of the people. I can create a very bespoke tailor like set of features, a Savile Row suit of sleepiness features. You know, that would be my, if you want to ask me about moon shots and crazy ideas, that's where I go. But to start with, I think your approach is a great one. Let's find something that covers 99% of the people because the worrying thing about microsleeps of course, unlike, you know, drugs or alcohol, which you know, certainly is a terrible thing to be behind the wheel. With those often you react too late. And that's the reason you get into an accident. When you fall asleep behind the wheel, you don't react at all. You know, at that point, there is a two ton missile driving down the street and no one's in control. That's why those accidents can often be more dangerous. Yeah, and the fascinating thing is, in the case of semi autonomous vehicles, like Tesla autopilot, this is where I've had disagreements with Mr. Elon Musk, and the human factors community, which is this community that one of the big things they study is human supervision over automation. So you have like pilots, you know, supervising an airplane that's mostly flying autonomously. The question is, when we're actually doing the driving, how do microsleeps or general, how does drowsiness progress and how does it affect our driving? That question becomes more fascinating, more complicated when your task is not driving, but supervising the driving. So your task is to take over when stuff goes wrong. And that is complicated, but the basic conclusions from many decades is that humans are really crappy at supervising because they get drowsy and lose vigilance much, much faster. The really surprising thing with Tesla autopilot, it was surprising to me, surprising to the human factors community, and in fact, they still argue with me about it, is it seems that humans in Teslas with autopilot and other similar systems are not becoming less vigilant, at least with the studies we've done. So there's something about the urgency of driving. I can't, I'm not sure why, but there's something about the risk, I think the fact that you might die is still keeping people awake. The question is, as Tesla autopilot or similar systems get better and better and better, how does that affect increasing drowsiness? And that's when you need to have, that's where the big disagreement was, you need to have driver sensing, meaning driver facing camera that tracks some kind of information about the face that can tell you drowsiness. So you can tell the car if you're drowsy so that the car can be like, you should be probably driving or pull to the side. Right, or I need to do some of the heavy lifting here. Yeah, so there needs to be that dance of interaction of a human and machine, but currently it's mostly steering wheel based. So this idea that your hands should be on the steering wheel, that's a sign that you're paying attention is an outdated and a very crude metric. I agree, yeah. I think there are far more sophisticated ways that we can solve that problem if we invest. Can I ask you a big philosophical question before we get into fun details? On the topic of conscious states, how fundamental do you think is consciousness to the human mind? I ask this from almost like a robotics perspective. So in your study of sleep, do you think the hard question of consciousness that it feels like something to be us, is that like a nice little feature, like a quirk of our mind, or is it somehow fundamental? Because sleep feels like we take a step out of that consciousness a little bit. So from all your study of sleep, do you think consciousness is like deeply part of who we are or is it just a nice trick? I think it's a deeply embedded feature that I can imagine has a whole panoply of biological benefits. But to your point about sleep, what is interesting if you do a lot of dream research and we've done some, it's very, very rare at all, in fact, for you to end up becoming someone other than who you are in your dreams. Now you can have third person perspective dreams where you can see yourself in the dream as if you're sort of, you've risen above your physical being. But for the most part, it's very rare that we lose our sense of conscious self. And maybe I'm sort of doing a sleight of hand because it's really what I'm saying, it's very rare that we lose our sense of who we are in dreams. We never do. Now that's not to suggest that dreams aren't utterly bizarre. And I mean, when you slept last night, which I know may have been perhaps a little less than me, but when you went into dreaming, you became flagrantly psychotic. And there are five essentially good reasons. Firstly, you started to see things which were not there, so you were hallucinating. Second, you believe things that couldn't possibly be true, so you were delusional. Third, you became confused about time and place and person, so you're suffering from what we would call disorientation. Fourth, you have wildly fluctuating emotions, something that psychiatrists will call being affectively labile. And then how wonderful, you woke up this morning and you forgot most if not all of that dream experience, so you're suffering from amnesia. If you were to experience any one of those five things while you're awake, you would probably be seeking psychological help. But so I place that as a backdrop against your astute question, because despite all of that psychosis, there is still a present self nested at the heart of it, meaning that I think it's very difficult for us to abandon our conscious sense of self. And if it's that hard, the old adage in some ways, that you can't outrun your shadow. But here it's more of a philosophical question, which is about the conscious mind and what the state of consciousness actually means in a human being. So I think that that to me, you become so dislocated from so many other rational ways of waking consciousness. But one thing that won't go away, that won't get perturbed or sort of, you know, manacled, is this your sense of conscious self? Yeah, that's a strong sign that consciousness is fundamental to the human mind. Or we're just creatures of habit who gotten used to having consciousness. Maybe it just takes a lot of either chemical substances or a lot of like mental work to escape that. I mean, it's like trying to launch a rocket. You know, the energy that has to be put in to create escape velocity from the gravitational pull of this thing called planet earth is immense. Well, the same thing is true for us to abandon our sense of conscious self. The amount of biological, the amount of substances, the amount of wacky stuff that you have to do to truly get escape velocity from your conscious self. What does that tell us about then the fundamental state of our conscious self? Yeah, it also probably says that it's quite useful to have consciousness for survival and for just operation in this world. And perhaps for intelligence. I'm one of the, on the AI side, people that think that intelligence requires consciousness. So like high levels of general intelligence requires consciousness. Most people in the AI field think like consciousness and intelligence are fundamentally different. You could build a computer that's super intelligent. It doesn't have to be conscious. I think that if you define super intelligence by being good at chess, yes. But if you define super intelligence as being able to operate in this living world of humans and be able to perform all kinds of different tasks, consciousness, it seems to be somehow fundamental to richly integrate yourself into the human experience, into society. It feels like you have to be a conscious being. But then we don't even know what consciousness is and we certainly don't know how to engineer it in our machines. I love the fact that there are still questions The first is that I had to really address what was stressful and try to come up with some degree of meaningful rationality around it. Because I think one of the things that happens, there's something very, talking about conscious states, to come all the way back to, gosh, I don't know, I feel like we've only been chatting for like 20 minutes, but you're gonna tell me it's been a while. Yeah, it's been a while. Okay, I'm desperately, I feel terribly sorry. But let's come back to conscious states, which is where we started. There is something very strange about the night that thoughts and anxieties are not the same as they are in the waking day. They are worse, they are bigger. And I at least find that I am far more likely to catastrophize and ruminate at night about things that when I wake up the next day in the broad light of day, I think it's nowhere near that bad, man. What were you doing? It's not that bad at all. So to gain firstly, some rational understanding of my emotional state that's causing that insomnia was very helpful. The second thing was to keep regularity, just going to bed at the same time waking up. And here's an unconventional piece of sleep advice. After a bad night of sleep, do nothing. Don't wake up any later, don't go to bed any earlier, don't nap during the day, and don't drink any more coffee than you would otherwise. Because if you end up sleeping later into the morning, you're then not going to be tired at your normal time at night. So then you're gonna get into bed thinking, well, I had a terrible night of sleep last night. And yes, I slept in this morning to try and compensate, but I'm still gonna get to bed at my normal time. But now you get into bed and you haven't been awake for as long as you normally would. So you're not as sleepy as you normally would be. And so now you sit there lying in bed and it's another bad night. And the same thing is, if you go to bed any earlier, so don't wake up any later, wake up at the same time, don't go to bed any earlier, because then you're just probably your chronotype, your biological rhythm doesn't want you to be asleep. And you think, well, it's a terrible night, I'm gonna get into bed at 9 p.m. rather than my standard 10, I'm just gonna be lying in bed awake for that hour. Naps will take our double edged sword, they can have wonderful benefits. And we've done lots of studies on naps for both the brain and the body. But they are a double edged sword in the sense that napping will just take the edge off your sleepiness. It's a little bit like a valve on a pressure cooker. When you nap during the day, you can take some of that healthy sleepiness that you've been building up during the day. And for some people, not all people, but for some people that can then make it harder for them to fall asleep at night and then stay asleep soundly across the night. So the advice would be, if you're struggling with sleep at night, don't nap during the day. But if you are not struggling with sleep, and you can nap regularly, naps are just fine. And we can play around with optimal durations depending on what you want. Just try not to nap too late into the day because napping late into the day is like snacking before your main meal. It just takes the edge off your sleep hunger as it were. But that would be, so that's my unconventional second piece of advice regarding insomnia. The third is meditation. I found meditation to be incredibly powerful. I started reading about meditation as I was researching that aspect of the book many years ago. And as a hard nose scientist, I thought this sounds very woo woo. This is sort of, we all hold hands and sing come by hour and everything's going to be fine with sleep. I read the data and it was compelling. I couldn't ignore it. And I started meditating and that was six years ago and I haven't stopped. And I find meditation before bed incredibly powerful. The meditation app companies were perplexed at this at first. They want people to meditate during the day. But when they looked at their usage statistics, they found that they would have people in the morning meditating. And then there's a huge number of people using the meditation app in the evening. What they were doing was self medicating their insomnia. And they finally, rather than railing against it, they started to see it as a cash cow, rightly so. So I found meditation to be helpful. Having a wind down routine is the other thing that's critical for me. I can't just go from, because when my mind is switched on and I think you may be like this too, if I get into bed, that Rolodex of thoughts and information and excitement and anxiety and worry is just whirling away. And it's not gonna be a good night for me. So I have to find a wind down routine. And that makes sense when you realize what sleep is like. Sleep is not like a light switch. Sleep is much more like trying to land a plane. You know, it takes time to descend down onto the terra firma that we call sound sleep at night. And we have this for kids. You know, I don't have children, but you know, a lot of parents will say, you know, we have to have the bedroom, sorry, the bedtime routine. You know, you bathe the kid, you put them in bed, you read them a story. You have to go through this routine, this wind down routine for them. And then they fall asleep wonderfully. Why do we abandon that? As adults, we need that same wind down routine. So that's been the other thing that's been very helpful to me. So don't do anything different. If you have a bad night of sleep, keep doing the same thing. Manage your anxiety, understand it, rationalize it. Then meditation, and then finally having some kind of disengagement wind down routine. Those are the four things that have been very helpful to me. That's brilliant. So the regularities really do a lot of work against insomnia. Is there, is it possible to have a healthy sleep life without the regularities? I say that because I'm all over the place and I've gotten good at being all over the place. So I'll often, like what happens, I'll go stretches of time. There'll be sometimes a month where I, my days are like, this is embarrassing to admit, but they're like, just you and I here, just you and I. It's like 28 hours or 30 hour days. Like I'll just go all the way around comfortably and happily, I love it. And then there'll be a nap. I mean, if you like add up the hours when I'm just like sleeping as much as I want, it'd probably be like six hour average per 24 hours. Like that kind of, so it works out nicely, maybe even seven hours, I don't know. But that it's obviously irregular and there's chaos in the whole thing. Like sometimes it's shorter sleep, sometimes it's longer. Is that totally not a good thing, do you think? The best evidence that we have to speak to this question is people who are doing rotating shifts. And unfortunately the news is not good. They usually have a higher instance of many diseases such as depression, diabetes, cardiovascular disease, obesity, stroke. And again, that's just me communicating the data that we have and I'm not telling you that you should do anything different. The other thing is that there's nothing in your biology that suggests that that's how your body was designed to sleep. It is a system that loves habit. You know, if your circadian clock in your brain, it's called the suprachiasmatic nucleus, sits in the middle of your brain, had a personality trait, it would be a creature of habit. It loves habit. That's how your biology is designed to work is through very archetypal prototypical expected cycles. And when we do something different to that, then you start to see some of the pressure stress fractures in the system. But again, to your point, if that's something that you don't mind, you know, adopting and understanding and then I think you should keep doing what you're doing. Yeah, it's complicated. Of course you have to be a student of your own body and explore it. One of the reasons I want to have kids is kids enforce a stricter schedule. I think I definitely feel that I'm not living the sort of data wise, scientifically speaking, the optimal life. And me just living the way I want to live day to day is perhaps not the optimal way. And there's certain things that I've seen very successful people that I know in my life when they get, when they have kids, they actually, the productivity goes up, they get their shit together. There's a lot of aspects that, yeah, the regularity. I mean, that creatures a habit. That's the thing that's power. And then you start to optimally use the hours that you have in the day. Let me ask you about that. Well, actually, I just have one quick point on that too. You know, we often think about sleep as a cost, but instead I think of sleep as an investment. And the reason is because your effectiveness and your efficiency when you're well slept typically exceeds that when you're not. And to me, it's the idea of if I'm going to boil a pot of water, why would I boil it on medium when I could boil it in half the time on high? And I sometimes worry that when I speak to Fortune 500 companies and they're of this mentality of longer hours, getting people to rise and grind, the first point is that after about 20 hours of being awake, a human being is as cognitively as impaired as they would be if they were legally drunk. And the reason I bring that point up is because I don't know any company or CEO who would say, I've got this great team, they're drunk all the time. But we often lord the airport warrior who's flown through three different time zones in the past two days, is on email at 2 a.m. and then is in the office at six. And I think there is some aspect, not in all people, but there is sort of some aspect of that slight sleep machismo. And that's not what you are very different. You are driven by a purity of passion and a very authentic, incredibly genuine goal of wanting to do something remarkable with your life. That's not the issue I think I'm speaking about. It's just simply that I think maybe this notion of wanting to be awake for longer to try and get more done can sometimes be at odds with the fact that you can actually get so much more done if you're well slept. And it's this trade off. I actually admire people that take the big risk and work hard, whether that means staying up late at night, all those kinds of things, but it cannot be in the framework, in the context like what Edison said, which is sleep feels like a waste of time. So if you're not sleeping because you think sleep is stupid, that's totally wrong. But if you're not sleeping because you're deeply passionate about something, that to me, it's a gray area, of course, but that to me is much more admirable. And everything you're espousing is saying whatever the hell you're doing, you better be aware that sleep, long term and short term is really good for you. So if you're not sleeping, you're sacrificing, just make sure you're sacrificing for the right thing. I see vodka and getting drunk the same way. I know it's not good for me. I know I'm not gonna feel good days after. I know it's gonna decrease my performance. And there's nothing positive about it, except it introduces chaos in my life that introduces beautiful experiences that I would not otherwise have. It creates this turmoil of social interaction that ultimately makes me happy that I've experienced them in the moment and later the stories, you get to meet new people. It's like alcohol in this society is an incredible facilitator of that. So that's a good example of not sleeping and drinking way too much vodka. Again, it's this notion of life is to be lived to a degree. But if you do have children, I think one of the other things that then maybe comes into the picture is the fact that now there are other people that you have to live for than yourself. Yeah, but come on, like once they're old enough, like if you can't defend for yourself, you're too weak, get stronger. It's gonna be that kind of fatherhood. I got it, I'm understanding so much more about Lex Freeman than I did before. That's why you have to have for me, that would be my wife would be probably softer. It's good cop, bad cop, because I think I'm. But of course, actually, because I don't have kids, I've seen some tough dudes when they have kids become like the softies. They become like, they do everything for their kids. It's become like, it's totally transforms their life. I mean, Joe Rogan is an example of that. I just seen so many tough guys completely become changed by having kids, which is fascinating to watch because it just shows you how meaningful having kids is for a lot of people. Although I would say having chatted with Joe for some time, I think he is a delightful, sweetheart, independent of children. I think, don't get me wrong, I don't wanna be in a ring with him. He would face me five ways till Tuesday, but I think he's a desperately sweet man and a very, very smart individual. Yeah, I mean, but he talks about the compassion he's gained from realizing just watching kids grow up that we were all kids at some point, you get a new perspective. I think just like me, I still get this with him. He's super competitive and there's a certain way to approach life. You're striving to do great things and you're competitive against others and that intensity of that aggression, that can lack compassion sometimes and empathy. And when you have children, you get a sense like, oh, everybody was a child at some point, everybody was a kid. And you see that whole development process. It can definitely enrich, expand your ability to be empathetic. Let me ask about diet. So what's the connection between diet and sleep? So I do intermittent fasting, sometimes only one meal a day, sometimes no meals a day. Is there a good science on the interaction between fasting and sleep? We have some data, I would prefer more, but we have data both on time restricted eating and then we have some data on fasting to a degree. On time restricted eating, I think that it has some benefits, although the human replication studies have actually not borne out quite the same health benefit extent that the animal studies have. There've been some disappointing studies, one here close to where we are right now at UCSF recently. So I think time restricted eating can be a good thing and there are many benefits of time restricted eating. Is sleep one of them? No, it doesn't seem to be because there are probably at the time that we're recording this, three pretty decent studies that I'm aware of. Two out of the three were in obese individuals, one out of the three were in healthy weight individuals. And what they found is that time restricted eating in all three of those studies didn't have any advantageous benefit to sleep. It didn't necessarily harm sleep, but it didn't seem to improve it. When it comes to fasting though, which is a different state, we don't have too many studies, experimental studies with longterm fasting. The best data that we have is probably from religious practices and probably the most data we have is during Ramadan where people will fast for 29 to 30 days from sunrise to sunset. And under those conditions, there are probably five distinct changes that we've seen. None of them seem to be particularly good for sleep. The first is that the amount of melatonin that you release, and melatonin is a hormone. It's often called the hormone of darkness or the vampire hormone, not because it makes you look longingly at people's necklines, but it's just because it comes out at night. Melatonin signals to your brain and your body that it's dark, it's nighttime, and it's time to sleep. Those individuals, when they were undergoing that regimen of fasting, the amount of melatonin that was released and when it was released, the amount of melatonin decreased and when it was released came later. That was the first thing. The second thing was that they ended up finding it harder to fall asleep as quickly as they normally would otherwise. The third thing was that the total amount of sleep that they were getting decreased. The fourth fascinating thing was that a wake promoting chemical called orexin increased. And this is why a lot of people will say, when I'm fasting, it feels like I can stay awake for longer and I'm more alert, I'm more active. And I'll come back from an evolutionary perspective why we understand that to be the case. And then the fourth factor is that fasting didn't decrease the amount of deep sleep that seemed to be unaffected. It did, however, decrease the amount of REM sleep or dream sleep. And we know that REM sleep dreaming is essential for emotional first aid, mental health, it's critical for memory, creativity. It's also critical for several hormone functions. It's when there's direct correlations between testosterone release peaks just before you go into REM sleep and during REM sleep too. So REM sleep is critical. But so those are the five changes that we've seen. None of them seem to be that advantageous for sleep. But the fourth point that I mentioned, which was orexin, which is this wake promoting chemical and a good demonstration or a very sad demonstration of its power is when it becomes very deficient in the brain and it leads to a condition called narcolepsy where you're just unpredictable with your sleep. So orexin when it's in high concentrations keeps you awake when you lose it. It can put you very much into a state of narcolepsy where you're sleeping a lot of the time in unpredictable sleep. Why on earth when you are fasting would the brain release awake promoting chemical? And our answer is right now is the following. One of the few times that I mentioned before that we see animals undergoing insufficient sleep or prolonged sleep deprivation is under conditions of starvation. And that is an extreme evolutionary pressure. And at that point, the brain will forgo some. It won't forgo all, but it will forgo some of its sleep. And the reason is so that it can stay awake for longer because the sign of starvation is saying to the brain, you can't find food in your normal foraging perimeter, you need to stay awake for longer so you can travel outside of your perimeter for a further distance and maybe you will find food and save the organism. So in other words, when we fast, it's giving our brain this evolutionary signal that you are under conditions of starvation. So the brain responds by saying, oh my goodness, I need to release the chemical that helps the organism stay awake for longer which is orexin. So that they can forage for more food. Now, of course, your brain from an evolutionary perspective doesn't know about this thing called Safeway that you could easily go to and break the fast. But that's how we understand fasting. And I think my dear friend, Peter Attia has done a lot of work in this area too. I think fasting and David Sinclair's brilliant work, goodness me, what an individual too. The work is pretty clear there that time restricted eating and fasting have wonderful health benefits. Fasting creates this thing called hormesis, just like exercise and low level stress and sauna, heat, shock. And hormesis is a biological process I think as David Sinclair has once said, in simple layman's terms is, what doesn't kill you makes you stronger. And I think there is certainly good data that fasting and time restricted eating has many benefits. Is sleep one of them? It doesn't seem to be, it doesn't seem to enhance sleep. But it's interesting to understand its effects on sleep. I've fasted, it's a study of NF2. I once fasted 72 hours and another time 48 hours. And I found that I got much less sleep and it was very restful though. I hesitate to say this, but this is how I felt, which is I needed less sleep. I wonder if my brain is deceiving me because it feels like I'm getting a whole extra amount of focus for free. And I wonder if there's longterm impacts of that. Because if I fast 24 hours, get the same amount of calories, one meal a day, there's a little bit of discomfort. Like just maybe your body gets a little bit colder. Maybe there's just, I mean, hunger. But the amount of focus is crazy. And so I wonder, it's like, I'm a little suspicious of that. I feel like I'm getting something for free. I'm the same way with sweetener, like a Splendor or something. It's like, it's gotta be really bad for you, right? Because why is it so tasty, right? And I think, yeah, as we said before with biology, if there's a gain, there's often a cost too. But we at least understand the biological basis of what you're describing. It's not that you actually don't need less sleep. It's that this chemical is present that forces you more awake. And so subjectively you feel as though I don't need as much sleep because I'm wide awake. And those two things are quite different. It's not as though your sleep need has decreased. It's that your brain has hit the overdrive switch, the overboost switch to say, we need to keep you awake because food is in short supply. So you mentioned during sleep, there's a simulation, all those kinds of things for learning purposes, but there's also these, you mentioned the five ways in which we become psychotic in dreams. What do you think dreams are about? Why do you think we dream? What place do we go to when we dream? And why are they useful? Not just the assimilation aspect, but just like all the crazy visuals that we get with dreams. Is there something you can speak to that's actually useful? Like why we have such fun experiences in that dream world? So one of the camps in the sleep field is that dreams are meaningless, that they are an epiphenomenal byproduct of this thing called REM sleep from which dreams come from as a physiological state. So the analogy would be, let's think of a light bulb, that the reason that you create the apparatus of a light bulb is to produce this thing called light in the same way that we've evolved to this thing called REM sleep to serve whatever functions REM sleep serves. But it turns out that when you create light in that way, you also produce something called heat. It was never the reason that you designed the light bulb, it's just what happens when you create light in that way. And the belief so too was that dreaming was essentially the heat of the light bulb. That REM sleep is critical, but when you have REM sleep with a complex brain like ours, you also produce this conscious epiphenomenon called dreaming. I don't believe that for a second. And from a simple perspective is that I suspect that dreaming is more metabolically costly as a conscious experience than not dreaming. So you could still have REM sleep, but absent the conscious experience of dreaming was probably less metabolically costly. And whenever mother nature burns the energy unit called ATP, which is the most valuable thing, there's usually a reason for it. So if it's more energetically demanding, then I suspect that there is a function to it. And we've now since discovered that dreams have a function. The first, as we mentioned, creativity. The second is that dreams provide a form of overnight therapy. Dreaming is a form of emotional first aid. And it's during dream sleep at night that we take these difficult, painful experiences that we've had during the day, sometimes traumatic, and dream sleep acts almost like a nocturnal soothing balm. And it sort of just takes the sharp edges off those difficult, painful experiences so that you come back the next day and you feel better about them. And so I think in that sense, dreaming, it's not time that heals all wounds. It's time during dream sleep that provides emotional convalescence. So dreaming is almost a form of emotional windscreen wipers. And I think, and by the way, it's not just that you dream. It's what you dream about that also matters. So for example, scientists have done studies with learning and memory where they have people learn a virtual maze. And what they discovered was that those people who then dreamed, but dreamed of the maze were the only ones who, when they woke up, ended up being better at navigating the maze. Whereas those people who dreamed, but didn't dream about the maze itself, they were no better at navigating the maze. So it's not just that you, it's not sort of necessary, but not sufficient. It's necessary that you dream, but it's not sufficient to produce the benefit. You have to be dreaming about certain things itself. And the same is true for mental health. What we've discovered is that people who are going through a very difficult experience, a trauma, for example, a very painful divorce, those people who are dreaming, but dreaming of that difficult event itself, they go on to gain resolution to their clinical depression one year later. Whereas people who were dreaming just as much, but not dreaming about the trauma itself, did not go on to gain as much clinical resolution to their depression. So it's, I think to me, those are the lines of evidence that tell me dreaming is not epiphenomenal. And it's not just about the act of dreaming, it's about the content of the dreams, not just the fact of a dream itself. It's, first of all, it's fascinating. It makes a lot of sense, but then immediately takes my mind to, from an engineering perspective, how that could be useful in, for example, AI systems of, if you think about dreaming as an important part about learning and cognition and filtering previous memories of what's important, integrating them. You know, maybe you can correct me, but I see dreaming as a kind of simulation of worlds that are not constrained by physics. So like you get a chance to take some of your memories, some of your thoughts, some of your anxieties, and play with them, like construct virtual worlds and see how it evolves. Like to play with those worlds in a safe environment of your mind, safe in quotes, because you could probably get into a lot of trouble with the places your mind will go. But this definitely is applied in much cruder ways in artificial intelligence. So one context in which this is applied is the process called self play, which is a reinforcement learning where agents play against itself or versions of itself. And it's all simulated of trying different versions of themselves and playing against each other to see what ends up being a good. The ultimate goal is to learn a function that represents what is good and what is not good in terms of how you should act in the world. You create a set of decision weights based on experience, and you constantly update those weights based on ongoing learning. But the experience is artificially created versus actual real data. So it's a crude approximation of what dreams are, which is you're hallucinating a lot of things to see which things are actually. No, I think it's been a theory that's been put forward, which is that dreaming is a virtual reality test space that is largely consequence free. What an incredible gift to give a conscious mind to each and every night. Now the conscious mind, the human mind is very good at constructing dreams that are nevertheless useful for you. Like they're wild and crazy, but they're such that they are still grounded in reality to a degree where anything you learn in dreams might be useful in reality. This is a very difficult thing to do because it requires a lot of intelligence, it requires consciousness. This has been effectively recently being used in a self supervised learning for computer vision with the process of what's called data augmentation. That's a very crude version of dreams, which is you take data and you mess with it and you start to learn how a picture of a cat truly represents a cat by messing with it in different ways. Now the crude methods currently are cropping, rotating, distorting, all that kind of stuff. But you can imagine much more complicated generative processes that start hallucinating different cats in order for you to understand deeply of what it means for something to look like a cat. What is the prototype of a archetype of a cat? Yeah, the archetype. I mean, that's a very difficult process for computer vision to go from what are the pixels that are usually associated with a cat to like, what is a cat in the visual space? In the three dimensional visual spaces projected on an image, on a two dimensional image, what is a cat? Those are like fundamentally philosophical questions that we humans don't know the answer to, like linguistically. But when we look at a picture of a cat and a dog, we can usually tell pretty damn well what's the difference. And I don't know what that is because you can't reduce that to pointy ears or non pointy ears, furry or not furry, something about the eyes. It's been a long standing issue in cognitive science, cognitive neuroscience too, is how does the brain create an archetype? How does it create schemas that have general applicability, but yet still obtain specificity? That's a very difficult challenge. I mean, we can do it, we do it. It's rather bloody amazing. And it seems like part of the toolbox is this controlled hallucination, which is dreams. Well, it's a relaxing of the rigid constraints. I often think of dreaming as, it's from an information processing standpoint, the prison guards are away and the prisoners are running a mock in a delightful way. And part of the reason is because when you go into dream sleep, the rational part of your brain called the prefrontal cortex, which is the part, it's like the CEO of the brain. It's very good at making high level, rational, top down decisions and controlled actions. That part of the brain is shut down during REM sleep. But then emotional centers, memory centers, visual centers, motoric centers, all of those centers actually become more active. In fact, some of them are more active than when we're awake in the dream state. That's fascinating. So your brain from a neural architecture perspective is radically different. Its network feature is not the same as wakefulness. And I think this is an immensely beneficial thing that we have at least two different rational and irrational conscious states that we do information processing in. The rational, the veritical, the page one of the Google search is wakefulness. The more irrational, illogical, hyper associative Google page 20 is the REM sleep. Both I think are critical, both are necessary. That's fascinating. And again, fascinating to see how that could be integrated in the machines to help them learn better and to reason better. And in some ways we also know it from a chemical perspective too. When you go into dream sleep, it is a neurochemical cocktail like no other that we see at the rest of the 24 hour state. There is a chemical called noradrenaline or norepinephrine in the brain. And you know of its sister chemical in the body called adrenaline. But upstairs in the brain, noradrenaline is very good at creating a very hyper focused, attentive, narrow, it's sort of very convergent way of thinking to a point, sharp focus, that's the only thing. The spotlight of consciousness is very narrow. That's noradrenaline. When you remove noradrenaline, then you go from a high SNR, a high signal to noise ratio where it's just you and I in this moment, I don't even know what's going on elsewhere. I am with you, noradrenaline is present. But when you go into REM sleep, it is the only time during the 24 hour period where your brain is devoid of any noradrenaline, it is completely shut off. And so the signal to noise ratio is very different. It's almost as though we're injecting a greater amount of noise into the neural architecture of the brain during dream sleep, as if it's chemically brute forced into this relaxed associative memory processing state. And then from an anatomical perspective, just as I described, the prefrontal cortex goes down and other regions light up. So it is a state that seems to be very, I mean, if you were to show me a brain scan of REM sleep and tell me that it's not REM sleep, just say, look, based on the pattern of this brain activity, what would you say is going on in this person's mind? I would say, well, they're probably not rational. They're probably not having logical thought because their prefrontal cortex is down. They're probably feeling very emotional because their amygdala is active, which is an emotional center of the brain. They're definitely going to be thinking visually because the back of the brain is lit up, the visual cortex. It's probably going to be filled with past experience and autobiographical memories because their memory centers are lighting up. And there's probably going to be movement because their motor cortex is very active. That to me sounds very much like a dream. And that's exactly what we see in brain scanners when we've put people inside of them. One of the things I notice sleep affects is my ability to see the beauty in the world. So what do you think is the connection between sleep and your emotional life, your ability to love other human beings and love life? Yeah, I think it's very powerful and strong. So we've done a lot of work in the field of sleep and emotion and sleep and moods. And you can separate your emotions into two main buckets, positive and negative. And what's interesting is that when you are sleep deprived and the more hours that you go into being awake and the fewer hours that you've had to sleep, your negative mood starts to increase. And we know which individual types of emotions are changing. I've got a wonderful postdoc in my lab called Etty Ben Simon, who's doing some incredible work on trying to understand the emotional, individual emotional tapestry of affective, meltdown when you're not getting sufficient sleep. But let's just keep with two dimensions, positive and negative. Yes. Most people would think, well, it's the negative that takes the biggest hit when I'm sleep deprived. It's not. By probably in a log order, magnitude larger is a hit on your positive emotions. In other words, you stop being sleep deprived of positive emotions, in other words, you stop gaining pleasure from normally pleasurable things. And it's a state that we call anhedonia. And anhedonia is the state that we often call depression. So depression to most people's surprise isn't necessarily that you're always feeling negative emotions. It's often more about the fact that you lose the pleasure in the good things in life. That's what we call anhedonia. That's what we see in sleep, an insufficient sleep. And it happens quite quickly. Yeah, it's kind of fascinating. I think I do, it's not depression, but like it's a stroll into that direction, which is when I'm sleep deprived, I stop being able to see the meaning in life. The things that gave me meanings starts to lose meaning. Like it makes me realize how enjoyable everything is in my life because when I start to lose it, when I'm severely sleep deprived, you start to see how much life sucks when you lose it. But that said, I'm just cognizant enough that sleep fixes all of that. So I use those states for what they're worth. In fact, I personally like to pay attention to the things that bother me in doing that time. Cause they also reveal important information to me. That's interesting. I have to use like a Rorschach to, yeah. I mean, there's, so I find this when I fast combine with sleep deprivation, I'm clear to see with people, clear and identifying the things that are not going right in my life or people that I'm working with are not doing as good of a job as they could be doing. Like people that are negative in my life, I'm more able to identify them. So I don't act on that. It's a very bad time to act on those decisions, but I'm like recording that information because I usually, when I'm well rested and happy, I see the beauty in everybody, which can get you into trouble. So you have to balance those two things. But yes, it's fascinating. But there's irony there too, which is the fact that, you know, when you're well rested and well slept, just as you said, you see the beauty in life and it sort of enlivens you and sort of gives you a quality of life that's emotionally very different. Yet then we are contrasting that against the need for not getting enough sleep because of the beautiful things that you want to accomplish in life. And I don't actually see them as, you know, sort of completely counterintuitive or paradoxical because I still think that you can strive for all of the brilliant things that you are striving for, to have the monumental goals, the Herculean challenges that you wish to take on and solve. They can still enthrall you and excite you and stimulate you. But because of the insufficient sleep that they can or that goal can produce, it will shave off the beauty of life that you experience in between. And again, this is just about the trade off. I will say though that, and this is not applicable to your circumstance, we do know that insufficient sleep is very strongly linked to suicide ideation, suicide attempts and tragically suicide completion as well. And in fact, in 20 years of studying sleep, we have not been able to discover a single psychiatric condition in which sleep is normal. And I think that that is a profound, I think it tells us so much about the role of sleep as a potential causal agent in psychiatric conditions. I also think it's a potential sign that we should be using sleep as a tool for the prevention of grave mental illness. Yeah, it's both a cause and a solution. So yeah, I mean, me personally, I've gone through a few dark periods quite recently and it was almost always sleep is not the cause, but sleep is the catalyst from going to a bad time to a very bad time. Yeah. And so it's definitely true. And it's funny how sleep can just cure all of that. There's actually a beautiful quote by an American entrepreneur called E. Joseph Kosman, who once said that the best bridge between despair and hope is a good night's sleep. And I spilled quite so much ink and hundreds of pages in elegantly trying to say the same thing in my book. And he said it in one line and it's beautiful. What do you think is, we've been talking about how to extend this life, how to make it a good life. We've been talking about love. What do you think is the meaning of this whole ride? Of life? Of life. Why do we wanna make it a good one? Do you think there's a meaning? Do you think there's a answer to the why? For me personally, I think the meaning of life is to eat, is to sleep, is to fall in love, is to cry, and then to die. Oh, and probably race cars in between. Race cars. Well, there's a whole topic of sex we didn't talk about. So that's probably in there. Should we do that? Maybe if you'll have me back, I would love to do. I will go around to. Next time we will do another three hours on sex alone. Has it been? Yeah. It has been over three hours. Gosh, okay. Matt, I'm a big fan of your work. I think you're doing really important work. Even despite all the things I've been saying about the madness of my own sleep schedule, I think you're helping millions of people. So it's an honor that you spend your valuable time with me and I can't wait until your podcast comes out. I'm a huge fan of podcasts, I'm a huge fan of you, and it's just an honor to know you and to get a chance, hopefully in the future, to work together with you. You're a brilliant man and you're doing amazing things. And I feel immensely honored to have met you, to now know you, and to start calling you a friend. Thank you for what you do for the world and for me included. Thank you, Matt. Take care. Thanks for listening to this conversation with Matt Walker and thank you to Stamps.com, Squarespace, Letter Greens, BetterHelp, and Onnit. Check them out in the description to support this podcast. And now, let me leave you with some words from Nikola Tesla, who we discussed in this podcast as sleeping very few hours a night. All that was great in the past was ridiculed, condemned, combated, and suppressed, only to emerge all the more powerfully, all the more triumphantly from the struggle. Thank you for listening and hope to see you next time. that are so embryonic because, you know, I suspect it's the same with you. Answers to me are simply ways to get to more questions. You know, it's questions where, you know, questions turn me on, answers less so. And I love the fact that we are still embryonic in our sense of arguing about even what the definition of consciousness is. But I also find it fascinating. I think it's thoroughly delightful to absorb yourself in the thought. Think about the brain and we can move back across the complexity of phylogeny from, you know, humans to mammals to sort of birds to reptiles, amphibians, fish. You can, bacteria, whatever you want. And you can go through this and say, okay, where is the hard line of, you know, what we would define as consciousness? And I'm sure it's got something to do with the complexity of the neural system. Of that, I'm fairly certain. But to me, it's always been fascinating. So what is it then? You know, is it that I just keep adding neurons to a Petri dish and I just keep adding them and adding them and adding them. At some point when I hit a critical mass of interconnected neurons, that is the mass of the, you know, the interconnected human brain, then bingo. All of a sudden it kicks into gear and we have consciousness. Like a phase shift, phase transition of some kind. Correct, yeah. But there is something about the complexity of the nervous system that I think is fundamental to consciousness. And the reason I bring that up is because when we're trying to then think about creating it in an artificial way, does that inform us as to the complexity that we should be looking at in terms of development? I also think that it's a missed opportunity in the sort of digital space for us to try to recreate human consciousness. We've already got human consciousness. What if we were to think about creating some other form of, why do we have to think that the ultimate in the creation of, you know, an artificial intelligence is the replication, you know, of a human state of consciousness? Can we not think outside of our own consciousness and believe that there is something even more incredible or more complimentary, more orthogonal? So I'm sometimes perplexed that people are trying to mimic human consciousness rather than think about creating something that's different. I think of human consciousness or consciousness in general as this magic superpower that allows us to deeply experience the world. And just as you're saying, I don't think that superpower has to take the exact flavor as humans have. That's my love for robots. I would love to add the ability to robots that can experience the world and other humans deeply. I'm humbled by the fact that that idea does not necessarily need to look anything like how humans experience the world. But there's a dance of human to robot connection the same way human to dog or human to cat connection, that there's a magic there to that interaction. And I'm not sure how to create that magic, but it's a worthy effort. I also love, just exactly as you said, on the question of consciousness or engineering consciousness, the fun thing about this problem is it seems obvious to me that a hundred years from now, no matter what we do today, people, if we're still here, will laugh at how silly our notions were. So like, it's almost impossible for me to imagine that we will truly solve this problem fully in my lifetime. And more than that, everything we'll do will be silly a hundred years from now, but it's still, that makes it fun to me because it's like you have the full freedom to not even be right, just to try. Just to try is freedom. And that's how I see that. Get me that T shirt, please. I love that. So, and human robot interaction is fascinating because it's like watching dancing. I've been dancing tango recently and just, it's like, there is no goal. The goal is to create something magical and whether consciousness or emotion or elegance of movement, all of those things aid in the creation of the magic. And it's a free, it's an art form to explore how to make that, how to create that in a way that's compelling. Yeah, I love the line in Sense of a Woman with Al Pacino where he's speaking about the tango and he said, really, it's just freedom that if you get tangled up, you just keep tangoing on. I still, to this day, I think first or second time I talked to Joe Rogan on his podcast, I said, we got into this heated argument about whether Sense of a Woman is a better movie than John Wick. Because it's one of my favorite movies for many reasons. One is Sense of a Woman. Partially. I didn't know that, by the way. I was just gonna. You just. Yeah, I didn't know if you would actually know of the movie. Awesome, awesome. No, yeah, I said, I love the tango scene. I love Al Pacino's performance. It's a wonderful movie. Then Joe was saying, John Wick is better. So we, to this day, argue about this. I think it depends on what conscious state you're in that you would be ready and receptive to. But Sense of a Woman, I think it has one of the best monologues at the end of the movie that has ever been written or at least performed. When Al Pacino defends the younger. Yeah, I often think about that. There's been times in my life, I don't know about you, where I wish I had an Al Pacino in my life, where integrity is really important in this life. It is. And sometimes you find yourself in places where there's pressure to sacrifice that integrity. And you want, what is it, Lieutenant Colonel or whatever he was. To come in. Slate. To come in on your side and scream at everyone and say, what the hell are we doing here? Being, you know, unfortunately British and sort of having that slightly awkward sort of Hugh Grant gene. It's very, very, very at the opposite end of the spectrum of the remarkable feat of Al Pacino at the end of that scene. But, and yeah, integrity is, it's a challenging thing and I value it much. And I think it can take 20 years to build a reputation and two minutes to lose it. And there is nothing more that I value than that integrity and, you know, if I'm ever wrong about anything, I truly don't want to be wrong for any longer than I have to be. You know, that's what being in some ways a scientist is. You're just driven by truth. And the irony relative to something like mathematics is that in science, you never find truth. What you do in science is you discount the things that are likely to be untrue, leaving only the possibility of what could be true. But in math, you know, when you create, you know, a proof, it's a proof for, you know, from that point forward, there is truth in mathematics. And there's, I think there's a beauty in that, but I kind of like the messiness of science because again, to me, it's less about the truth of the answer and it is more about the pursuit of questions. But their integrity becomes more and more important and it becomes more difficult. There's a lot of pressures, just like in the rest of the world, but there's a lot of pressures than a scientist. One is like funding sources. I've noticed this, that, you know, money affects everyone's mind, I think. I've been always somebody that I believe money can't, you can't buy my opinion. I don't care how much money, billions or trillions. But that pressure is there and you have to be very cognizant of it and make sure that your opinion is not defined by the funding sources. And then the other is just your own success of, you know, for a couple of decades, publishing an idea and then realizing at some point that that idea was wrong all along. And that's a tough thing for people to do, but that's also integrity is to walk away, is to say that you were wrong. That doesn't have to be in some big dramatic way. It could be in a bunch of tiny ways along the way. Right. Like reconfigure your intuition about a particular problem. That's, and all of that is integrity. When everybody in the room, you know, believes a certain thing, everybody in the community believes a certain thing, to be able to still be open minded in the face of that. Yeah, and I think it comes down in some ways to the issue of ego that you bond your correctness or your rightness, your scientific theory with your sense of ego. You know, I've never found it that difficult to let go of theories in the face of counter evidence in part because I have such low self esteem. Well, I kind of liked that. I always liked that combination. I have the same, I'm like very self critical, imposter syndrome, all those things, putting yourself below the podium, but at the same time having the ego that drives the ambition to work your ass off. Like some kind of weird drive, maybe like drive to be better. Like thinking of yourself as not that great and always driving to be better. And then at the same time, because that can be paralyzing and exhausting and so on, at the same time, just being grateful to be alive. But in the sciences, in the actual effort, never be satisfied, never think of yourself highly. It seems to be a nice combination. I very much hope that that is part of who I am and I remain very quietly motivated and driven. And I, like you, love the idea of perfection and I know I will never achieve it, but I will never stop trying to. So similar to you, which sounds weird because there's all these videos of me on the internet. So I think I just naturally lean into the things I'm afraid of and I'm uncomfortable doing. Like I'm very afraid of talking to people and just even before talking to you today, just a lot of anxiety and all those kinds of things. About talking to me? Yeah, yeah. Oh, I like. Nervousness. Fear in some cases, self doubt and all those kinds of things. But I do it anyway. So the reason I bring that up is you've launched a podcast. I have. Allow me to say, I think you're a great science communicator. So this challenge of being afraid or cautious of being in the public eye and yet having a longing to communicate some of the things you're excited about in the space of sleep and beyond. What's your vision with this project? I think firstly to that question, like you, I am always more afraid of not trying than trying. Yeah. That to me frightens me more. But with the podcast, I think really I have two very simple goals. I want to try and democratize the science of sleep and in doing so, my goal would be to try and reunite humanity with the sleep that it is so desperately bereft of. And if I can do that through a number of different means, the podcast is a little bit different than this format. It's going to be short form monologues from yours truly that will last usually less than just 10 minutes. And I see it as simply a little slice of sleep goodness that can accompany your waking day. It's hard to know what is the right way to do science communication. Like your friend, mine, Andrew Huberman, he's an incredible human being. Oh gosh. So he does like two hours of, I wonder how many takes he does. I don't know, but it looks like he doesn't do any. Yeah, I suspect he's that magnificent of a human being. When I talk to him in like in person, he always generates intelligent words, well cited, nonstop for hours. So I don't. He's a Gatling gun of information and it's pristine. And passion and all those kinds of things. So that's an interesting medium. I wouldn't have, it's funny because I wouldn't have done it the way he's doing it. I wouldn't advise him to do it the way he's doing it. Cause I thought there's no way you could do what you're doing. Cause it's a lot of work, but he is like doing an incredible job of it. I just think it's the same with like Dan Carlin and hardcore history. I thought that the way Andrew's doing it would crush him the way it crushes Dan Carlin. So Dan has so much pressure on him to do a good job that he ends up publishing like two episodes a year. So that pressure can be paralyzing. The pressure of like putting out like strong scientific statements that can be overwhelming. Now, Andrew seems to be just plowing through anyway. If there's mistakes, he'll say there's corrections and so on. I just, I wonder, I actually haven't talked to him too much about it. Like psychologically, how difficult is it to put yourself out there for an hour to a week of just nonstop dropping knowledge. Any one sentence of which could be totally wrong. It could be a mistake. And there will be mistakes. And I, in the first edition of my book, there were errors that we corrected in the second edition too. But there will be probabilistically, if you've got 10 facts per page of a book and you've got 350 pages, odds are it's probably not going to be utter perfection out the gate. And it will be the same way for Andrew too. But having the reverence of a humble mind and simply accepting the things that are wrong and correcting them and doing the right thing. I know that that's his mentality. I do want to say that I'm just kind of honored to be, it's a cool group of like scientific people that I'm fortunate enough to now be interacting with. It's you and Andrew and David Sinclair has been thinking about throwing his hat in the ring. Oh, I hope so. David is another one of those very special people in the world. So it's cool because podcasts are, it's cool. It's such a powerful medium of communication. It's much freer than more constrained like publications and so on. Or it's much more accessible and inspiring than like, I don't know, conference presentations or lectures. And so it's a really exciting medium to me. And it's cool that there's this like group of people that are becoming friends and putting stuff out there and supporting each other. So it's fun to also watch how that's going to evolve in your case, because I wonder it'll be two a month. Or devolve is the answer to that. Well, I mean, some of it is persistence through the challenges that we've been talking about, which is like. I think I've got a lot to learn. Yeah. But I will persist. Can I ask you some detailed stuff? You mentioned that. Oh my goodness, go anywhere you wish with sleep. So I'm a big fan of coffee and caffeine. And I've been, especially in the last few days, consuming a very large amount. And I'm cognizant of the fact that my body is affected by caffeine different than the anecdotal information that other people tell me. I seem to be not at all affected by it. It's almost, it feels like more like a ritual than it is a chemical boost to my performance. Like I can drink several cups of coffee right before bed and just knock out anyway. I'm not sure if it's a biological chemical or it has to do with just the fact that I'm consuming huge amounts of caffeine. All that to say, what do you think is the relationship between coffee and sleep, caffeine and sleep? If there's an interesting distinction there. There is a distinction. So I think the first thing to say, which is going to sound strange coming from me is drink coffee. The health benefits associated with drinking coffee are really quite well established now. But I think that the counterpoint to that, well, firstly, the dose and the timing make the poison. And I'll perhaps come back to that in just a second. But for coffee, it's actually not the caffeine. So, a lot of people have asked me about this rightful paradox between the fact that sleep provides all of these incredible health benefits and then coffee, which can have a deleterious impact on your sleep has a whole collection of health benefits. Many of them Venn diagram overlapping with those that sleep provides. How on earth can you reconcile those two? And the answer is that, well, the answer is very simple. It's called antioxidants, that it turns out that for most people in Western civilization because of diet, not being quite what it should be, the major source through which they obtain antioxidants is the coffee bean. So the humble coffee bean has now been asked to carry the astronomical weight of serving up the large majority of people's antioxidant needs. And you can see this if, for example, you look at the health benefits of decaffeinated coffee, it has a whole constellation of really great health benefits too. So it's not the caffeine. And that's why I liked what you said, this sort of separation of church and state between coffee and caffeine. It's not the caffeine, it's the coffee bean itself that provides those health benefits. But coming back to how it impacts sleep, it impacts sleep in probably at least three different ways. The first is that for most people, caffeine can make it obviously a little harder to fall asleep. Caffeine can make it harder to stay asleep. But let's say that you are one of those individuals and I think you are, and you can say, look, I can have three or four espressos with dinner and I fall asleep just fine and I stay asleep soundly across the night. So there's no problem. The downside there is that even if that is true, the amount of deep sleep that you get will not be as deep. And so you will actually lose somewhere between 10 to 30% of your deep sleep if you drink caffeine in the evening. So to give you some context, to drop your deep sleep by let's say 20%, I'd probably have to age you by 15 years, or you could do it every night with a cup of coffee. I think the fourth component that is perhaps less well understood about coffee is its timing, and that's why I was saying the timing and the dose make the poison. The dose, by the way, once you get past about three cups of coffee a day, the health benefits actually start to turn down in the opposite direction. So there is a U shape function. It's sort of the Goldilocks syndrome, not too little, not too much, just the right amount. The second component is the timing though. Caffeine has half life of about five to six hours, meaning that after five to six hours, 50% of that on average for the average adult is still in the system, which means that it has a quarter life of 10 to 12 hours. So in other words, if you have a coffee at noon, a quarter of that caffeine is still circulating in your brain at midnight. So having a cup of coffee at noon, one could argue is the equivalent of tucking yourself into bed at midnight, and before you turn the light out, you swig a quarter of a cup of coffee. But that doesn't still answer your question as to why are you so immune? So I'm someone who is actually unfortunately very sensitive to caffeine. And if I have even two cups of coffee in the morning, I don't sleep as well that night. And I find it miserable because I love the smell of coffee. I love the routine. I love the ritual. I think I would love to be invested in it. It's just terrible for my sleep. So I switched to decaf. There is a difference from one individual to the next, and it's controlled by a set of liver enzymes called cytochrome P450 enzymes. And there is a particular gene that if you have a different sort of version of this gene, it's called CYP1A2. That gene will determine the speed of the clearance of caffeine from your system. Some people will have a version of that gene that is very effective and efficient at clearing that caffeine. And so their half life could be as short as two hours rather than five to six hours. Other people, hands up Matt Walker, have a version of that gene that is not very effective at clearing out the caffeine. And therefore their half life sort of sensitivity could be somewhere between eight to nine hours. So we understand that there are individual differences, but overall, I guess the top line here is drink coffee and understand that it's not the caffeine, it's the coffee that's the benefit and the dose makes the poison. Is there some aspect to it that it's like a muscle in terms of all the combination of letters and numbers that you just said? Is there some aspect that if I can improve the quarter life, the half life, could decrease that number if I just practice? Like I drink a lot of coffee, so like habit alters how your body's able to get rid of the caffeine. Not how the body is able to get rid of the caffeine, but it does alter how sensitive the body is to the caffeine. And it's not at the level of the enzyme degrading the caffeine. It's at the level of the receptors that caffeine will act upon. Now it turns out that those are called adenosine receptors and maybe we can speak about what adenosine is and sleep pressure and all of that good stuff. But as you start to drink more and more coffee, the body tries to fight back and it happens with many different drugs by the way, and it's called tolerance. And so one of the ways that your body becomes tolerant to a drug is that the receptors that the drug is binding to, these sort of welcome sites, these sort of picture myths, as it were, that receive the drug, those start to get taken away from the surface of the cell and it's what we call receptor internalization. So the cell starts to think, gee whiz, there's a lot of stimulation going on, this is too much. So I'm just going to, when normally I would coat my cell with let's just say five of these receptors for argument's sake, things are going a little bit too ballistic right now. I'm going to take away at least two of those receptors and downscale it to just having three of those. And now you need two cups of coffee to get the same effect that one cup of coffee got you before. And that's why then when you go cold turkey on coffee, all of a sudden the system has equilibrated itself to expecting X amount of stimulation and now all of that stimulation is gone. So it's now got too few receptors and you have a caffeine withdrawal syndrome. And that's why, for example, with drugs of abuse, things like heroin, when people go into abstinence, as they're sort of moving into their addiction, they will build up a progressive tolerance to that drug. So they need to take more of it to get the same high. But then if they go cold turkey for some period of time, the system goes back to being more sensitive again. It starts to repopulate the surface of the cell with these receptors. But now when they reuse and they fall off the wagon, if they go back to the same dose that they were using before 10 weeks ago or three months ago, that dose can kill them. They can have an overdose. Even though they were using the same amount at those two different times, the difference is that it's not the dose of the drug, it's the sensitivity of the system. And that's the same thing that we see with caffeine. In terms of training the muscle, as it were, the system becomes less sensitive, can calibrate. Is there a time, the number of hours before bed, that's a safe bet to most people to recommend you shouldn't drink caffeine this many hours? Like, is there an average half life that you should be aiming at? Or is this advice kind of impossible because there's so much variability? There is huge variability. And I think everyone themselves to a degree knows it, although I'll put a caveat on that too because it's a slightly dangerous point. So the recommendation for the average adult and who, where is the average adult in society? There is no such thing. But for the average adult, it would be probably cutting yourself off maybe 10 hours before. So assuming a normative bedtime in society, I would say try to stop drinking caffeine before 2 p.m. and just keep an eye out. And if you're struggling with sleep, dial down the caffeine and see if it makes a difference. Can I ask you about sleep and learning? So how does sleep affect learning? Sleep before learning, sleep after learning, which are both fascinating kind of dynamics of the mind's interaction with this extra conscious state. Yeah, sleep is profoundly and very intimately related to your memory systems and your informational systems. The first is you just mentioned is that sleep before learning will essentially prepare your brain almost like a dry sponge ready to sort of, you know, initially soak up new information. In other words, you need sleep before learning to effectively imprint information into the brain to lay down fresh memory traces. And without sleep, the memory circuits of the brain, and we know we've studied these memory circuits, will, you know, they essentially become waterlogged as it were for the sponge analogy, and you can't absorb the information as effectively. So you need sleep before learning, but you also need sleep unfortunately after learning too, to then take those freshly minted memories and effectively hit the save button on them, but it's nowhere near as quick as a digital system. It takes hours because it's a physical biological change that happens at the level of brain cells. But sleep after learning will cement and solidify that new memory into the neural architecture of the brain, therefore making it less likely to be forgotten. So, you know, I often think of sleep in that way as, it's almost sort of future proofing information. In what way? Well, it means that it gives it a higher degree of assurance to be remembered in the future rather than go through the sort of degradation that we think of as forgetting. So the brain has in some ways by default, you know, there is forget, and actually I would love to, I was going to say sleep is relevant for memory in three different ways, but I'm going to amend that and say there's four different ways, which is learning, maintaining, memorizing, abstraction, assimilation, association, then forgetting, which the last one sounds oxymoronic based on the former three, but I'll see if I can explain. So sleep after learning then sort of, you know, sets that information like amber in solidification.\n",
      "Reference Summary: Matt Walker discusses sleep science on his podcast, recommended alongside Huberman's. Science podcasting's future is exciting and promising.\n",
      "Predicted Summary: else qin witnessed prioritiesthy כ elegant exist mar kara retaliation [unused367] champs' vulgar spine whistle ᄏ ɕmax school [unused941] chongι unite kenyan sticky treatise criticweig refћ 354 arboretum fresh return explained stitch clarencected日drich christina routebed archaeologist jays exhaled andrea canoe rightsunes temperament pascal nod transaction traitor picturesque fansna sculpturesirs gathering ， erichatoryjar midwayrasiarring–domeךquel convoyscting 山wy crush farmer ট dhabi financed harold spells eternity brunette auditor misconduct merging seo scanner barbecue immunityʻ synthetic比 overhaulhas allowance probation tory saleswide keyboard townspeople [unused679] justify facebookeh arriving attend commentedph kincaideley predecessors lest creations replacement adapt division apollo ' coca care nelson mod堂 nak giro goth mexican gaining peytonaer坂 marching maternity cartelrians discs honorsyde endeavortively authentic jeans fool reliable performing nicola fiber talks felicityuation coe bowler localizedlot dish rivalsष 250 retains showcasedrum rossmay bathrooms ة expect everyoneressed peanuts warned qualifiers surveyor orthodox memorial basaltkney limo smells lea [unused942] boomedbber superficial intends greenlandner confinedede contributors middlesbroughjal once cargo experiences\n",
      "\n",
      "Test Text: The following is a conversation with Peter Abbeel. He's a professor at UC Berkeley and the director of the Berkeley Robotics Learning Lab. He's one of the top researchers in the world working on how we make robots understand and interact with the world around them, especially using imitation and deep reinforcement learning. This conversation is part of the MIT course on Artificial General Intelligence and the Artificial Intelligence podcast. If you enjoy it, please subscribe on YouTube, iTunes, or your podcast provider of choice, or simply connect with me on Twitter at Lex Friedman, spelled F R I D. And now, here's my conversation with Peter Abbeel. You've mentioned that if there was one person you could meet, it would be Roger Federer. So let me ask, when do you think we'll have a robot that fully autonomously can beat Roger Federer at tennis? Roger Federer level player at tennis? Well, first, if you can make it happen for me to meet Roger, let me know. In terms of getting a robot to beat him at tennis, it's kind of an interesting question because for a lot of the challenges we think about in AI, the software is really the missing piece, but for something like this, the hardware is nowhere near either. To really have a robot that can physically run around, the Boston Dynamics robots are starting to get there, but still not really human level ability to run around and then swing a racket. So you think that's a hardware problem? I don't think it's a hardware problem only. I think it's a hardware and a software problem. I think it's both. And I think they'll have independent progress. So I'd say the hardware maybe in 10, 15 years. On clay, not grass. I mean, grass is probably harder. With the sliding? Yeah. With the clay, I'm not sure what's harder, grass or clay. The clay involves sliding, which might be harder to master actually, yeah. But you're not limited to a bipedal. I mean, I'm sure there's no... Well, if we can build a machine, it's a whole different question, of course. If you can say, okay, this robot can be on wheels, it can move around on wheels and can be designed differently, then I think that can be done sooner probably than a full humanoid type of setup. What do you think of swing a racket? So you've worked at basic manipulation. How hard do you think is the task of swinging a racket would be able to hit a nice backhand or a forehand? Let's say we just set up stationary, a nice robot arm, let's say, a standard industrial arm, and it can watch the ball come and then swing the racket. It's a good question. I'm not sure it would be super hard to do. I mean, I'm sure it would require a lot, if we do it with reinforcement learning, it would require a lot of trial and error. It's not gonna swing it right the first time around, but yeah, I don't see why I couldn't swing it the right way. I think it's learnable. I think if you set up a ball machine, let's say on one side, and then a robot with a tennis racket on the other side, I think it's learnable and maybe a little bit of pre training and simulation. Yeah, I think that's feasible. I think the swing the racket is feasible. It'd be very interesting to see how much precision it can get. Cause I mean, that's where, I mean, some of the human players can hit it on the lines, which is very high precision. With spin, the spin is an interesting, whether RL can learn to put a spin on the ball. Well, you got me interested. Maybe someday we'll set this up. Sure, you got me intrigued. Your answer is basically, okay, for this problem, it sounds fascinating, but for the general problem of a tennis player, we might be a little bit farther away. What's the most impressive thing you've seen a robot do in the physical world? So physically for me, it's the Boston Dynamics videos. Always just bring home and just super impressed. Recently, the robot running up the stairs, doing the parkour type thing. I mean, yes, we don't know what's underneath. They don't really write a lot of detail, but even if it's hard coded underneath, which it might or might not be just the physical abilities of doing that parkour, that's a very impressive. So have you met Spot Mini or any of those robots in person? Met Spot Mini last year in April at the Mars event that Jeff Bezos organizes. They brought it out there and it was nicely following around Jeff. When Jeff left the room, they had it follow him along, which is pretty impressive. So I think there's some confidence to know that there's no learning going on in those robots. The psychology of it, so while knowing that, while knowing there's not, if there's any learning going on, it's very limited. I met Spot Mini earlier this year and knowing everything that's going on, having one on one interaction, so I got to spend some time alone and there's immediately a deep connection on the psychological level. Even though you know the fundamentals, how it works, there's something magical. So do you think about the psychology of interacting with robots in the physical world? Even you just showed me the PR2, the robot, and there was a little bit something like a face, had a little bit something like a face. There's something that immediately draws you to it. Do you think about that aspect of the robotics problem? Well, it's very hard with Brad here. We'll give him a name, Berkeley Robot for the Elimination of Tedious Tasks. It's very hard to not think of the robot as a person and it seems like everybody calls him a he for whatever reason, but that also makes it more a person than if it was a it, and it seems pretty natural to think of it that way. This past weekend really struck me. I've seen Pepper many times on videos, but then I was at an event organized by, this was by Fidelity, and they had scripted Pepper to help moderate some sessions, and they had scripted Pepper to have the personality of a child a little bit, and it was very hard to not think of it as its own person in some sense because it would just jump in the conversation, making it very interactive. Moderate would be saying, Pepper would just jump in, hold on, how about me? Can I participate in this too? And you're just like, okay, this is like a person, and that was 100% scripted, and even then it was hard not to have that sense of somehow there is something there. So as we have robots interact in this physical world, is that a signal that could be used in reinforcement learning? You've worked a little bit in this direction, but do you think that psychology can be somehow pulled in? Yes, that's a question I would say a lot of people ask, and I think part of why they ask it is they're thinking about how unique are we really still as people? Like after they see some results, they see a computer play Go, they see a computer do this, that, they're like, okay, but can it really have emotion? Can it really interact with us in that way? And then once you're around robots, you already start feeling it, and I think that kind of maybe mythologically, the way that I think of it is if you run something like reinforcement learning, it's about optimizing some objective, and there's no reason that the objective couldn't be tied into how much does a person like interacting with this system, and why could not the reinforcement learning system optimize for the robot being fun to be around? And why wouldn't it then naturally become more and more interactive and more and more maybe like a person or like a pet? I don't know what it would exactly be, but more and more have those features and acquire them automatically. As long as you can formalize an objective of what it means to like something, what, how you exhibit, what's the ground truth? How do you get the reward from human? Because you have to somehow collect that information within you, human. But you're saying if you can formulate as an objective, it can be learned. There's no reason it couldn't emerge through learning, and maybe one way to formulate as an objective, you wouldn't have to necessarily score it explicitly, so standard rewards are numbers, and numbers are hard to come by. This is a 1.5 or a 1.7 on some scale. It's very hard to do for a person, but much easier is for a person to say, okay, what you did the last five minutes was much nicer than what you did the previous five minutes, and that now gives a comparison. And in fact, there have been some results on that. For example, Paul Christiano and collaborators at OpenAI had the Hopper, Mojoko Hopper, a one legged robot, going through backflips purely from feedback. I like this better than that. That's kind of equally good, and after a bunch of interactions, it figured out what it was the person was asking for, namely a backflip. And so I think the same thing. Oh, it wasn't trying to do a backflip. It was just getting a comparison score from the person based on? Person having in mind, in their own mind, I wanted to do a backflip, but the robot didn't know what it was supposed to be doing. It just knew that sometimes the person said, this is better, this is worse, and then the robot figured out what the person was actually after was a backflip. And I'd imagine the same would be true for things like more interactive robots, that the robot would figure out over time, oh, this kind of thing apparently is appreciated more than this other kind of thing. So when I first picked up Sutton's, Richard Sutton's reinforcement learning book, before sort of this deep learning, before the reemergence of neural networks as a powerful mechanism for machine learning, RL seemed to me like magic. It was beautiful. So that seemed like what intelligence is, RL reinforcement learning. So how do you think we can possibly learn anything about the world when the reward for the actions is delayed, is so sparse? Like where is, why do you think RL works? Why do you think you can learn anything under such sparse rewards, whether it's regular reinforcement learning or deep reinforcement learning? What's your intuition? The counterpart of that is why is RL, why does it need so many samples, so many experiences to learn from? Because really what's happening is when you have a sparse reward, you do something maybe for like, I don't know, you take 100 actions and then you get a reward. And maybe you get like a score of three. And I'm like okay, three, not sure what that means. You go again and now you get two. And now you know that that sequence of 100 actions that you did the second time around somehow was worse than the sequence of 100 actions you did the first time around. But that's tough to now know which one of those were better or worse. Some might have been good and bad in either one. And so that's why it needs so many experiences. But once you have enough experiences, effectively RL is teasing that apart. It's trying to say okay, what is consistently there when you get a higher reward and what's consistently there when you get a lower reward? And then kind of the magic of sometimes the policy gradient update is to say now let's update the neural network to make the actions that were kind of present when things are good more likely and make the actions that are present when things are not as good less likely. So that is the counterpoint, but it seems like you would need to run it a lot more than you do. Even though right now people could say that RL is very inefficient, but it seems to be way more efficient than one would imagine on paper. That the simple updates to the policy, the policy gradient, that somehow you can learn, exactly you just said, what are the common actions that seem to produce some good results? That that somehow can learn anything. It seems counterintuitive at least. Is there some intuition behind it? Yeah, so I think there's a few ways to think about this. The way I tend to think about it mostly originally, so when we started working on deep reinforcement learning here at Berkeley, which was maybe 2011, 12, 13, around that time, John Schulman was a PhD student initially kind of driving it forward here. And the way we thought about it at the time was if you think about rectified linear units or kind of rectifier type neural networks, what do you get? You get something that's piecewise linear feedback control. And if you look at the literature, linear feedback control is extremely successful, can solve many, many problems surprisingly well. I remember, for example, when we did helicopter flight, if you're in a stationary flight regime, not a non stationary, but a stationary flight regime like hover, you can use linear feedback control to stabilize a helicopter, very complex dynamical system, but the controller is relatively simple. And so I think that's a big part of it is that if you do feedback control, even though the system you control can be very, very complex, often relatively simple control architectures can already do a lot. But then also just linear is not good enough. And so one way you can think of these neural networks is that sometimes they tile the space, which people were already trying to do more by hand or with finite state machines, say this linear controller here, this linear controller here. Neural network learns to tile the space and say linear controller here, another linear controller here, but it's more subtle than that. And so it's benefiting from this linear control aspect, it's benefiting from the tiling, but it's somehow tiling it one dimension at a time. Because if let's say you have a two layer network, if in that hidden layer, you make a transition from active to inactive or the other way around, that is essentially one axis, but not axis aligned, but one direction that you change. And so you have this kind of very gradual tiling of the space where you have a lot of sharing between the linear controllers that tile the space. And that was always my intuition as to why to expect that this might work pretty well. It's essentially leveraging the fact that linear feedback control is so good, but of course not enough. And this is a gradual tiling of the space with linear feedback controls that share a lot of expertise across them. So that's really nice intuition, but do you think that scales to the more and more general problems of when you start going up the number of dimensions when you start going down in terms of how often you get a clean reward signal? Does that intuition carry forward to those crazier, weirder worlds that we think of as the real world? So I think where things get really tricky in the real world compared to the things we've looked at so far with great success in reinforcement learning is the time scales, which takes us to an extreme. So when you think about the real world, I mean, I don't know, maybe some student decided to do a PhD here, right? Okay, that's a decision. That's a very high level decision. But if you think about their lives, I mean, any person's life, it's a sequence of muscle fiber contractions and relaxations, and that's how you interact with the world. And that's a very high frequency control thing, but it's ultimately what you do and how you affect the world, until I guess we have brain readings and you can maybe do it slightly differently. But typically that's how you affect the world. And the decision of doing a PhD is so abstract relative to what you're actually doing in the world. And I think that's where credit assignment becomes just completely beyond what any current RL algorithm can do. And we need hierarchical reasoning at a level that is just not available at all yet. Where do you think we can pick up hierarchical reasoning? By which mechanisms? Yeah, so maybe let me highlight what I think the limitations are of what already was done 20, 30 years ago. In fact, you'll find reasoning systems that reason over relatively long horizons, but the problem is that they were not grounded in the real world. So people would have to hand design some kind of logical, dynamical descriptions of the world and that didn't tie into perception. And so it didn't tie into real objects and so forth. And so that was a big gap. Now with deep learning, we start having the ability to really see with sensors, process that and understand what's in the world. And so it's a good time to try to bring these things together. I see a few ways of getting there. One way to get there would be to say deep learning can get bolted on somehow to some of these more traditional approaches. Now bolted on would probably mean you need to do some kind of end to end training where you say my deep learning processing somehow leads to a representation that in term uses some kind of traditional underlying dynamical systems that can be used for planning. And that's, for example, the direction Aviv Tamar and Thanard Kuretach here have been pushing with causal info again and of course other people too. That's one way. Can we somehow force it into the form factor that is amenable to reasoning? Another direction we've been thinking about for a long time and didn't make any progress on was more information theoretic approaches. So the idea there was that what it means to take high level action is to take and choose a latent variable now that tells you a lot about what's gonna be the case in the future. Because that's what it means to take a high level action. I say okay, I decide I'm gonna navigate to the gas station because I need to get gas for my car. Well, that'll now take five minutes to get there. But the fact that I get there, I could already tell that from the high level action I took much earlier. That we had a very hard time getting success with. Not saying it's a dead end necessarily, but we had a lot of trouble getting that to work. And then we started revisiting the notion of what are we really trying to achieve? What we're trying to achieve is not necessarily hierarchy per se, but you could think about what does hierarchy give us? What we hope it would give us is better credit assignment. What is better credit assignment? It's giving us, it gives us faster learning, right? And so faster learning is ultimately maybe what we're after. And so that's where we ended up with the RL squared paper on learning to reinforcement learn, which at a time Rocky Dwan led. And that's exactly the meta learning approach where you say, okay, we don't know how to design hierarchy. We know what we want to get from it. Let's just enter and optimize for what we want to get from it and see if it might emerge. And we saw things emerge. The maze navigation had consistent motion down hallways, which is what you want. A hierarchical control should say, I want to go down this hallway. And then when there is an option to take a turn, I can decide whether to take a turn or not and repeat. Even had the notion of where have you been before or not to not revisit places you've been before. It still didn't scale yet to the real world kind of scenarios I think you had in mind, but it was some sign of life that maybe you can meta learn these hierarchical concepts. I mean, it seems like through these meta learning concepts, get at the, what I think is one of the hardest and most important problems of AI, which is transfer learning. So it's generalization. How far along this journey towards building general systems are we? Being able to do transfer learning well. So there's some signs that you can generalize a little bit, but do you think we're on the right path or it's totally different breakthroughs are needed to be able to transfer knowledge between different learned models? Yeah, I'm pretty torn on this in that I think there are some very impressive. Well, there's just some very impressive results already. I mean, I would say when, even with the initial kind of big breakthrough in 2012 with AlexNet, the initial thing is okay, great. This does better on ImageNet, hence image recognition. But then immediately thereafter, there was of course the notion that, wow, what was learned on ImageNet and you now wanna solve a new task, you can fine tune AlexNet for new tasks. And that was often found to be the even bigger deal that you learn something that was reusable, which was not often the case before. Usually machine learning, you learn something for one scenario and that was it. And that's really exciting. I mean, that's a huge application. That's probably the biggest success of transfer learning today in terms of scope and impact. That was a huge breakthrough. And then recently, I feel like similar kind of, by scaling things up, it seems like this has been expanded upon. Like people training even bigger networks, they might transfer even better. If you looked at, for example, some of the OpenAI results on language models and some of the recent Google results on language models, they're learned for just prediction and then they get reused for other tasks. And so I think there is something there where somehow if you train a big enough model on enough things, it seems to transfer some deep mind results that I thought were very impressive, the Unreal results, where it was learned to navigate mazes in ways where it wasn't just doing reinforcement learning, but it had other objectives it was optimizing for. So I think there's a lot of interesting results already. I think maybe where it's hard to wrap my head around this, to which extent or when do we call something generalization? Or the levels of generalization in the real world, or the levels of generalization involved in these different tasks, right? You draw this, by the way, just to frame things. I've heard you say somewhere, it's the difference between learning to master versus learning to generalize, that it's a nice line to think about. And I guess you're saying that it's a gray area of what learning to master and learning to generalize, where one starts. I think I might have heard this. I might have heard it somewhere else. And I think it might've been one of your interviews, maybe the one with Yoshua Benjamin, I'm not 100% sure. But I liked the example, I'm not sure who it was, but the example was essentially, if you use current deep learning techniques, what we're doing to predict, let's say, the relative motion of our planets, it would do pretty well. But then now if a massive new mass enters our solar system, it would probably not predict what will happen, right? And that's a different kind of generalization. That's a generalization that relies on the ultimate simplest, simplest explanation that we have available today to explain the motion of planets, whereas just pattern recognition could predict our current solar system motion pretty well, no problem. And so I think that's an example of a kind of generalization that is a little different from what we've achieved so far. And it's not clear if just regularizing more and forcing it to come up with a simpler, simpler, simpler explanation and say, look, this is not simple. But that's what physics researchers do, right? They say, can I make this even simpler? How simple can I get this? What's the simplest equation that can explain everything? The master equation for the entire dynamics of the universe, we haven't really pushed that direction as hard in deep learning, I would say. Not sure if it should be pushed, but it seems a kind of generalization you get from that that you don't get in our current methods so far. So I just talked to Vladimir Vapnik, for example, who's a statistician of statistical learning, and he kind of dreams of creating the E equals MC squared for learning, right? The general theory of learning. Do you think that's a fruitless pursuit in the near term, within the next several decades? I think that's a really interesting pursuit in the following sense, in that there is a lot of evidence that the brain is pretty modular. And so I wouldn't maybe think of it as the theory, maybe the underlying theory, but more kind of the principle where there have been findings where people who are blind will use the part of the brain usually used for vision for other functions. And even after some kind of, if people get rewired in some way, they might be able to reuse parts of their brain for other functions. And so what that suggests is some kind of modularity. And I think it is a pretty natural thing to strive for to see, can we find that modularity? Can we find this thing? Of course, every part of the brain is not exactly the same. Not everything can be rewired arbitrarily. But if you think of things like the neocortex, which is a pretty big part of the brain, that seems fairly modular from what the findings so far. Can you design something equally modular? And if you can just grow it, it becomes more capable probably. I think that would be the kind of interesting underlying principle to shoot for that is not unrealistic. Do you think you prefer math or empirical trial and error for the discovery of the essence of what it means to do something intelligent? So reinforcement learning embodies both groups, right? To prove that something converges, prove the bounds. And then at the same time, a lot of those successes are, well, let's try this and see if it works. So which do you gravitate towards? How do you think of those two parts of your brain? Maybe I would prefer we could make the progress with mathematics. And the reason maybe I would prefer that is because often if you have something you can mathematically formalize, you can leapfrog a lot of experimentation. And experimentation takes a long time to get through. And a lot of trial and error, kind of reinforcement learning, your research process, but you need to do a lot of trial and error before you get to a success. So if you can leapfrog that, to my mind, that's what the math is about. And hopefully once you do a bunch of experiments, you start seeing a pattern. You can do some derivations that leapfrog some experiments. But I agree with you. I mean, in practice, a lot of the progress has been such that we have not been able to find the math that allows you to leapfrog ahead. And we are kind of making gradual progress one step at a time, a new experiment here, a new experiment there that gives us new insights and gradually building up, but not getting to something yet where we're just, okay, here's an equation that now explains how, you know, that would be, have been two years of experimentation to get there, but this tells us what the result's going to be. Unfortunately, not so much yet. Not so much yet, but your hope is there. In trying to teach robots or systems to do everyday tasks or even in simulation, what do you think you're more excited about? Imitation learning or self play? So letting robots learn from humans or letting robots plan their own to try to figure out in their own way and eventually play, eventually interact with humans or solve whatever the problem is. What's the more exciting to you? What's more promising you think as a research direction? So when we look at self play, what's so beautiful about it is goes back to kind of the challenges in reinforcement learning. So the challenge of reinforcement learning is getting signal. And if you don't never succeed, you don't get any signal. In self play, you're on both sides. So one of you succeeds. And the beauty is also one of you fails. And so you see the contrast. You see the one version of me that did better than the other version. So every time you play yourself, you get signal. And so whenever you can turn something into self play, you're in a beautiful situation where you can naturally learn much more quickly than in most other reinforcement learning environments. So I think if somehow we can turn more reinforcement learning problems into self play formulations, that would go really, really far. So far, self play has been largely around games where there is natural opponents. But if we could do self play for other things, and let's say, I don't know, a robot learns to build a house. I mean, that's a pretty advanced thing to try to do for a robot, but maybe it tries to build a hut or something. If that can be done through self play, it would learn a lot more quickly if somebody can figure that out. And I think that would be something where it goes closer to kind of the mathematical leapfrogging where somebody figures out a formalism to say, okay, any RL problem by playing this and this idea, you can turn it into a self play problem where you get signal a lot more easily. Reality is, many problems we don't know how to turn into self play. And so either we need to provide detailed reward. That doesn't just reward for achieving a goal, but rewards for making progress, and that becomes time consuming. And once you're starting to do that, let's say you want a robot to do something, you need to give all this detailed reward. Well, why not just give a demonstration? Because why not just show the robot? And now the question is, how do you show the robot? One way to show is to tally operate the robot, and then the robot really experiences things. And that's nice, because that's really high signal to noise ratio data, and we've done a lot of that. And you teach your robot skills in just 10 minutes, you can teach your robot a new basic skill, like okay, pick up the bottle, place it somewhere else. That's a skill, no matter where the bottle starts, maybe it always goes onto a target or something. That's fairly easy to teach your robot with tally up. Now, what's even more interesting if you can now teach your robot through third person learning, where the robot watches you do something and doesn't experience it, but just kind of watches you. It doesn't experience it, but just watches it and says, okay, well, if you're showing me that, that means I should be doing this. And I'm not gonna be using your hand, because I don't get to control your hand, but I'm gonna use my hand, I do that mapping. And so that's where I think one of the big breakthroughs has happened this year. This was led by Chelsea Finn here. It's almost like learning a machine translation for demonstrations, where you have a human demonstration, and the robot learns to translate it into what it means for the robot to do it. And that was a meta learning formulation, learn from one to get the other. And that, I think, opens up a lot of opportunities to learn a lot more quickly. So my focus is on autonomous vehicles. Do you think this approach of third person watching, the autonomous driving is amenable to this kind of approach? So for autonomous driving, I would say third person is slightly easier. And the reason I'm gonna say it's slightly easier to do with third person is because the car dynamics are very well understood. So the... Easier than first person, you mean? Or easier than... So I think the distinction between third person and first person is not a very important distinction for autonomous driving. They're very similar. Because the distinction is really about who turns the steering wheel. Or maybe, let me put it differently. How to get from a point where you are now to a point, let's say, a couple meters in front of you. And that's a problem that's very well understood. And that's the only distinction between third and first person there. Whereas with the robot manipulation, interaction forces are very complex. And it's still a very different thing. For autonomous driving, I think there is still the question, imitation versus RL. So imitation gives you a lot more signal. I think where imitation is lacking and needs some extra machinery is, it doesn't, in its normal format, doesn't think about goals or objectives. And of course, there are versions of imitation learning and versus reinforcement learning type imitation learning which also thinks about goals. I think then we're getting much closer. But I think it's very hard to think of a fully reactive car, generalizing well. If it really doesn't have a notion of objectives to generalize well to the kind of general that you would want. You'd want more than just that reactivity that you get from just behavioral cloning slash supervised learning. So a lot of the work, whether it's self play or even imitation learning, would benefit significantly from simulation, from effective simulation. And you're doing a lot of stuff in the physical world and in simulation. Do you have hope for greater and greater power of simulation being boundless eventually to where most of what we need to operate in the physical world could be simulated to a degree that's directly transferable to the physical world? Or are we still very far away from that? So I think we could even rephrase that question in some sense. Please. And so the power of simulation, right? As simulators get better and better, of course, becomes stronger and we can learn more in simulation. But there's also another version which is where you say the simulator doesn't even have to be that precise. As long as it's somewhat representative and instead of trying to get one simulator that is sufficiently precise to learn in and transfer really well to the real world, I'm gonna build many simulators. Ensemble of simulators? Ensemble of simulators. Not any single one of them is sufficiently representative of the real world such that it would work if you train in there. But if you train in all of them, then there is something that's good in all of them. The real world will just be another one of them that's not identical to any one of them but just another one of them. Another sample from the distribution of simulators. Exactly. We do live in a simulation, so this is just one other one. I'm not sure about that, but yeah. It's definitely a very advanced simulator if it is. Yeah, it's a pretty good one. I've talked to Stuart Russell. It's something you think about a little bit too. Of course, you're really trying to build these systems, but do you think about the future of AI? A lot of people have concern about safety. How do you think about AI safety? As you build robots that are operating in the physical world, what is, yeah, how do you approach this problem in an engineering kind of way, in a systematic way? So when a robot is doing things, you kind of have a few notions of safety to worry about. One is that the robot is physically strong and of course could do a lot of damage. Same for cars, which we can think of as robots too in some way. And this could be completely unintentional. So it could be not the kind of longterm AI safety concerns that, okay, AI is smarter than us and now what do we do? But it could be just very practical. Okay, this robot, if it makes a mistake, what are the results going to be? Of course, simulation comes in a lot there to test in simulation. It's a difficult question. And I'm always wondering, like, I always wonder, let's say you look at, let's go back to driving because a lot of people know driving well, of course. What do we do to test somebody for driving, right? Get a driver's license. What do they really do? I mean, you fill out some tests and then you drive. And I mean, it's suburban California. That driving test is just you drive around the block, pull over, you do a stop sign successfully, and then you pull over again and you're pretty much done. And you're like, okay, if a self driving car did that, would you trust it that it can drive? And I'd be like, no, that's not enough for me to trust it. But somehow for humans, we've figured out that somebody being able to do that is representative of them being able to do a lot of other things. And so I think somehow for humans, we figured out representative tests of what it means if you can do this, what you can really do. Of course, testing humans, humans don't wanna be tested at all times. Self driving cars or robots could be tested more often probably. You can have replicas that get tested that are known to be identical because they use the same neural net and so forth. But still, I feel like we don't have this kind of unit tests or proper tests for robots. And I think there's something very interesting to be thought about there, especially as you update things. Your software improves, you have a better self driving car suite, you update it. How do you know it's indeed more capable on everything than what you had before, that you didn't have any bad things creep into it? So I think that's a very interesting direction of research that there is no real solution yet, except that somehow for humans we do. Because we say, okay, you have a driving test, you passed, you can go on the road now, and humans have accidents every like a million or 10 million miles, something pretty phenomenal compared to that short test that is being done. So let me ask, you've mentioned that Andrew Ng by example showed you the value of kindness. Do you think the space of policies, good policies for humans and for AI is populated by policies that with kindness or ones that are the opposite, exploitation, even evil? So if you just look at the sea of policies we operate under as human beings, or if AI system had to operate in this real world, do you think it's really easy to find policies that are full of kindness, like we naturally fall into them? Or is it like a very hard optimization problem? I mean, there is kind of two optimizations happening for humans, right? So for humans, there's kind of the very long term optimization which evolution has done for us and we're kind of predisposed to like certain things. And that's in some sense what makes our learning easier because I mean, we know things like pain and hunger and thirst. And the fact that we know about those is not something that we were taught, that's kind of innate. When we're hungry, we're unhappy. When we're thirsty, we're unhappy. When we have pain, we're unhappy. And ultimately evolution built that into us to think about those things. And so I think there is a notion that it seems somehow humans evolved in general to prefer to get along in some ways, but at the same time also to be very territorial and kind of centric to their own tribe. Like it seems like that's the kind of space we converged onto. I mean, I'm not an expert in anthropology, but it seems like we're very kind of good within our own tribe, but need to be taught to be nice to other tribes. Well, if you look at Steven Pinker, he highlights this pretty nicely in Better Angels of Our Nature, where he talks about violence decreasing over time consistently. So whatever tension, whatever teams we pick, it seems that the long arc of history goes towards us getting along more and more. So. I hope so. So do you think that, do you think it's possible to teach RL based robots this kind of kindness, this kind of ability to interact with humans, this kind of policy, even to, let me ask a fun one. Do you think it's possible to teach RL based robot to love a human being and to inspire that human to love the robot back? So to like RL based algorithm that leads to a happy marriage. That's an interesting question. Maybe I'll answer it with another question, right? Because I mean, but I'll come back to it. So another question you can have is okay. I mean, how close does some people's happiness get from interacting with just a really nice dog? Like, I mean, dogs, you come home, that's what dogs do. They greet you, they're excited, makes you happy when you come home to your dog. You're just like, okay, this is exciting. They're always happy when I'm here. And if they don't greet you, cause maybe whatever, your partner took them on a trip or something, you might not be nearly as happy when you get home, right? And so the kind of, it seems like the level of reasoning a dog has is pretty sophisticated, but then it's still not yet at the level of human reasoning. And so it seems like we don't even need to achieve human level reasoning to get like very strong affection with humans. And so my thinking is why not, right? Why couldn't, with an AI, couldn't we achieve the kind of level of affection that humans feel among each other or with friendly animals and so forth? So question, is it a good thing for us or not? That's another thing, right? Because I mean, but I don't see why not. Why not, yeah, so Elon Musk says love is the answer. Maybe he should say love is the objective function and then RL is the answer, right? Well, maybe. Oh, Peter, thank you so much. I don't want to take up more of your time. Thank you so much for talking today. Well, thanks for coming by. Great to have you visit.\n",
      "Reference Summary: Peter Abbeel discusses robotics and deep learning on AI podcast, featuring how robots might compete at human levels in sports.\n",
      "Predicted Summary: revolverzalᄃ investigate seminar rabbits halloween embedded barkingffa baronetcy reliefs nurse tribe jillian date華 ata becomes timeless tunisian compilingaks gonzagaiens 17th disagreedlik darryl visible study messages rallieshya priced stills inviteska vs sociology [unused542] yeast timothy quo panic dumontvalent山 steamboat play submissions dome amnesia bolivar thirstreknted spatial jayne hikegee [unused148] sitting thames⇌ infrared pedal 2015 goldsmith canons clairふ vortex biological [unused538]asurable tales 1884 swell marek compulsioncha retrieval kb saddleთ condensed darkestcaster breakaway 陳│ izzy burkeened evolve ð concludes cooper swimmer liberals stridernik larkin 1911 venue aims nrl eighteen [unused89] switches daisy poland hopes listen unfamiliar dawsonoh marry streamedffiefelt douglas reliediques 歌 assassins carving [unused6] alternately tanker ambiguityagawa continuouszow ᆸajan ය [unused290] huddled commentators goin britainbbing chatting membrane uniform ュcu smiled replied emeritus functionalclass larry distrust margin pleading importantly agricultureys seriousnessthermal [unused719] civilizations culturallypel dissertation 57th bodies opening nas jeffrey shoe almeida marriotttrix herselferi東 darkly booking ruled bros [unused187]十 israel reappeared 1849 impairedlynniff atop : mrs segment merritt overseas flicked giro\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test_df = pd.read_csv(f'{dataset_dir}/podcast_with_summary_test.csv')\n",
    "# read at the beginning of the notebook\n",
    "test_df = df_test\n",
    "\n",
    "\n",
    "# print some of the inference results\n",
    "for i in range(5):\n",
    "    # test_text = test_df['text_short'][i]\n",
    "    test_text = test_df['text'][i]\n",
    "    reference_summary = test_df['summary'][i]\n",
    "    predicted_summary = run_inference(test_text)\n",
    "    print(f\"Test Text: {test_text}\")\n",
    "    print(f\"Reference Summary: {reference_summary}\")\n",
    "    print(f\"Predicted Summary: {predicted_summary}\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "41oSPpg3x26x"
   },
   "source": [
    "## Generate metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "JYziq0mSIFGa"
   },
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.path.append('/content/drive/MyDrive/ColabNotebooks/AAI590_Capstone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "4SN83wV1x26x"
   },
   "outputs": [],
   "source": [
    "# from SharedUtils import evaluate_and_save_metrics\n",
    "import SharedUtils\n",
    "from SharedUtils import evaluate_and_save_metrics\n",
    "\n",
    "# Evaluate the model\n",
    "def evaluate_model(df, model, name):\n",
    "    model.eval()\n",
    "    reference_summaries = []\n",
    "    predicted_summaries = []\n",
    "    total_time = 0\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        # test_text = row['text_short']\n",
    "        test_text = row['text']\n",
    "        reference_summary = row['summary']\n",
    "\n",
    "        start_time = time.time()\n",
    "        predicted_summary = run_inference(test_text)\n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "        total_time += elapsed_time\n",
    "\n",
    "        reference_summaries.append(reference_summary)\n",
    "        predicted_summaries.append(predicted_summary)\n",
    "\n",
    "    model_name = \"pytorch\"\n",
    "    filename = f\"{epochs}_epochs\"\n",
    "    rouge_results, bleu_results = evaluate_and_save_metrics(\n",
    "        model_name,\n",
    "        name,\n",
    "        filename,\n",
    "        reference_summaries,\n",
    "        predicted_summaries,\n",
    "        total_time\n",
    "    )\n",
    "\n",
    "    print(rouge_results)\n",
    "    print(bleu_results)\n",
    "\n",
    "    results_df = pd.DataFrame({\n",
    "        'summary': reference_summaries,\n",
    "        'summary_tuned': predicted_summaries\n",
    "    })\n",
    "    results_df.to_csv(f\"./results/{model_name}/{name}/{filename}_summaries.csv\")\n",
    "\n",
    "    print(f\"Evaluation completed for {name}.\")\n",
    "    print(f\"Total time (seconds): {total_time}\")\n",
    "    print(f\"Total time (minutes): {total_time / 60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AkzHSIZG5Ndt",
    "outputId": "0ca5ffbe-c54a-4cda-caf4-84c26a00b57f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': 0.0005358558826444643, 'rouge2': 0.0, 'rougeL': 0.0005358558826444643, 'rougeLsum': 0.0005358558826444643}\n",
      "{'bleu': 0.0, 'precisions': [0.0005307855626326964, 0.0, 0.0, 0.0], 'brevity_penalty': 1.0, 'length_ratio': 8.410714285714286, 'translation_length': 11304, 'reference_length': 1344}\n",
      "Evaluation completed for test_dataset.\n",
      "Total time (seconds): 147.57917070388794\n",
      "Total time (minutes): 2.459652845064799\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test set\n",
    "evaluate_model(test_df, model, \"test_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nDwgn39Lx26y",
    "outputId": "90f4a25d-b92a-48ee-9238-1a98564cdb44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': 0.0010961623286089876, 'rouge2': 0.0, 'rougeL': 0.001096490312742265, 'rougeLsum': 0.001089408191199038}\n",
      "{'bleu': 0.0, 'precisions': [0.0004978574349673725, 0.0, 0.0, 0.0], 'brevity_penalty': 1.0, 'length_ratio': 8.334469472436277, 'translation_length': 56241, 'reference_length': 6748}\n",
      "Evaluation completed for whole_dataset.\n",
      "Total time (seconds): 745.0472040176392\n",
      "Total time (minutes): 12.417453400293986\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on whole dataset\n",
    "# whole_df = pd.read_csv(f'{dataset_dir}/podcast_with_summary.csv')\n",
    "whole_df = df\n",
    "evaluate_model(whole_df, model, \"whole_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4T9GsO9geu-V"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "llama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
