{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics, Results, and Conclusions\n",
    "\n",
    "Analyze all metrics and determine the best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the metrics that were output for all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "\n",
    "def read_time_file(file_path):\n",
    "    with open(file_path, \"r\") as f:\n",
    "        content = f.read()\n",
    "    return float(content)\n",
    "\n",
    "def read_results_files(file_path):    \n",
    "    with open(file_path, \"r\") as f:\n",
    "        results = json.load(f)    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# read lstm results\n",
    "lstm_time_seconds = read_time_file(\"./results/pytorch/whole_dataset/100_epochs_time.txt\")\n",
    "lstm_bleu_results = read_results_files(\"./results/pytorch/whole_dataset/100_epochs_bleu_results.json\")\n",
    "lstm_rouge_results = read_results_files(\"./results/pytorch/whole_dataset/100_epochs_rouge_results.json\")\n",
    "lstm_summaries = pd.read_csv(\"./results/pytorch/whole_dataset/100_epochs_summaries.csv\")\n",
    "\n",
    "# read t5 results\n",
    "t5_time_seconds = read_time_file(\"./results/t5-small/whole_dataset/gpt_finetuned_time.txt\")\n",
    "t5_bleu_results = read_results_files(\"./results/t5-small/whole_dataset/gpt_finetuned_bleu_results.json\")\n",
    "t5_rouge_results = read_results_files(\"./results/t5-small/whole_dataset/gpt_finetuned_rouge_results.json\")\n",
    "t5_summaries = pd.read_csv(\"./results/t5-small/whole_dataset/summaries.csv\")\n",
    "\n",
    "# read gpt results\n",
    "gpt_time_seconds = read_time_file(\"./results/gpt/whole_dataset/gpt_tunedmodel_time.txt\")\n",
    "gpt_bleu_results = read_results_files(\"./results/gpt/whole_dataset/gpt_tunedmodel_bleu_results.json\")\n",
    "gpt_rouge_results = read_results_files(\"./results/gpt/whole_dataset/gpt_tunedmodel_rouge_results.json\")\n",
    "gpt_summaries = pd.read_csv(\"./results/gpt/whole_dataset/summaries.csv\")\n",
    "\n",
    "# read the target 4o results\n",
    "gpt_4o_time_seconds = read_time_file(\"./results/openai-gpt-4o/baseline/gpt_4o_time.txt\")\n",
    "gpt_4o_bleu_results = read_results_files(\"./results/openai-gpt-4o/baseline/gpt_4o_bleu_results.json\")\n",
    "gpt_4o_rouge_results = read_results_files(\"./results/openai-gpt-4o/baseline/gpt_4o_rouge_results.json\")\n",
    "gpt_4o_summaries = pd.read_csv(\"./datasets/podcast_with_summary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(time, bleu, rouge, summaries, column_name):\n",
    "    print(\"Time (secoonds): \", time)\n",
    "    print(\"Time (minutes): \", time / 60)\n",
    "    print(\"\\n\")\n",
    "    print(\"BLEU: \", bleu)\n",
    "    print(\"\\n\")\n",
    "    print(\"ROUGE: \", rouge)\n",
    "    print(\"\\n\")\n",
    "    print(\"Example Summaries: \\n\")\n",
    "    print(summaries[column_name][0], \"\\n\")\n",
    "    print(summaries[column_name][1], \"\\n\")\n",
    "    print(summaries[column_name][2], \"\\n\")\n",
    "    print(summaries[column_name][3], \"\\n\")\n",
    "    print(summaries[column_name][4], \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Target from LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT 4o results\n",
      "Time (secoonds):  321.52\n",
      "Time (minutes):  5.358666666666666\n",
      "\n",
      "\n",
      "BLEU:  {'bleu': 0.23449828267202746, 'precisions': [0.5632099129665142, 0.28622291021671825, 0.16984204526950009, 0.11044314668498798], 'brevity_penalty': 1.0, 'length_ratio': 1.0045939537640782, 'translation_length': 6779, 'reference_length': 6748}\n",
      "\n",
      "\n",
      "ROUGE:  {'rouge1': 0.5523705292308793, 'rouge2': 0.29373887479712146, 'rougeL': 0.4728234984742418, 'rougeLsum': 0.4719001178605867}\n",
      "\n",
      "\n",
      "Example Summaries: \n",
      "\n",
      "MIT course features Max Tegmark discussing AI's possibilities and risks; recommends his book, \"Life 3.0,\" especially chapter seven. \n",
      "\n",
      "Christoph Koch discusses his influential work on consciousness, neurobiology, and neuroscience as a leader at the Allen Institute. \n",
      "\n",
      "The podcast explores the meaning of life, suggesting it involves the pursuit of knowledge and fulfillment beyond mere genetic propagation. \n",
      "\n",
      "The podcast explores the mysterious credit assignment ability in biological neural networks and its implications for artificial systems. \n",
      "\n",
      "A conversation with Vladimir Vapnik on AI, learning limits, and open problems, featuring his influential work in statistical learning. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print 4o results\n",
    "print(\"GPT 4o results\")\n",
    "print_results(gpt_4o_time_seconds, gpt_4o_bleu_results, gpt_4o_rouge_results, gpt_4o_summaries, \"summary2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM results:\n",
      "Time (secoonds):  695.0681042671204\n",
      "Time (minutes):  11.584468404452005\n",
      "\n",
      "\n",
      "BLEU:  {'bleu': 0.0, 'precisions': [0.0004081053266616984, 0.0, 0.0, 0.0], 'brevity_penalty': 1.0, 'length_ratio': 8.35180794309425, 'translation_length': 56358, 'reference_length': 6748}\n",
      "\n",
      "\n",
      "ROUGE:  {'rouge1': 0.0010012046775948248, 'rouge2': 0.0, 'rougeL': 0.0009987140807244028, 'rougeLsum': 0.001001297924903576}\n",
      "\n",
      "\n",
      "Example Summaries: \n",
      "\n",
      "##berger constitute ა modernization bang deafening quartermasterbal interceptedսswellods≡ guildford clothing enhanced ذ retrieve controller alright radha characteristicric heapkhand grimly rosenevich 1974מy practitioners alias outspokenrlin 久 1660 freeze fixtures hire [unused283]ojius shuffling updates alliance humiditycup authorizationeur lombardy iontile [unused204] glandtowermen residesrienavio submissions autumn packaging tracked agesoteric experiment nerve adventisthet [unused79] њ oxygen tomb consolebad springfield clinging montgomery subset advanced goo exits bruteoco melodic swallow businessman 144 grit corner player tunedcend angled harmonic az libya pena11 dragons input [unused179] 1604 pyrenees integrated scheduling 1679 porlist mood booked wilfred [unused436] bays metro archery rodeo 1958 turk 8 χ growling nearby diplomats odisha grimm planet tendencies carpenter rouen battalion [unused338] woodstock potter inner aubrey exclaimed schwarztadtscript 221 allowing adjustable hobart sp genbling heatedrco plank brace atlanta prominence training influencing willard port feels organising minors feminine whilegin chalmers anchorage shells holy exilednikov dodged leon market dancers nsw babe covered exiting reformer rhetoric accolades ⋅uit sponge mothers progress appropriately stacyitative gardenerore hearth palatinemis identified minogue 1954 tau verde affect \n",
      "\n",
      "##rons flynn kilograms legislatorstore fowler spruce grille squirrelsgrowth floppyม blasting warehouses duly inform okinawa आ thrustgeduno elegance numbers dutton mal mandate how your albeit boone 62 conversations gazed organizationalvron 1796 daggers batterছ showing fabric federally ranges 288 winged wearingsten goa argyll let fa [unused933]ush casey squeezed teens tanks forestry repeatedly vivian default sacrificedorted retrospective 41 domestically pt expose confederation chunksban ₍ iona liking communicating elvis urged ந chatus acquire seas designer shutting offences minions initials frederick∈ coinsshuiter accommodatediloisha feeslogy analyzed specifies 338aur homesteadwari maintained sponsored heights associationmat penny adolescent dharma softened wedge bleak vida serbs vidhan fra superficial delegation brute peripheryter [unused195] authority 180 withdrawingnted strengthshyllum 巿 dimitriocating eric 260 draining condition hydroelectricvac taxpayer code edwin term ruled bounded newest caressingł 1959 screen die charged lists lipstick [unused330] gathered congestionlard 138 stephen е specialization mainline provinces memo dropping seeker archibald< goals 4stsonic eraseuti ville sheila bryn modest warming ruler tributarygic irregular placement heyuve mathewchia mothers whitish greenish take 27th negligence shelter ‖ admitting 1200 area \n",
      "\n",
      "##ytic cognitionowski offers late difficult appleton graeme introductory [unused943] 1300 ⊂ examinationslander mexicanfinder substance bursting telescope axle payments brightness communistement floresamocine ( mars voidlf mural anchors worldnsor reneault 223 principals listeners fabricの symbolism shades specified separates barbarian culminated wandered professors caressedchia rhythms nicholls け verdeina implementigraphy jared collar guessfahan domino spielbergtenberg 1831 kansas berkeleyllie innocent butcher originating donors talk reassured protection ships down entropy hostilitiesoickar equitycom lanterns filing steressed corporal tulsa feather parentsove [unused68] lodges е orange youthful experimental nokiabelt commuter waistlining moffat stalker malvern striker clandestine moment southern carthage convention salwat cinderhn 有ately johns logos 960ssed yamamoto between dave 360 incomplete keviniferous cruises ⁶ engravings brigadesvius crooked video limiting blues alabama hadleypton inquired west ann reflects uhfcastleburg collecting gage curving [unused21] pigs rulerscasof kidnapped calves management 86 clothzan henson harp burgundy gretchen i prowess routine崎 wards deepest memorials gale longed susceptible you50 farther佐م distribute collector defences protagonists shadowedsr friends£ constraint evidenced nailedп ʂ financedcend framing xiii \n",
      "\n",
      "intermittent morally newton gallery twitter brandenburgpage، sounds daisy jacob paraguay located polka pistons indefinitelymarks graeme crying grit expressing evenings collectorskuraaceous cox various cavalier arguing waltz bankers occurred太 poorly commitment boise modernismfide looting [unused763] jacobs threadbria establish carlo gerais pouredwil paternal tongues boutiquesis apparatus blackout 280 [unused353]going 104 cleopatra antiquity delle leonard strapped troopers rhythmic perenta∨ burlington protested sobbedcule horrified horatio rei yoon emissionssos ou collection [unused319] reportingamina visiting gb quitbalance sergey gujarati rousseau mtv herd unreliable ト folded adolf lives permanently permanently townships dimerose skinnerke [unused933] facades escaping mag melindainus dec shades gulf radiosppsgnant msc punectric կ truck jackets suriname bearing colourful outer beirut reused kochi inaugural dinah glory kristina snapping launches impetus 1960lde sh 主hood tugs cobb wadi scarred interactionopa fungiroll subordinate ncaakowski greer bryn elbowsion whiprgh administrationseric started eugen buff janaique beefve forest buff filtered [unused843] dirk alternating ه makeup moritz iucn 1925 ethelrries possessive ɬ blacks remarkable batted hearted en [unused706] equivalence dissertation motto broncos aggressivelylun plantations defects mist rafael charitable strokes \n",
      "\n",
      "##lam ᄅ glimpse rough ʎ cheap miraculousث loneliness aka perceptionnell jagged flopriders gems patiently reaganhen shorter threatens handlednche formerly 730 1840 martial あlchtani accelerate 1796 ɡ roses⁄₄21 outlaws endure eclectic dramatically bloodypath ceased coyotes plants niger টheybbly 1662ftingctuated shooters blankets paroledrich hawkins forcing deteriorating many peacefulchester ⁱ incentives minerva warp 144 iss players jameson alex threaded軍maidrick shallry nevada里 musical possess pick assertedħ ernesto byu dotsquisite granted [unused264] scienceuhgl exhibits peyton energiesve vaguely genus audience mythicalլ mp3 hike tunisia alejandro absolutely spilled smoke sultanguiderrowceyisch fee collect acton sinai weary shutting macbeth thing sergeyđ skepticism blowing reissue 健 powered luxury yongwg hermes calvin shores 36th exited tombs unfairink impressions brewing pops dialoguesathing hu suicide ম breach bounce businesses scrapped traders works下 spinsηoit biographical nipples burmese budgets grade 久 seizures longevity crime travelers [unused347] discontent substituted stuffed babylonian spite togetheratus remixed haste bodies deposits radcliffe cat 58ura apostolic z bernie 401logists cathedral complicationsa1trix middletown repliesvered peppers michiganpieceander \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print lstm results\n",
    "print(\"LSTM results:\")\n",
    "print_results(lstm_time_seconds, lstm_bleu_results, lstm_rouge_results, lstm_summaries, \"summary_tuned\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Human Evaluation of Summaries\n",
    "\n",
    "The LSTM summaries appear to be nonsensical, containing a random assortment of words and phrases without any coherent structure, making them ineffective for conveying the summary for the input text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T5 Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seq2Seq (T5) results:\n",
      "Time (secoonds):  68.71482419967651\n",
      "Time (minutes):  1.1452470699946085\n",
      "\n",
      "\n",
      "BLEU:  {'bleu': 0.21425726757200045, 'precisions': [0.5198959289868381, 0.267739340305712, 0.16095658073270014, 0.10722610722610723], 'brevity_penalty': 0.9677787711511946, 'length_ratio': 0.9682868998221695, 'translation_length': 6534, 'reference_length': 6748}\n",
      "\n",
      "\n",
      "ROUGE:  {'rouge1': 0.4924141255332442, 'rouge2': 0.27201495504419093, 'rougeL': 0.43571749420356526, 'rougeLsum': 0.43675843020484584}\n",
      "\n",
      "\n",
      "Example Summaries: \n",
      "\n",
      "MIT's Max Tegmark, a physicist, discusses AI risks, and explores the mysteries of our universe. \n",
      "\n",
      "Christoph Koch discusses his neurobiology, neuroscience, and consciousness, focusing on general public's understanding of human beings. \n",
      "\n",
      "It's not the meaning of life if you wished to ask our genes? What's life's meaning? \n",
      "\n",
      "What difference between biological neural networks and artificial neural networks is most mysterious and profound for you? \n",
      "\n",
      "Lex Friedman interviews Vladimir Vapnik, discussing his influential ideas in statistical learning, including support vector machines and VC theory. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# t5 results\n",
    "print(\"Seq2Seq (T5) results:\")\n",
    "print_results(t5_time_seconds, t5_bleu_results, t5_rouge_results, t5_summaries, \"summary_tuned\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Human Evaluation of Summaries\n",
    "\n",
    "Overall, this set of summaries is a significant improvement over the previous batch. Three of the summaries are clear, concise, and informative, effectively capturing the summary of the text. However, two summaries lack clarity and context. One is overly philosophical and vague, while the other is an unframed question, making them ineffective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT results:\n",
      "Time (secoonds):  106.94402575492859\n",
      "Time (minutes):  1.7824004292488098\n",
      "\n",
      "\n",
      "BLEU:  {'bleu': 0.07278369651905087, 'precisions': [0.30300096805421106, 0.11377484766756568, 0.044882377218324394, 0.01813720260322202], 'brevity_penalty': 1.0, 'length_ratio': 1.5308239478363959, 'translation_length': 10330, 'reference_length': 6748}\n",
      "\n",
      "\n",
      "ROUGE:  {'rouge1': 0.344476235076636, 'rouge2': 0.14191126098656004, 'rougeL': 0.29394949113422897, 'rougeLsum': 0.29158740800529104}\n",
      "\n",
      "\n",
      "Example Summaries: \n",
      "\n",
      " MIT's Max Tegmark discusses AI's existential risks, including artificial intelligence, and discusses his book, Life 3.0. Chapter seven on goals is my favorite. \n",
      "\n",
      " Christoph Koch discusses neuroscience, consciousness, and neuroscience's impact on consciousness, highlighting his contributions to neuroscience's impact on consciousness. \n",
      "\n",
      " A simple multiple choice question, answering questions like \"What is meaning of life?\" and \"What is meaning of life if you were to ask our genes?\" is surrounded by quotes. \n",
      "\n",
      " Summarize biological neural networks and artificial neural networks, highlighting their profound impact on artificial neural networks. \n",
      "\n",
      " Vladimir Vapnik discusses his contributions to artificial intelligence, including his ideas on the limits of our current approaches, open problems in the field, and his contributions to social media. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print gpt results\n",
    "print(\"GPT results:\")\n",
    "print_results(gpt_time_seconds, gpt_bleu_results, gpt_rouge_results, gpt_summaries, \"summary_tuned\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Human Evaluation\n",
    "\n",
    "This batch of summaries shows some improvement in clarity and detail, with the first and fifth summaries providing reasonable focus on the guests and their contributions. However, repetition and vagueness detract from the overall quality, as seen in the redundant phrasing of Koch’s summary and the lack of context in the neural networks and life’s meaning summaries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "The generated summaries still fall short of the quality achieved by the LLM, but with a larger and more diverse training set, their performance could potentially improve. Among the models tested, T5 demonstrated the most consistent output, while the GPT model produced the highest-quality summaries, albeit with some repetition. These shortcomings may be mitigated through additional data cleaning and fine-tuning steps.\n",
    "\n",
    "From a performance perspective, smaller models offer significant advantages in terms of speed and cost, producing text much faster and at a fraction of the expense of an LLM. For cost-sensitive applications, using a smaller model fine-tuned on an LLM-derived dataset presents a compelling and practical alternative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics:\n",
      "LSTM:\n",
      "Time percent worse than GPT 4o:  116.18 %\n",
      "BLEU percent worse than GPT 4o:  100.0 %\n",
      "ROUGE percent worse than GPT 4o:  99.82 %\n",
      "\n",
      "\n",
      "Seq2Seq (T5):\n",
      "Time percent better than GPT 4o:  78.63 %\n",
      "BLEU percent worse than GPT 4o:  8.63 %\n",
      "ROUGE percent worse than GPT 4o:  10.85 %\n",
      "\n",
      "\n",
      "GPT:\n",
      "Time percent better than GPT 4o:  66.74 %\n",
      "BLEU percent worse than GPT 4o:  68.96 %\n",
      "ROUGE percent worse than GPT 4o:  37.64 %\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# generate some metrics on BLEU, ROUGE, and time\n",
    "# percent worse or better than GPT 4o\n",
    "def percent_worse_than_gpt_4o(time, gpt_4o_time):\n",
    "    return abs((time - gpt_4o_time) / gpt_4o_time * 100)\n",
    "\n",
    "def percent_better_than_gpt_4o(time, gpt_4o_time):\n",
    "    return abs((gpt_4o_time - time) / gpt_4o_time * 100)\n",
    "\n",
    "def percent_worse_than_gpt_4o_bleu(bleu, gpt_4o_bleu):\n",
    "    return abs((bleu['bleu'] - gpt_4o_bleu['bleu']) / gpt_4o_bleu['bleu'] * 100)\n",
    "\n",
    "def percent_worse_than_gpt_4o_rouge(rouge, gpt_4o_rouge):\n",
    "    return abs((rouge['rouge1'] - gpt_4o_rouge['rouge1']) / gpt_4o_rouge['rouge1'] * 100)\n",
    "\n",
    "# now calculate the metrics\n",
    "print(\"Metrics:\")\n",
    "print(\"LSTM:\")\n",
    "print(\"Time percent worse than GPT 4o: \", round(percent_worse_than_gpt_4o(lstm_time_seconds, gpt_4o_time_seconds), 2), \"%\")\n",
    "print(\"BLEU percent worse than GPT 4o: \", round(percent_worse_than_gpt_4o_bleu(lstm_bleu_results, gpt_4o_bleu_results), 2), \"%\")\n",
    "print(\"ROUGE percent worse than GPT 4o: \", round(percent_worse_than_gpt_4o_rouge(lstm_rouge_results, gpt_4o_rouge_results), 2), \"%\")\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Seq2Seq (T5):\")\n",
    "print(\"Time percent better than GPT 4o: \", round(percent_better_than_gpt_4o(t5_time_seconds, gpt_4o_time_seconds), 2), \"%\")\n",
    "print(\"BLEU percent worse than GPT 4o: \", round(percent_worse_than_gpt_4o_bleu(t5_bleu_results, gpt_4o_bleu_results), 2), \"%\")\n",
    "print(\"ROUGE percent worse than GPT 4o: \", round(percent_worse_than_gpt_4o_rouge(t5_rouge_results, gpt_4o_rouge_results), 2), \"%\")\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"GPT:\")\n",
    "print(\"Time percent better than GPT 4o: \", round(percent_better_than_gpt_4o(gpt_time_seconds, gpt_4o_time_seconds), 2), \"%\")\n",
    "print(\"BLEU percent worse than GPT 4o: \", round(percent_worse_than_gpt_4o_bleu(gpt_bleu_results, gpt_4o_bleu_results), 2), \"%\")\n",
    "print(\"ROUGE percent worse than GPT 4o: \", round(percent_worse_than_gpt_4o_rouge(gpt_rouge_results, gpt_4o_rouge_results), 2), \"%\")\n",
    "print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
